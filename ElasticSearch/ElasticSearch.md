**Elasticsearch**

**介绍**

> Elasticsearch（ES）是一个基于Lucene构建的开源、分布式、RESTful接口的全文搜索引擎。Elasticsearch还是一个分布式文档数据库，其中每个字段均可被索引，而且每个字段的数据均可被搜索，ES能够横向扩展至数以百计的服务器存储以及处理PB级的数据。可以在极短的时间内存储、搜索和分析大量的数据。通常作为具有复杂搜索场景情况下的核心发动机。
>

**Elasticsearch能做什么**

> 1. 当你经营一家网上商店，你可以让你的客户搜索你卖的商品。在这种情况下，你可以使用ElasticSearch来存储你的整个产品目录和库存信息，为客户提供精准搜索，可以为客户推荐相关商品。
> 2. 当你想收集日志或者交易数据的时候，需要分析和挖掘这些数据，寻找趋势，进行统计，总结，或发现异常。在这种情况下，你可以使用Logstash或者其他工具来进行收集数据，当这引起数据存储到ElasticsSearch中。你可以搜索和汇总这些数据，找到任何你感兴趣的信息。
> 3. 对于程序员来说，比较有名的案例是GitHub，GitHub的搜索是基于ElasticSearch构建的，在github.com/search页面，你可以搜索项目、用户、issue、pull  request，还有代码。共有40~50个索引库，分别用于索引网站需要跟踪的各种数据。虽然只索引项目的主分支（master），但这个数据量依然巨大，包括20亿个索引文档，30TB的索引文件。
>



**ES基本概念与关系型数据库的比较**

| ES概念                                         | 关系型数据库       |
| ---------------------------------------------- | ------------------ |
| Index（索引）支持全文检索                      | Database（数据库） |
| Type（类型）                                   | Table（表）        |
| Document（文档），不同文档可以有不同的字段集合 | Row（数据行）      |
| Field（字段）                                  | Column（数据列）   |
| Mapping（映射）                                | Schema（模式）     |

ElasticSearch是基于Lucene工具包 做了一下封装和增强





**一、ElasticSearch概述**

Elaticsearch，简称为es，是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据;

本身扩展性很好，可以扩展到上百台服务器，处理PB级别(大数据时代）的数据。

es使用java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是<mark>通过简单的RESTFUL API{/user  get.post.delete}来隐藏Lucene的复杂性，从而让全文搜索变得简单</mark>。

据国际权威的数据库产品评测机构DB Engines的统计，在2016年1月，ElasticSearch已超过Solr等，成为**排名第一的搜索引擎类应用**。



**历史**

> 多年前，一个叫做Shay Banon的刚结婚不久的失业开发者，由于妻子要去伦敦学习厨师，他便跟着也去了。在他找工作的过程中，为了给妻子构建一个食谱的搜索引擎，他开始构建一个早期版本的Lucene。
>
> 直接基于Lucene工作会比较困难，所以Shay开始抽象Lucene代码以便lava程序员可以在应用中添加搜索功能。他发布了他的第一个开源项目，叫做“Compass”。
>
> 后来Shay找到一份工作，这份工作处在高性能和内存数据网格的分布式环境中，因此高性能的、实时的、分布式的搜索引擎也是理所当然需要的。然后他决定重写Compass库使其成为一个独立的服务叫做Elasticsearch。
>
> 第一个公开版本出现在2010年2月，在那之后Elasticsearch已经成为Github上最受欢迎的项目之一，代码贡献者超过300人。一家主营Elasticsearch的公司就此成立，他们一边提供商业支持一边开发新功能，不过Elasticsearch将永远开源且对所有人可用。
>
> Shay的妻子依旧等待着她的食谱搜索…..

**谁在使用：**

> 1、维基百科,类似百度百科，全文检索,高亮,搜索推荐(权重)
> 2、The Guardian (国外新闻网站) ,类似搜狐新闻,用户行为日志(点击,浏览,收藏,评论) +社交网络数据(对某某新闻的相关看法) ,数据分析,给到每篇新闻文章的作者,让他知道他的文章的公众反馈(好 坏 热门 垃圾 鄙视 崇拜)
> 3、Stack Overflow (国外的程序异常讨论论坛) , IT问题,程序的报错,提交上去,有人会跟你讨论和回答,全文检索,搜索相关问题和答案,程序报错了,就会将报错信息粘贴到里面去,搜索有没有对应的答案
> 4、GitHub (开源代码管理),搜索 上千亿行代码
> 5、电商网站,检索商品
> 6、日志数据分析, logstash采集日志, ES进行复杂的数据分析, **ELK技术, elasticsearch+logstash+kibana**
> 7、商品价格监控网站,用户设定某商品的价格阈值,当低于该阈值的时候,发送通知消息给用户,比如说订阅牙膏的监控,如果高露洁牙膏的家庭套装低于50块钱,就通知我,我就去买
> 8、BI系统,商业智能, Business Intelligence。比如说有个大型商场集团，BI ,分析一下某某区域最近3年的用户消费  金额的趋势以及用户群体的组成构成,产出相关的数张报表。ES执行数据分析和挖掘,  Kibana进行数据可视化
> 9、国内:站内搜索(电商,招聘,门户,等等),IT系统搜索(OA,CRM,ERP,等等),数据分析(ES热门的一一个使用场景)



**ES和Solr**

**ElasticSearch简介**

- Elasticsearch是一个**实时分布式搜索和分析引擎**。 它让你以前所未有的速度处理大数据成为可能。
- 它用于<mark>**全文搜索、结构化搜索、分析**</mark>以及将这三者混合使用:
- `维基百科`使用Elasticsearch提供**全文搜索**并**高亮关键字**,以及输入**实时搜索**(search-asyou-type)和**搜索纠错**(did-you-mean)等搜索建议功能。
- `英国卫报`使用Elasticsearch结合用户日志和社交网络数据提供给他们的编辑以实时的反馈,以便及时了解公众对新发表的文章的回应。
- `StackOverflow`结合全文搜索与地理位置查询,以及more-like-this功能来找到相关的问题和答案。
- `Github`使用Elasticsearch检索1300亿行的代码。
- Elasticsearch不仅用于大型企业，它还让创业公司将最初的想法变成可扩展的解决方案。
- Elasticsearch可以在你的笔记本上运行,也可以在数以百计的服务器上处理PB级别的数据。
- Elasticsearch是一个基于Apache Lucene的开源搜索引擎。无论在开源还是专有领域, Lucene可被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。
  - 但是, **Lucene只是一个库**。 想要使用它,你必须使用Java来作为开发语言并将其直接集成到你的应用中,更糟糕的是, Lucene非常复杂,你需要深入了解检索的相关知识来理解它是如何工作的。
- Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能,但是它的**目的**是<mark>通过简单的**RESTful API**来隐藏Lucene的复杂性,从而让全文搜索变得简单。</mark>



**Solr简介**

- Solr是Apache下的一个顶级开源项目,采用Java开发,它是**基于Lucene的全文搜索服务器**。Solr提供了比Lucene更为**丰富的查询语言**,同时实现了**可配置**、**可扩展**，并对**索引、搜索性能进行了优化**
- Solr可以**独立运行**,运行在Tomcat等这些Selrvlet容器中 , Solr 索引的实现方法很简单,<mark>用POST方法向Solr服务器发送一个描述Field及其内容的XML文档, Solr根据xml文档**添加、删除、更新**索引</mark>。Solr 搜索只需要发送HTTP GET请求,然后对Solr返回xml、json等格式的查询结果进行解析,组织页面布局。
- Solr不提供构建UI的功能, **Solr提供了一个管理界面,通过管理界面可以查询Solr的配置和运行情况。**
- Solr是基于lucene开发企业级搜索服务器,实际上就是封装了lucene.
- Solr是一个独立的企业级搜索应用服务器,它**对外提供类似于Web-service的API接口**。用户可以通过http请求,向搜索引擎服务器提交-定格式的文件,生成索引;也可以通过提出查找请求,并得到返回结果。



**ElasticSearch与Solr比较**

```
当单纯的对已有数据进行搜索时，Solr更快
```

```
当实时建立索引时，Solr会产生io阻塞，查询性能较差，ElasticSearch具有明显的优势
```

```
随着数据量的增加，Solr的搜索效率会变得更低，而ElasticSearch却没有明显的变化
```

```
转变我们的搜索基础设施从Solr到ElasticSearch，我们看见一个即时约50倍提高搜索性能！
```

**总结**

> 1、**es**基本是**开箱即用**(解压就可以用!) ,非常简单。Solr安装略微复杂一丢丢!
> 2、**Solr 利用Zookeeper进行分布式管理**,而**Elasticsearch自身带有分布式协调管理功能。不需要搭建zookeeper集群**
> 3、Solr 支持更多格式的数据,比如JSON、XML、 CSV ,而**Elasticsearch仅支持json文件格式，但足够了**。
> 4、Solr 官方提供的功能更多,而Elasticsearch本身更注重于核心功能，高级功能多有第三方插件提供，例如图形化界面需要kibana友好支撑
> 5、**Solr 查询快,但更新索引时慢(即插入删除慢)** ，用于电商等查询多的应用;
>
> - **ES建立索引快(即查询慢)** ，即**实时性查询快**，用于facebook新浪等搜索。
> - Solr是传统搜索应用的有力解决方案，但Elasticsearch更适用于新兴的实时搜索应用。
>
> 6、Solr比较成熟，有一个更大，更成熟的用户、开发和贡献者社区，而Elasticsearch相对开发维护者较少,更新太快,学习使用成本较高。









**二、ElasticSearch安装**

```
JDK1.8，最低要求
```

使用Java开发，必须保证`ElasticSearch`的版本与Java的核心jar包版本对应！（Java环境保证没错）

**这里在windows上进行安装**

**1、安装**

下载地址：https://www.elastic.co/cn/downloads/

历史版本下载：https://www.elastic.co/cn/downloads/past-releases/

解压即可（尽量将ElasticSearch相关工具放在统一目录下）

**2、熟悉目录**

```shell
bin # 启动文件目录
config # 配置文件目录
    1og4j2 # 日志配置文件
    jvm.options # java虚拟机相关的配置(默认启动占1g内存，内容不够需要自己调整)
    elasticsearch.ym1 # elasticsearch的配置文件! 默认9200端口!跨域配置
1ib # 相关jar包
modules # 功能模块目录
plugins # 插件目录
    ik # 分词器
```

**3、启动**

> 一定要检查自己的java环境是否配置好，然后双击安装好的bin目录下的elasticsearch.bat  
>
> 网址中输入localhost:9200





**安装可视化界面**

```
elasticsearch-head 依赖于nodejs
```

**使用前提**：需要安装nodejs

1、下载地址

https://github.com/mobz/elasticsearch-head

2、安装

解压即可（尽量将ElasticSearch相关工具放在统一目录下）

3、启动

```shell
cd elasticsearch-head 
# 安装依赖 cnpm install
# 启动 npm run start
# 访问 http://localhost:9100/
```

> 存在跨域问题（只有当两个页面同源，才能交互）
>
> 同源（端口，主机，协议三者都相同）
>
> https://blog.csdn.net/qq_38128179/article/details/84956552

**开启跨域（在elasticsearch解压目录config下elasticsearch.yml中添加）**

```shell
# 开启跨域http.cors.enabled: true
# 所有人访问http.cors.allow-origin: "*"
```

> 重启elasticsearch

**再次连接**

**如何理解上图：**

> - 如果你是初学者
>   - 索引 可以看做 “数据库”
>   - 类型 可以看做 “表”
>   - 文档 可以看做 “库中的数据（表中的行）”
> - 这个head，我们只是把它当做可视化数据展示工具，之后所有的查询都在kibana中进行
>   - 因为不支持json格式化，不方便





**安装kibana**

Kibana是一个针对ElasticSearch的开源分析及可视化平台,用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana ,可以通过各种图表进行高级数据分析及展示。Kibana让海量数据更容易理解。它操作简单,基于浏览器的用户界面可以快速创建仪表板(  dashboard  )实时显示Elasticsearch查询动态。设置Kibana非常简单。无需编码或者额外的基础架构,几分钟内就可以完成Kibana安装并启动Elasticsearch索引监测。

**1、下载地址:**

> 下载的版本需要与ElasticSearch版本对应

https://www.elastic.co/cn/downloads/

历史版本下载：https://www.elastic.co/cn/downloads/past-releases/

**2、安装**

解压即可（尽量将ElasticSearch相关工具放在统一目录下）

**3、启动**

点击bin目录下的kibana.bat

**访问**

```
localhost:5601
```

**4、开发工具**

（Postman、curl、head、谷歌浏览器插件）

> 也可以使用 `Kibana`进行测试
>
> 查询语句写在设置按钮的Console中

> 如果说，你在英文方面不太擅长，kibana是支持汉化的

**5、kibana汉化**

编辑器打开`kibana解压目录/config/kibana.yml`，添加

```
i18n.locale: "zh-CN"
```

> 重启kibana

**汉化成功**



**了解ELK**

- ELK是Elasticsearch、Logstash、 Kibana三大开源框架首字母大写简称。市面上也被成为Elastic Stack。
  - 其中Elasticsearch是一个基于Lucene、分布式、通过Restful方式进行交互的近实时搜索平台框架。
    - 像类似百度、谷歌这种大数据全文搜索引擎的场景都可以使用Elasticsearch作为底层支持框架，可见Elasticsearch提供的搜索能力确实强大,市面上很多时候我们简称Elasticsearch为es。
  - Logstash是ELK的中央数据流引擎,用于从不同目标(文件/数据存储/MQ )收集的不同格式数据,经过过滤后支持输出到不同目的地(中间件/MQ/redis/elasticsearch/kafka等)。
  - Kibana可以将elasticsearch的数据通过友好的页面展示出来 ,提供实时分析的功能。
- 市面上很多开发只要提到ELK能够一致说出它是一个日志分析架构技术栈总称 ,但实际上ELK不仅仅适用于日志分析,它还可以**支持其它任何数据分析和收集的场景**,日志分析和收集只是更具有代表性。并非唯一性。

```
收集清洗数据(Logstash) ==> 搜索、存储(ElasticSearch) ==> 展示(Kibana)
```

![img](F:\markdown笔记\ElasticSearch/20201124224044.png)







**三、ElasticSearch核心概念**

**概述**

> ElasticSearch是**面向文档**，关系行数据库和ElasticSearch客观对比！**一切都是JSON！**

| Relational DB mysql | ElasticSearch          |
| ------------------- | ---------------------- |
| 数据库（database）  | 索引（indices）        |
| 表（tables）        | types \<慢慢会被弃用!> |
| 行（rows）          | documents              |
| 字段（columns）     | fields                 |

**elasticsearch（集群）**中可以包含多个**索引（数据库）** ,每个索引中可以包含多个**类型（表）** ,每个类型下又包含多个**文档（行）** ,每个文档中又包含多个**字段（列）**。

> **物理设计:**
>
> elasticsearch在后台把**每个索引划分成多个分片**，每份分片可以在集群中的不同服务器间迁移
>
> **启动的ElasticSearch服务，默认就是一个集群，且默认集群名为elasticsearch**
>
> **逻辑设计:**
>
> 一个索引类型中，包含多个文档，比如说文档1，文档2。当我们索引一篇文档时，可以通过这样的顺序找到它：索引 => 类型 => 文档ID ，通过这个组合我们就能索引到某个具体的文档。 注意：ID不必是整数，实际上它是个字符串。



> **文档（”行“）**
>
> 之前说elasticsearch是面向文档的，那么就意味着**索引和搜索数据的最小单位是文档**，elasticsearch中，文档就是一条条数据，有几个重要属性:
>
> - 自我包含，一篇文档同时包含字段和对应的值，也就是同时包含key:value !
> - 可以是层次型的，一个文档中包含自文档，复杂的逻辑实体就是这么来的! {就是一个json对象}
> - 灵活的结构，文档不依赖预先定义的模式，我们知道关系型数据库中，要提前定义字段才能使用，在elasticsearch中，对于字段是非常灵活的，有时候,我们可以忽略该字段，或者动态的添加一个新的字段。
>
> 尽管我们可以随意的新增或者忽略某个字段，但是，每个字段的类型非常重要，比如一个年龄字段类型，可以是字符串也可以是整形。因为elasticsearch会保存字段和类型之间的映射及其他的设置。这种映射具体到每个映射的每种类型，这也是为什么在elasticsearch中，类型有时候也称为映射类型。





> **类型（“表”）**
>
> 类型是文档的逻辑容器，就像关系型数据库一样，表格是行的容器。类型中对于字段的定义称为映射，比如name映射为字符串类型。我们说文档是无模式的，它们不需要拥有映射中所定义的所有字段，比如新增一个字段，那么elasticsearch是怎么做的呢?
>
> - elasticsearch会自动的将新字段加入映射，但是这个字段不确定它是什么类型，elasticsearch就开始猜，如果这个值是18，那么elasticsearch会认为它是整形。但是elasticsearch也可能猜不对，所以最安全的方式就是提前定义好所需要的映射，这点跟关系型数据库殊途同归了，先定义好字段，然后再使用。







> **索引（“库”）**
>
> 索引是映射类型的容器， elasticsearch中的索引是一个非常大的文档集合。 索引存储了映射类型的字段和其他设置。然后它们被存储到了各个分片上了。我们来研究下分片是如何工作的。
>
> **物理设计：节点和分片 如何工作**
>
> 创建新索引
>
> 一个集群至少有一个节点，而一个节点就是一个elasricsearch进程，节点可以有多个索引默认的，如果你创建索引，下图展示索引有个5个分片(primary shard ,又称主分片)构成的，每一个主分片会有一个副本(replica shard，又称复制分片)
>
> ![img](F:\markdown笔记\ElasticSearch/20201124234946.png)
>
> 上图是一个有3个节点的集群，可以看到主分片P和对应的复制分片R都不会在同一个节点内，这样有利于某个节点挂掉了，数据也不至于失。实际上，**一个分片是一个Lucene索引，又因为一个索引被分为多个分片（所以一个ElasticSearch索引包含多个Lucene索引）** ，**一个包含倒排索引的文件目录，倒排索引的结构使得elasticsearch在不扫描全部文档的情况下，就能告诉你哪些文档包含特定的关键字**。
>
> **倒排索引（Lucene索引底层）**
>
> > 简单说就是 按（文章关键字，对应的文档\<0个或多个\>）形式建立索引，根据关键字就可直接查询对应的文档（含关键字的），无需查询每一个文档，如下图
> >
> > 原始数据：文章id：包含关键字   倒排索引： 关键字：文章id
>
> ![img](https://liuyou-images.oss-cn-hangzhou.aliyuncs.com/markdown/20201125003531.png)







> **四、IK分词器(elasticsearch插件)**
>
> > **IK分词器：中文分词器**
>
> 分词：即把一段中文或者别的划分成一个个的关键字，我们在搜索时候会把自己的信息进行分词，会把数据库中或者索引库中的数据进行分词，然后进行一一匹配操作，**默认的中文分词是将每个字看成一个词**（<mark>不使用IK分词器的情况下</mark>），比如“我爱狂神”会被分为”我”，”爱”，”狂”，”神” ，这显然是不符合要求的，所以我们需要安装中文分词器ik来解决这个问题。
>
> **IK提供了两个分词算法**: `ik_smart`和`ik_max_word` ,其中`ik_smart`为**最少切分**, `ik_max_word`为**最细粒度划分**! 
>
> **1、下载**
>
> > 版本要与ElasticSearch版本对应
>
> 下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases
>
> **2、安装**
>
> > 解压到ElasticSearch的plugins目录ik文件夹下
>
> **3、重启ElasticSearch**
>
> > 加载了IK分词器 日志中显示 load plugin[analysis-ik]
>
> **4、查看插件**
>
> ```
> E:\ElasticSearch\elasticsearch-7.6.1\bin>elasticsearch-plugin list
> ```
>
> **5、使用kibana测试**
>
> `ik_smart`：最少切分
>
> ![img](F:\markdown笔记\ElasticSearch/20201125013948.png)
>
> `ik_max_word`：最细粒度划分（穷尽词库的可能）
>
> ![img](F:\markdown笔记\ElasticSearch/20201125014210.png)
>
> > 从上面看，感觉分词都比较正常，但是大多数，分词都满足不了我们的想法，如下例
>
> ![img](F:\markdown笔记\ElasticSearch/20201125015809.png)
>
> > 那么，我们需要手动将该词添加到分词器的词典当中
>
> **6、添加自定义的词添加到扩展字典中**
>
> ```
> elasticsearch目录/plugins/ik/config/IKAnalyzer.cfg.xml
> ```
>
> 打开 `IKAnalyzer.cfg.xml` 文件，扩展字典
>
> ![img](F:\markdown笔记\ElasticSearch/20201125020519.png)
>
> 创建字典文件，添加字典内容
>
> ![img](F:\markdown笔记\ElasticSearch/20201125020802.png)
>
> 重启ElasticSearch，再次使用kibana测试
>
> ![smart](F:\markdown笔记\ElasticSearch/20201125021137.png)
>
> 







> **五、Rest风格说明**
>
> **一种软件架构风格**,而不是标准,只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以**更简洁**，**更有层次**，**更易于实现缓存**等机制。
>
> REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。 Web 应用程序最重要的 REST 原则是，客户端和服务器之间的交互在请求之间是无状态的。从客户端到服务器的每个请求都必须包含理解请求所必需的信息。如果服务器在请求之间的任何时间点重启，客户端不会得到通知。此外，无状态请求可以由任何可用服务器回答，这十分适合云计算之类的环境。客户端可以缓存数据以改进性能。
>
> 在服务器端，应用程序状态和功能可以分为各种资源。资源是一个有趣的概念实体，它向客户端公开。资源的例子有：应用程序对象、数据库记录、算法等等。每个资源都使用 URI(Universal Resource Identifier) 得到一个唯一的地址。所有资源都共享统一的接口，以便在客户端和服务器之间传输状态。使用的是标准的 HTTP 方法，比如 GET、 PUT、 POST 和DELETE。
>
> 在 REST 样式的 Web 服务中，每个资源都有一个地址。资源本身都是方法调用的目
> 标，方法列表对所有资源都是一样的。这些方法都是标准方法，包括 HTTP GET、 POST、PUT、 DELETE，还可能包括 HEAD 和 OPTIONS。简单的理解就是，如果想要访问互联网上的资源，就必须向资源所在的服务器发出请求，请求体中必须包含资源的网络路径， 以及对资源进行的操作(增删改查)。
>
> REST 样式的 Web 服务若有返回结果，大多数以JSON字符串形式返回。
> 
>
> **基本Rest命令说明：**
>
> |      method      |                   url地址                   |          描述          |
> | :--------------: | :-----------------------------------------: | :--------------------: |
> | PUT（创建,修改） |  localhost:9200/索引名称/[类型名称]/文档id  | 创建文档（指定文档id） |
> |   POST（修改）   |      localhost:9200/索引名称/类型名称       | 创建文档（随机文档id)  |
> |   GET（查询）    | localhost:9200/索引名称/[类型名称]/[文档id] |   查询文档通过文档ID   |
> |  DELETE（删除）  | localhost:9200/索引名称/[类型名称]/[文档id] |        删除文档        |
>
> **测试**
>
> 1、创建一个索引test1类型type1添加文档1
>
> ```sql
> PUT /test1/type1/1{  
> 	"name" : "流柚",  
> 	"age" : 18
> }
> ```
>
> ![img](F:\markdown笔记\ElasticSearch/20201201144937.png)
>
> > **2、字段数据类型**
> >
> > - 字符串类型
> >
> >   - text
> >
> >     keyword
> >
> >     - text：支持分词，全文检索,支持模糊、精确查询,不支持聚合,排序操作;text类型的最大支持的字符长度无限制,适合大字段存储；
> >     - keyword：不进行分词，直接索引、支持模糊、支持精确匹配，支持聚合、排序操作。keyword类型的最大支持的长度为—32766个UTF-8类型的字符,可以通过设置ignore_above指定自持字符长度，超过给定长度后的数据将不被索引，无法通过term精确匹配检索返回结果。
> >
> > - 数值型
> >
> >   - long、Integer、short、byte、double、float、**half float**、**scaled float**
> >
> > - 日期类型
> >
> >   - date
> >
> > - 布尔类型
> >
> >   - boolean
> >
> > - 二进制类型
> >
> >   - binary
> >
> > - 等
>
> **3、指定字段的类型（使用PUT）**
>
> > 类似于建库（建立索引和字段对应类型），也可看做规则的建立
>
> ```sql
> PUT /test2{  
> 	"mappings": {    
> 		"properties": {      
> 			"name": {        
> 				"type": "text"      
> 				},      
> 			"age":{        
> 				"type": "long"      
> 			},      
> 			"birthday":{        
> 				"type": "date"      
> 			}    
> 		}  
> 	}
> }
> ```
>
> **4、获取3建立的规则**
>
> ```
> GET test2
> ```
>
> **5、获取默认信息**
>
> > `_doc` 默认类型（default type），type 在未来的版本中会逐渐弃用，因此产生一个默认类型进行代替
>
> ```sql
> PUT /test3/_doc/1{  
>  "name": "流柚",  
>  "age": 18,  
>  "birth": "1999-10-10"
> }
> 
> GET test3 // 查看默认类型
> ```
>
> > 如果自己的文档字段没有被指定，那么ElasticSearch就会给我们默认配置字段类型
>
> 扩展：通过`get  _cat/healt`   `get _cat/indices?v`  可以获取ElasticSearch的当前的很多信息！
>
> **6、修改**
>
> > 两种方案
> >
> > ①旧的（使用put覆盖原来的值）
> >
> > - 版本+1（_version）
> > - 但是如果漏掉某个字段没有写，那么更新是没有写的字段 ，会消失
> >
> > ```mysql
> > PUT /test3/_doc/1{  
> >     "name" : "流柚是我大哥",  
> >     "age" : 18,  
> >     "birth" : "1999-10-10"
> > }
> > 
> > # /_doc/1 修改会有字段丢失 若少字段，eg : age birth丢失
> > PUT /test3/_doc/1{  
> > 	"name" : "流柚"
> > }
> > ```
> >
> > ②新的（使用post的update） 推荐
> >
> > - version加1
> > - 需要注意doc
> > - 不会丢失字段
> >
> > ```sql
> > POST /test3/_doc/1/_update{  
> >     "doc":{    
> >         "name" : "post修改，version加一",    
> >         "age" : 2  
> >     }
> > }
> > GET /test3/_doc/1
> > ```
>
> **7、删除**
>
> ```
> DELETE /test1   # 删除库
> ```
>
> 
>
> **8、查询（简单条件）**
>
> `GET /test3/_doc/1`
>
> `GET /test3/_doc/_search?q=name:流柚`  得看name的类型keyword则完全匹配，text可以分词匹配
>
> **9、复杂查询**
>
> 输出的score：若存在多条匹配，则代表匹配度，越高越好
>
> **①查询匹配**
>
> > - `match`：匹配（会使用分词器解析（先分析文档，然后进行查询））
> > - `_source`：过滤字段
> > - `sort`：排序
> > - `form`、`size` 分页
> >
> > ```sql
> > // 查询匹配  
> > GET /blog/user/_search  {    
> >     "query":{      
> >         "match":{  // 查询的参数体 匹配  
> >         	"name":"流"      
> >         }    
> >     },    
> >     "_source": ["name","desc"], // 过滤字段 只查name 和 desc  结果过滤
> >     "sort": [ // age 升序排列
> >         {        
> >     		"age": {          
> >              	"order": "asc"        
> >         	}      
> >         }    
> >     ],    
> >     "from": 0,  // 从第几条数据开始 类似于limit from,size   
> >     "size": 1  // 限制显示一个
> > }
> > ```
> >
> > ##### ②多条件查询（bool）
> >
> > - `must` 相当于 `and`
> > - `should` 相当于 `or`
> > - `must_not` 相当于 `not (... and ...)`
> > - `filter` 过滤
> >
> > ```sql
> > /// bool 多条件查询
> > //// must <==> and
> > //// should <==> or
> > //// must_not <==> not (... and ...)
> > //// filter数据过滤
> > //// boost
> > //// minimum_should_matchGET 
> > /blog/user/_search{  
> >     "query":{    
> >         "bool": {      
> >             "must": [   // and     
> >                 {          
> >                      "match":{            
> >                          "age":3          
> >                 	 }        
> >                 },        
> >                 {          
> >                      "match": {            
> >                      	"name": "流"         
> >                 	 }        
> >                 }      
> >             ],      
> >             "filter": {        
> >                  "range": {     // 过滤条件 范围     
> >                      "age": {            
> >                      	"gte": 1,     // gt > lt < gte >= lte <=       
> >                     	"lte": 3         
> >                       }        
> >                   }      
> >              }    
> >         }  
> >     }
> > }
> > ```
> >
> > ##### ③匹配数组
> >
> > - 可以多关键字查（空格隔开）— 匹配字段也是符合的
> > - `match` 会使用分词器解析（先分析文档，然后进行查询）
> > - 搜词
> >
> > ```sql
> > // 可以多关键字查（空格隔开）
> > // match 会使用分词器解析
> > GET /blog/user/_search{  
> >     "query":{    
> >         "match":{      
> >             "desc":"年龄 牛 大"    
> >         }  
> >     }
> > }
> > ```
> >
> > ##### ④精确查询
> >
> > - `term` 直接通过 倒排索引 指定**词条**查询
> > - 适合查询 number、date、 text，keyword
> >
> > ```sql
> > // 精确查询（必须全部都有，而且不可分，即按一个完整的词查询）
> > // term 直接通过 倒排索引 指定的词条 进行精确查找
> > GET /blog/user/_search{  
> >     "query":{    
> >         "term":{   // keyword 全部包含且不能多 text 包含即可  
> >         	"desc":"年 "    
> >         }  
> >     }
> > }
> > ```
> >
> > ##### ⑤text和keyword
> >
> > > - text：
> > >   - **支持分词**，**全文检索**、支持模糊、精确查询,不支持聚合,排序操作;
> > >   - text类型的最大支持的字符长度无限制,适合大字段存储；
> > > - keyword：
> > >   - **不进行分词**，**直接索引**、支持模糊、支持精确匹配，支持聚合、排序操作。
> > >   - keyword类型的最大支持的长度为——32766个UTF-8类型的字符,可以通过设置ignore_above指定自持字符长度，超过给定长度后的数据将不被索引。
> >
> > ##### ⑥高亮查询
> >
> > ```sql
> > /// 高亮查询
> > GET blog/user/_search{  
> >     "query": {    
> >         "match": {      
> >         	"name":"流"    
> >         }  
> >     },  
> >     "highlight": {    
> >         "fields": {      
> >         	"name": {}  // name前后加<em> </em> 
> >         }  
> >     }
> > } 
> > 
> > // 自定义前缀和后缀
> > GET blog/user/_search{  
> >     "query": {    
> >         "match": {      
> >         	"name":"流"    
> >         }  
> >     },  
> >     "highlight": {    
> >         "pre_tags": "<p class='key' style='color:red'>",    
> >         "post_tags": "</p>",     
> >         "fields": {     // name前后加<p class='key' style='color:red'> </p>
> >         	"name": {}    
> >         }  
> >     }
> > }
> > ```





**Elasticsearch基本概念**

> **Near Realtime(NRT) 几乎实时**
>
> Elasticsearch是一个几乎实时的搜索平台。意思是，从索引一个文档到这个文档可被搜索只需要一点点的延迟，这个时间一般为毫秒级。
>
> **单机 & 集群**
>
> 单台 Elasticsearch 服务器提供服务，往往都有最大的负载能力，超过这个阈值，服务器性能就会大大降低甚至不可用，所以生产环境中，一般都是运行在指定服务器集群中。除了负载能力，单点服务器也存在其他问题：
>
>     单台机器存储容量有限
>     单服务器容易出现单点故障，无法实现高可用
>     单服务的并发处理能力有限
>
> 配置服务器集群时，集群中节点数量没有限制，大于等于 2 个节点就可以看做是集群了。一般出于高性能及高可用方面来考虑集群中节点数量都是 3 个以上。总之，集群能提高性能，增加容错。
>
> ```shell
> # 复制三个文件
> 修改集群文件目录中每个节点的 config/elasticsearch.yml 配置文件
> 
> node-1001 节点
> # 节点 1 的配置信息：
> # 集群名称，节点之间要保持一致
> cluster.name: my-elasticsearch
> # 节点名称，集群内要唯一
> node.name: node-1001
> node.master: true
> node.data: true
> # ip 地址
> network.host: localhost
> # http 端口
> http.port: 1001
> # tcp 监听端口
> transport.tcp.port: 9301
> # discovery.seed_hosts: ["localhost:9301", "localhost:9302","localhost:9303"]
> # discovery.zen.fd.ping_timeout: 1m
> # discovery.zen.fd.ping_retries: 5
> # 集群内的可以被选为主节点的节点列表
> # cluster.initial_master_nodes: ["node-1", "node-2","node-3"]
> # 跨域配置
> # action.destructive_requires_name: true
> http.cors.enabled: true
> http.cors.allow-origin: "*"
> 
> 
> 
> node-1002 节点
> # 节点 2 的配置信息：
> # 集群名称，节点之间要保持一致
> cluster.name: my-elasticsearch
> # 节点名称，集群内要唯一
> node.name: node-1002
> node.master: true
> node.data: true
> # ip 地址
> network.host: localhost
> # http 端口
> http.port: 1002
> # tcp 监听端口
> transport.tcp.port: 9302
> # 找主机
> discovery.seed_hosts: ["localhost:9301"]
> discovery.zen.fd.ping_timeout: 1m
> discovery.zen.fd.ping_retries: 5
> # 集群内的可以被选为主节点的节点列表
> # cluster.initial_master_nodes: ["node-1", "node-2","node-3"]
> # 跨域配置
> # action.destructive_requires_name: true
> http.cors.enabled: true
> http.cors.allow-origin: "*"
> 
> 
> 
> node-1003 节点
> # 节点 3 的配置信息：
> # 集群名称，节点之间要保持一致
> cluster.name: my-elasticsearch
> # 节点名称，集群内要唯一
> node.name: node-1003
> node.master: true
> node.data: true
> # ip 地址
> network.host: localhost
> # http 端口
> http.port: 1003
> # tcp 监听端口
> transport.tcp.port: 9303
> # 候选主节点的地址，在开启服务后可以被选为主节点
> discovery.seed_hosts: ["localhost:9301", "localhost:9302"]
> discovery.zen.fd.ping_timeout: 1m
> discovery.zen.fd.ping_retries: 5
> # 集群内的可以被选为主节点的节点列表
> # cluster.initial_master_nodes: ["node-1", "node-2","node-3"]
> # 跨域配置
> # action.destructive_requires_name: true
> http.cors.enabled: true
> http.cors.allow-origin: "*"
> 
> 
> 三、如果有必要，删除每个节点中的 data 目录中所有内容 。
> # 查看集群状态
> GET http://127.0.0.1:1001/_cluster/health
> 
> status字段指示着当前集群在总体上是否工作正常。它的三种颜色含义如下：
> green：所有的主分片和副本分片都正常运行。
> yellow：所有的主分片都正常运行，但不是所有的副本分片都正常运行。
> red：有主分片没能正常运行。
> ```
>
> **Cluster 集群**
>
> 集群中包含很多服务器， 一个节点就是其中的一个服务器。 作为集群的一部分，它存储数据，参与集群的索引和搜索功能。集群是一个或多个节点（服务器）的集合，  这些节点共同保存整个数据，并在所有节点上提供联合索引和搜索功能。一个集群由一个唯一集群ID确定，并指定一个集群名（默认为“elasticsearch”）。该集群名非常重要，因为节点可以通过这个集群名加入集群，一个节点只能是集群的一部分。
>
> 确保在不同的环境中不要使用相同的群集名称，否则可能会导致连接错误的群集节点。例如，你可以使用logging-dev、logging-stage、logging-prod分别为开发、阶段产品、生产集群做记录。
>
> **Node节点**
>
> 节点是单个服务器实例，它是集群的一部分，可以存储数据，并参与集群的索引和搜索功能。就像一个集群，节点的名称默认为一个随机的通用唯一标识符（UUID），确定在启动时分配给该节点。如果不希望默认，可以定义任何节点名。这个名字对管理很重要，目的是要确定你的网络服务器对应于你的ElasticSearch集群节点。
>
> 我们可以通过集群名配置节点以连接特定的群集。默认情况下，每个节点设置加入名为“elasticSearch”的集群。这意味着如果你启动多个节点在网络上，假设他们能发现彼此都会自动形成和加入一个名为“elasticsearch”的集群。在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何 Elasticsearch 节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。
>
> **Index索引** 库
>
> 索引是具有相似特性的文档集合。例如，可以为客户数据提供索引，为产品目录建立另一个索引，以及为订单数据建立另一个索引。索引由名称（必须全部为小写）标识，该名称用于在对其中的文档执行索引、搜索、更新和删除操作时引用索引。在单个群集中，你可以定义尽可能多的索引。
>
> **Type类型** 表
>
> 在索引中，可以定义一个或多个类型。类型是索引的逻辑类别/分区，其语义完全取决于你。一般来说，类型定义为具有公共字段集的文档。例如，假设你运行一个博客平台，并将所有数据存储在一个索引中。在这个索引中，你可以为用户数据定义一种类型，为博客数据定义另一种类型，以及为注释数据定义另一类型。
>
> **Document文档** 记录
>
> 文档是可以被索引的信息的基本单位。例如，你可以为单个客户提供一个文档，单个产品提供一个文档，以及单个订单提供另一个文档。本文件的表示形式为JSON（JavaScript Object Notation）格式，这是一种非常普遍的互联网数据交换格式。
>
> 在索引/类型中，你可以存储尽可能多的文档。文档实际上必须分配到索引或分配到索引中的类型中。
>
> **字段Field**
>
> 相当于是数据表的字段，对文档数据根据不同属性进行的分类标识，json的属性。
>
> **映射Mapping**
>
> mapping 是处理数据的方式和规则方面做一些限制，如：某个字段的数据类型、默认值、分析器、是否被索引等等。这些都是映射里面可以设置的，其它就是处理 ES 里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。
>
> **Shards & Replicas分片(分表)与副本**
>
> 索引可以存储大量的数据，这些数据可能超过单个节点的硬件限制。
>
> 为了解决这一问题，Elasticsearch提供细分你的指标分成多个块称为分片的能力。当你创建一个索引，你可以简单地定义你想要的分片数量。每个分片本身是一个全功能的、独立的“指数”，可以托管在集群中的任何节点。
>
> **Shards分片的重要性主要体现在以下两个特征：**
>
> 1. 分片允许你水平拆分或缩放内容的大小
> 2. 分片允许你分配和并行操作的碎片（可能在多个节点上）从而提高性能/吞吐量 这个机制中的碎片是分布式的以及其文件汇总到搜索请求是完全由ElasticSearch管理，对用户来说是透明的。
>
> 在同一个集群网络或云环境上，故障是任何时候都会出现的，拥有一个故障转移机制以防分片和节点因为某些原因离线或消失是非常有用的，并且被强烈推荐。为此，Elasticsearch允许你创建一个或多个拷贝，你的索引分片进入所谓的副本或称作复制品的分片，简称Replicas。
>
> **Replicas的重要性主要体现在以下两个特征：**
>
> 1. 副本为分片或节点失败提供了高可用性。为此，需要注意的是，一个副本的分片不会分配在同一个节点作为原始的或主分片，副本是从主分片那里复制过来的。
>
> 2. 副本允许用户扩展你的搜索量或吞吐量，因为搜索可以在所有副本上并行执行。
>
>    每个索引可以被分成多个分片。一个索引也可以被复制 0 次或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。
>
>    分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。
>
>    默认情况下，Elasticsearch 中的每个索引被分片为 1 个主分片和 1 个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有 1 个主分片和另外 1 个复制分片，这样的话每个索引总共就有 2 个分片。

> **分配Allocation**
>
> 将分片分配给某个节点的过程，包括分配主分片或者副本。如果是副本，还包含从主分片复制数据的过程。这个过程是由 master 节点完成的。



**选取master节点管理整个集群**

> 一个运行中的 Elasticsearch 实例称为一个节点，而集群是由一个或者多个拥有相同cluster.name 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。
>
> 当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。
>
> 作为用户，我们可以将请求发送到集群中的任何节点 ，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。



**三个分片三个副本**

> **故障转移**
>
> 当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 cluster.name 配置，它就会自动发现集群并加入到其中。但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。之所以配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。如果启动了第二个节点，集群将会拥有两个节点 : 所有主分片和副本分片都已被分配 。
>
> 
>
> **水平扩容**
>
> 怎样为我们的正在增长中的应用程序按需扩容呢？当启动了第三个节点，我们的集群将会拥有三个节点的集群 : 为了分散负载而对分片进行重新分配 。
>
> 但是如果我们想要扩容超过 6 个节点怎么办呢？主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够存储的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片或副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 1 增加到 2。
>
> ```json
> PUT http://127.0.0.1:1001/users/_settings
> {
>     "number_of_replicas" : 2
> }
> ```
>
> users 索引现在拥有 9 个分片： 3 个主分片和 6 个副本分片。 这意味着我们可以将集群扩容到 9 个节点，每个节点上一个分片。相比原来 3 个节点时，集群搜索性能可以提升 3 倍。
>
> 当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。
>
> 更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去 2 个节点的情况下不丢失任何数据。
>
> 
>
> **应对故障** 三个节点 三个主 六个复
>
> 我们关闭第一个节点，这时集群的状态为:关闭了一个节点后的集群。我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： Node 2 。在我们关闭 Node 1 的同时也失去了主分片 1 和 2 ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 red ：不是所有主分片都在正常工作。
>
> 幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 Node 2 和 Node 3 上对应的副本分片提升为主分片， 此时集群的状态将会为yellow。这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。
>
> 为什么我们集群状态是 yellow 而不是 green 呢？
>
> 虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应 2 份副本分片，而此时只存在一份副本分片。 所以集群不能为 green 的状态，不过我们不必过于担心：如果我们同样关闭了 Node 2 ，我们的程序依然可以保持在不丢任何数据的情况下运行，因为Node 3 为每一个分片都保留着一份副本。如果想恢复原来的样子，要确保Node-1的配置文件有如下配置：
>
> `discovery.seed_hosts: ["localhost:9302", "localhost:9303"]`
>
> 集群可以将缺失的副本分片再次进行分配，那么集群的状态也将恢复成之前的状态。 如果 Node 1 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。和之前的集群相比，只是 Master 节点切换了。
>
> 
>
> **路由计算 & 分片控制**
>
> **路由计算**
>
> 当索引一个文档的时候，文档会被存储到一个主分片中。 Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？当我们创建文档时，它如何决定这个文档应当被存储在分片 1 还是分片 2 中呢？首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：
>
> `shard = hash(routing) % number_of_primary_shards`
>
> routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。routing 通过hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。
>
> 这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。
>
> **分片控制**
>
> 所有的文档API都接受一个叫做routing 的路由参数，通过这个参数我们可以自定义文档到分片的映射。一个自定义的路由参数可以用来确保所有相关的文档——例如所有属于同一个用户的文档——都被存储到同一个分片中。
>
> 
>
> **数据写流程**
>
> 我们可以发送请求到集群中的任一节点(协调节点)。每个节点都有能力处理任意请求。每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上。当发送请求的时候， 为了扩展负载，更好的做法是轮询集群中所有的节点。
>
> 发送请求到集群中的任一节点，节点收到请求后计算处理的节点，处理节点的主分片保存数据，并发送给副本，副本保存后反馈，主分片反馈，客户端获取反馈。
>
> 新建、索引和删除请求都是写操作， 必须在主分片上面完成之后才能被复制到相关的副本分片。在客户端收到成功响应时，文档变更已经在主分片和所有副本分片执行完成，变更是安全的。有一些可选的请求参数允许您影响这个过程，可能以数据安全为代价提升性能。这些选项很少使用，因为 Elasticsearch 已经很快了，但是为了完整起见， 请参考下文：
>
> ```shell
> consistency
> # 即一致性。在默认设置下，即使仅仅是在试图执行一个写操作之前，主分片都会要求必须要有规定数量quorum的分片副本处于活跃可用状态，才会去执行写操作（其中分片副本，可以是主分片或者副本分片）。这是为了避免在发生网络分区故障（network partition）的时候进行写操作，进而导致数据不一致。 规定数量即： int((primary+number_of_replicas) / 2 ) + 1
> consistency 参数的值可以设为：
>     one ：只要主分片状态 ok 就允许执行写操作。
>     all：必须要主分片和所有副本分片的状态没问题才允许执行写操作。
>     quorum：默认值为quorum , 即大多数的分片副本状态没问题就允许执行写操作。
> # 注意，规定数量的计算公式中number_of_replicas指的是在索引设置中的设定副本分片数，而不是指当前处理活动状态的副本分片数。如果你的索引设置中指定了当前索引拥有3个副本分片，那规定数量的计算结果即：int((1 (primary) + 3 (replicas)) / 2) + 1 = 3，如果此时你只启动两个节点，那么处于活跃状态的分片副本数量就达不到规定数量，也因此您将无法索引和删除任何文档。
> 
> 
> timeout
>     # 如果没有足够的副本分片会发生什么？Elasticsearch 会等待，希望更多的分片出现。默认情况下，它最多等待1分钟。 如果你需要，你可以使用timeout参数使它更早终止：100是100毫秒，30s是30秒。
> ```
>
> 新索引默认有1个副本分片，这意味着为满足规定数量应该需要两个活动的分片副本。 但是，这些默认的设置会阻止我们在单一节点上做任何事情。为了避免这个问题，要求只有当number_of_replicas 大于1的时候，规定数量才会执行。
>
> 
>
> **数据读流程**
>
> 在处理读取请求时，客户端发送查询请求到协调节点，协调结点计算分片及副本位置，在每次请求的时候都会通过**轮询所有的分片及副本**来达到负载均衡。在文档被检索时，已经被索引的文档可能已经存在于主分片上但是还没有复制到副本分片。 在这种情况下，副本分片可能会报告文档不存在，但是主分片可能成功返回文档。 
>
> 
>
> **更新流程 & 批量操作流程**
>
> **更新流程**
>
> 部分更新一个文档结合了先前说明的读取和写入流程：部分更新一个文档的步骤如下：
>
>     1 客户端向Node 1发送更新请求。
>     2 Node 1将请求转发到主分片所在的Node 3 。
>     3 Node 3从主分片检索文档，修改_source字段中的JSON，并且尝试重新索引主分片的文档。如果文档已经被另一个进程修改,它会重试步骤3 ,超过retry_on_conflict次后放弃。
>     4 如果 Node 3成功地更新文档，它将新版本的文档并行转发到Node 1 和Node 2上的副本片，重新建立索引。一旦所有副本分片都返回成功，Node 3向协调节点也返回成功，协调节点向客户端返回成功。
>
> 当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。请记住，这些更改将会异步转发到副本分片，并且不能保证它们以发送它们相同的顺序到达。 如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。
>
> **批量操作流程**
>
> **mget和 bulk API的模式类似于单文档模式。**区别在于协调节点知道每个文档存在于哪个分片中。它将整个多文档请求分解成每个分片的多文档请求，并且将这些请求并行转发到每个参与节点。
>
> 协调节点一旦收到来自每个节点的应答，就将每个节点的响应收集整理成单个响应，返回给客户端。
>
> 用单个 mget 请求取回多个文档所需的步骤顺序:
>
>     1 客户端向 Node 1 发送 mget 请求。
>     2 Node 1为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复，Node 1 构建响应并将其返回给客户端。
>
> 
>
> **倒排索引**
>
> > 词条：索引中最小存储和查询单位
> >
> > 词典：词条的集合，B+树和哈希树实现
> >
> > 倒排表：词条找文档id，id找文档内容
>
> 分片是Elasticsearch最小的工作单元。但是究竟什么是一个分片，它是如何工作的？
>
> 传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值的能力。最好的支持是一个字段多个值需求的数据结构是倒排索引。
>
> 倒排索引原理
>
> Elasticsearch使用一种称为倒排索引的结构，它适用于快速的全文搜索。
>
> 见其名，知其意，有倒排索引，肯定会对应有正向索引。
>
> 所谓的正向索引，就是搜索引擎会将待搜索的文件都对应一个文件ID，搜索时将这个ID和搜索关键字进行对应，形成K-V对，然后对关键字进行统计计数。
>
> 但是互联网上收录在搜索引擎中的文档的数目是个天文数字，这样的索引结构根本无法满足实时返回排名结果的要求。所以，搜索引擎会将正向索引重新构建为倒排索引，即把文件ID对应到关键词的映射转换为关键词到文件ID的映射，每个关键词都对应着一系列的文件，这些文件中都出现这个关键词。
>
> 我们目前的倒排索引有一些问题：
>
>     Quick和quick以独立的词条出现，然而用户可能认为它们是相同的词。
>     fox和foxes非常相似，就像dog和dogs；他们有相同的词根。
>     jumped和leap，尽管没有相同的词根，但他们的意思很相近。他们是同义词。
>
> 使用前面的索引搜索+Quick +fox不会得到任何匹配文档。(记住，＋前缀表明这个词必须存在）。
>
> 如果我们将词条规范为标准模式，那么我们可以找到与用户搜索的词条不完全一致，但具有足够相关性的文档。例如：
>
>     Quick可以小写化为quick。
>     foxes可以词干提取变为词根的格式为fox。类似的，dogs可以为提取为dog。
>     jumped和leap是同义词，可以索引为相同的单词jump 。
>
> 所以，分词和标准化的过程称为分析，这非常重要。你只能搜索在索引中出现的词条，所以索引文本和查询字符串必须标准化为相同的格式。
>
> 
>
> **文档搜索**
>
> **不可改变的倒排索引**
>
> 早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。
>
> 倒排索引被写入磁盘后是不可改变的：它永远不会修改。
>
>     不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。
>     
>     一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。
>     
>     其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。
>     
>     写入单个大的倒排索引允许数据被压缩，减少磁盘IO和需要被缓存到内存的索引的使用量。
>
> 当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。
>
> **动态更新索引**
>
> 如何在保留不变性的前提下实现倒排索引的更新？
>
> 答案是：用更多的索引。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到,从最早的开始查询完后再对结果进行合并。
>
> Elasticsearch基于Lucene，这个java库引入了**按段搜索**的概念。每一段本身都是一个倒排索引。
>
> 按段搜索会以如下流程执行：
>
> 一、新文档被收集到内存索引缓存。
>
> 二、不时地, 缓存被提交。
>
>     一个新的段，一个追加的倒排索引，被写入磁盘。
>     一个新的包含新段名字的提交点被写入磁盘。
>     磁盘进行同步，所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件
>
> 三、新的段被开启，让它包含的文档可见以被搜索。
>
> 四、内存缓存被清空，等待接收新的文档。
>
> 当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。这种方式可以用相对较低的成本将新文档添加到索引。
>
> 段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个.del 文件，文件中会列出这些被删除文档的段信息。
>
> 当一个**文档被“删除”**时，它实际上只是在 .del 文件中被标记删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。
>
> 文档更新也是类似的操作方式:当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。
>
> 
>
> **文档刷新 & 文档刷写 & 文档合并**
>
> **近实时搜索**
>
> 随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。磁盘在这里成为了瓶颈。提交（Commiting）一个新的段到磁盘需要一个fsync来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。但是fsync操作代价很大；如果每次索引一个文档都去执行一次的话会造成很大的性能问题。
>
> 我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着fsync要从整个过程中被移除。在Elasticsearch和磁盘之间是文件系统缓存。像之前描述的一样，在内存索引缓冲区中的文档会被写入到一个新的段中。但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中，就可以像其它文件一样被打开和读取了。
>
> Lucene允许新段被写入和打开，使其包含的文档在未进行一次完整提交时便对搜索可见。这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。
>
> 在 Elasticsearch 中，**写入和打开一个新段**的轻量的过程叫做**refresh**。默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch是近实时搜索：**文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。**
>
> 这些行为可能会对新用户造成困惑：他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用refresh API执行一次手动刷新：`/usersl_refresh`
>
> 尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候，手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。相反，你的应用需要意识到Elasticsearch 的近实时的性质，并接受它的不足。
>
> 并不是所有的情况都需要每秒刷新。可能你正在使用Elasticsearch索引大量的日志文件，你可能**想优化索引速度而不是近实时搜索**，可以通过设置refresh_interval ，降低每个索引的刷新频率
>
> ```
> {
>     "settings": {
>     	"refresh_interval": "30s"
>     }
> }
> ```
>
> refresh_interval可以在既存索引上进行动态更新。在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来。
>
> **关闭自动刷新**
>
> ```
> PUT /users/_settings{ 
> 	"refresh_interval": -1 
> }
> ```
>
> **每一秒刷新**
>
> ```
> PUT /users/_settings{ 
> 	"refresh_interval": "1s" 
> }
> ```
>
> 
>
> **持久化变更**
>
> 如果没有用fsync把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。在动态更新索引，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。
>
> 即使通过每秒刷新(refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办?我们也不希望丢失掉这些数据。Elasticsearch 增加了一个translog ，或者叫事务日志，在每一次对Elasticsearch进行操作时均进行了日志记录。仅在translog进行了fsync和commit后，传输日志中的数据才会持久保存到磁盘 。如果发生硬件故障，操作系统崩溃，JVM崩溃或分片故障，则自上一个translog commit以来写入的所有数据都将丢失。
>
> 整个流程如下:
>
> 一、一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog
>
> 二、刷新（refresh）使分片每秒被刷新（refresh）一次：
>
>     这些在内存缓冲区的文档被写入到一个新的段中，且没有进行fsync操作。
>     这个段被打开，使其可被搜索。
>     内存缓冲区被清空。
>
> 三、这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志。
>
> 四、每隔一段时间—例如translog变得越来越大，索引被刷新（flush）；一个新的translog被创建，并且一个全量提交被执行。
>
>     所有在内存缓冲区的文档都被写入一个新的段。
>     缓冲区被清空。
>     一个提交点被写入硬盘。
>     文件系统缓存通过fsync被刷新（flush） 。
>     老的translog被删除。
>
> translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当Elasticsearch启动的时候，它会从磁盘中使用最后一个提交点去恢复己知的段，并且会重放translog 中所有在最后一次提交后发生的变更操作。
>
> translog 也被用来提供实时CRUD。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查 translog任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。
>
> 执行一个提交并且截断translog 的行为在 Elasticsearch被称作一次flush。分片每30分钟被自动刷新（flush)，或者在 translog 太大的时候也会刷新。
>
> 你很少需要自己手动执行flush操作，通常情况下，自动刷新就足够了。这就是说，在重启节点或关闭索引之前执行 flush有益于你的索引。当Elasticsearch尝试恢复或重新打开一个索引，它需要重放translog中所有的操作，所以如果日志越短，恢复越快。
>
> translog 的目的是保证操作不会丢失，在文件被fsync到磁盘前，被写入的文件在重启之后就会丢失。
>
> 但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次 fsync 。如果你决定使用异步translog 的话，你需要保证在发生 crash 时，丢失掉 sync_interval时间段的数据也无所谓。请在决定前知晓这个特性。如果你不确定这个行为的后果，最好是使用默认的参数`{“index.translog.durability”: “request”}`来避免数据丢失。
>
> ![screenshot_20220108_231558](F:\markdown笔记\ElasticSearch\screenshot_20220108_231558.png)
>
> **段合并**
>
> 由于自动刷新流程每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。每一个段都会消耗文件句柄、内存和 cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。
>
> Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。
>
> 段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。
>
> 启动段合并不需要你做任何事。进行索引和搜索时会自动进行。
>
> 一、当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。
>
> 二、合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。
>
> 三、一旦合并结束，老的段被删除
>
>     新的段被刷新(flush)到了磁盘。
>     写入一个包含新段且排除旧的和较小的段的新提交点。
>     新的段被打开用来搜索。老的段被删除。
>
> 合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。 Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。
>
> 
>
> **文档分析**
>
> 分析包含下面的过程：
>
>     将一块文本分成适合于倒排索引的独立的词条。
>     将这些词条统一化为标准格式以提高它们的“可搜索性”，或者recall。
>
> 分析器执行上面的工作。分析器实际上是将三个功能封装到了一个包里：
>
>     字符过滤器：首先，字符串按顺序通过每个字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉HTML，或者将&转化成and。
>     
>     分词器：其次，字符串被分词器分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。
>     
>     Token过滤器：最后，词条按顺序通过每个token过滤器 。这个过程可能会改变词条（例如，小写化Quick ），删除词条（例如， 像 a， and， the 等无用词），或者增加词条（例如，像jump和leap这种同义词）
>
> **内置分析器**
>
> Elasticsearch还附带了可以直接使用的预包装的分析器。接下来我们会列出最重要的分析器。为了证明它们的差异，我们看看每个分析器会从下面的字符串得到哪些词条：
>
> `"Set the shape to semi-transparent by calling set_trans(5)"`
>
> **标准分析器**
>
> 标准分析器是Elasticsearch 默认使用的分析器。它是分析各种语言文本最常用的选择。它根据Unicode 联盟定义的单词边界划分文本。删除绝大部分标点。最后，将词条小写。它会产生：
>
> `set, the, shape, to, semi, transparent, by, calling, set_trans, 5`
>
> **简单分析器**
>
> 简单分析器在任何不是字母的地方分隔文本，将词条小写。它会产生：
>
> `set, the, shape, to, semi, transparent, by, calling, set, trans`
>
> **空格分析器**
>
> 空格分析器在空格的地方划分文本。它会产生:
>
> `Set, the, shape, to, semi-transparent, by, calling, set_trans(5)`
>
> **语言分析器**
>
> 特定语言分析器可用于很多语言。它们可以考虑指定语言的特点。例如，英语分析器附带了一组英语无用词（常用单词，例如and或者the ,它们对相关性没有多少影响），它们会被删除。由于理解英语语法的规则，这个分词器可以提取英语单词的词干。
>
> 英语分词器会产生下面的词条：
>
> `set, shape, semi, transpar, call, set_tran, 5`
>
> `注意看transparent、calling和 set_trans已经变为词根格式。`
>
> **分析器使用场景**
>
> 当我们索引一个文档，它的全文域被分析成词条以用来创建倒排索引。但是，当我们在全文域搜索的时候，我们需要将查询字符串通过相同的分析过程，以保证我们搜索的词条格式与索引中的词条格式一致。
>
> **全文查询**，理解每个域是如何定义的，因此它们可以做正确的事：
>
>     当你查询一个全文域时，会对查询字符串应用相同的分析器，以产生正确的搜索词条列表。
>     当你查询一个精确值域时，不会分析查询字符串，而是搜索你指定的精确值。
>
> **测试分析器**
>
> 有些时候很难理解分词的过程和实际被存储到索引中的词条，特别是你刚接触Elasticsearch。为了理解发生了什么，你可以使用analyze API来看文本是如何被分析的。在消息体里，指定分析器和要分析的文本。
>
> ```sql
> GET http://localhost:9200/_analyze{
>     "analyzer": "standard",
>     "text": "Text to analyze"
> }
> ```
>
> 结果中每个元素代表一个单独的词条：
>
> ```sql
> {
>     "tokens": [
>         {
>             "token": "text", 
>             "start_offset": 0, 
>             "end_offset": 4, 
>             "type": "<ALPHANUM>", 
>             "position": 1
>         }, 
>         {
>             "token": "to", 
>             "start_offset": 5, 
>             "end_offset": 7, 
>             "type": "<ALPHANUM>", 
>             "position": 2
>         }, 
>         {
>             "token": "analyze", 
>             "start_offset": 8, 
>             "end_offset": 15, 
>             "type": "<ALPHANUM>", 
>             "position": 3
>         }
>     ]
> }
> ```
>
> 当Elasticsearch在你的文档中检测到一个新的字符串域，它会自动设置其为一个全文字符串域，使用标准分析器对它进行分析。你不希望总是这样。可能你想使用一个不同的分析器，适用于你的数据使用的语言。有时候你想要一个字符串域就是一个字符串域，不使用分析，直接索引你传入的精确值，例如用户 ID 或者一个内部的状态域或标签。要做到这一点，我们必须手动指定这些域的映射。
>
> 
>
> 
>
> **IK分词器** 细粒度指定分析器
>
> 首先通过 Postman 发送 GET 请求查询分词效果
>
> ```sqlite
> GET http://localhost:9200/_analyze{
> 	"text":"测试单词"
> }
> ```
>
> ES 的默认分词器无法识别中文测试、 单词这样的词汇，而是简单的将每个字拆完分为一个词。
>
> ```sql
> {
>     "tokens": [
>         {
>             "token": "测", 
>             "start_offset": 0, 
>             "end_offset": 1, 
>             "type": "<IDEOGRAPHIC>", 
>             "position": 0
>         }, 
>         {
>             "token": "试", 
>             "start_offset": 1, 
>             "end_offset": 2, 
>             "type": "<IDEOGRAPHIC>", 
>             "position": 1
>         }, 
>         {
>             "token": "单", 
>             "start_offset": 2, 
>             "end_offset": 3, 
>             "type": "<IDEOGRAPHIC>", 
>             "position": 2
>         }, 
>         {
>             "token": "词", 
>             "start_offset": 3, 
>             "end_offset": 4, 
>             "type": "<IDEOGRAPHIC>", 
>             "position": 3
>         }
>     ]
> }
> ```
>
> 这样的结果显然不符合我们的使用要求，所以我们需要下载 ES 对应版本的中文分词器。IK 中文分词器
>
> 
>
> 加入新的查询参数"analyzer":“ik_max_word”。
>
> ```sql
> GET http://localhost:9200/_analyze{
> 	"text":"测试单词",
> 	"analyzer":"ik_max_word"
> }
> ```
>
> 使用中文分词后的结果为：
>
> ```sql
> {
>     "tokens": [
>         {
>             "token": "测试", 
>             "start_offset": 0, 
>             "end_offset": 2, 
>             "type": "CN_WORD", 
>             "position": 0
>         }, 
>         {
>             "token": "单词", 
>             "start_offset": 2, 
>             "end_offset": 4, 
>             "type": "CN_WORD", 
>             "position": 1
>         }
>     ]
> }
> 
> 
> ```
>
> ES 中也可以进行扩展词汇，首先查询
>
> ```sql
> GET http://localhost:9200/_analyze{
>     "text":"弗雷尔卓德",
>     "analyzer":"ik_max_word"
> }
> ```
>
> 仅仅可以得到每个字的分词结果，我们需要做的就是使分词器识别到弗雷尔卓德也是一个词语。
>
>
> ```html
> <!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
> <properties>
> 	<comment>IK Analyzer 扩展配置</comment>
> 	<!--用户可以在这里配置自己的扩展字典 -->
> 	<entry key="ext_dict">custom.dic</entry>
> 	 <!--用户可以在这里配置自己的扩展停止词字典-->
> 	<entry key="ext_stopwords"></entry>
> 	<!--用户可以在这里配置远程扩展字典 -->
> 	<!-- <entry key="remote_ext_dict">words_location</entry> -->
> 	<!--用户可以在这里配置远程扩展停止词字典-->
> 	<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
> </properties>
> ```
>
> 扩展后再次查询
>
> ```sql
> GET http://localhost:9200/_analyze{
> 	"text":"测试单词",
> 	"analyzer":"ik_max_word"
> }
> ```
>
> **自定义分析器**
>
> 虽然Elasticsearch带有一些现成的分析器，然而在分析器上Elasticsearch真正的强大之处在于，你可以通过在一个适合你的特定数据的设置之中组合字符过滤器、分词器、词汇单元过滤器来创建自定义的分析器。一个分析器就是在一个包里面组合了三种函数的一个包装器，三种函数按照顺序被执行：
>
> **字符过滤器**
>
> 字符过滤器用来整理一个尚未被分词的字符串。例如，如果我们的文本是HTML格式的，它会包含像<p>或者<div>这样的HTML标签，这些标签是我们不想索引的。我们可以使用html清除字符过滤器来移除掉所有的HTML标签，并且像把&Aacute;转换为相对应的Unicode字符Á 这样，转换HTML实体。一个分析器可能有0个或者多个字符过滤器。
>
> **分词器**
>
> 一个分析器必须有一个唯一的分词器。分词器把字符串分解成单个词条或者词汇单元。标准分析器里使用的标准分词器把一个字符串根据单词边界分解成单个词条，并且移除掉大部分的标点符号，然而还有其他不同行为的分词器存在。
>
> 例如，关键词分词器完整地输出接收到的同样的字符串，并不做任何分词。空格分词器只根据空格分割文本。正则分词器根据匹配正则表达式来分割文本。
>
> **词单元过滤器**
>
> 经过分词，作为结果的词单元流会按照指定的顺序通过指定的词单元过滤器。词单元过滤器可以修改、添加或者移除词单元。我们已经提到过lowercase和stop词过滤器，但是在Elasticsearch 里面还有很多可供选择的词单元过滤器。词干过滤器把单词遏制为词干。ascii_folding过滤器移除变音符，把一个像"très”这样的词转换为“tres”。ngram和 edge_ngram词单元过滤器可以产生适合用于部分匹配或者自动补全的词单元。
>
> **自定义分析器例子**
>
> 接下来，我们看看如何创建自定义的分析器：
>
> ```sql
> PUT http://localhost:9200/my_index{
>     "settings": {
>         "analysis": {
>             "char_filter": {
>                 "&_to_and": { // 名字
>                     "type": "mapping", 
>                     "mappings": [
>                         "&=> and " //将 & 变为 and 
>                     ]
>                 }
>             }, 
>             "filter": {
>                 "my_stopwords": { // 名字
>                     "type": "stop", 
>                     "stopwords": [
>                         "the",  // 删除
>                         "a"
>                     ]
>                 }
>             }, 
>             "analyzer": {
>                 "my_analyzer": { // 名字
>                     "type": "custom", 
>                     "char_filter": [
>                         "html_strip", 
>                         "&_to_and"   // 名字
>                     ], 
>                     "tokenizer": "standard", 
>                     "filter": [
>                         "lowercase",  // 小写
>                         "my_stopwords"  // 名字
>                     ]
>                 }
>             }
>         }
>     }
> }
> ```
>
> 索引被创建以后，使用 analyze API 来 测试这个新的分析器：
>
> ```sql
> GET http://127.0.0.1:9200/my_index/_analyze{
>     "text":"The quick & brown fox",
>     "analyzer": "my_analyzer"
> }
> ```
>
> 返回结果为：
>
> ```sql
> {
>     "tokens": [
>         {
>             "token": "quick",
>             "start_offset": 4,
>             "end_offset": 9,
>             "type": "<ALPHANUM>",
>             "position": 1
>         },
>         {
>             "token": "and",
>             "start_offset": 10,
>             "end_offset": 11,
>             "type": "<ALPHANUM>",
>             "position": 2
>         },
>         {
>             "token": "brown",
>             "start_offset": 12,
>             "end_offset": 17,
>             "type": "<ALPHANUM>",
>             "position": 3
>         },
>         {
>             "token": "fox",
>             "start_offset": 18,
>             "end_offset": 21,
>             "type": "<ALPHANUM>",
>             "position": 4
>         }
>     ]
> }
> ```
>
> 
>
> 
>
> 
>
> **文档控制**
>
> **文档冲突**
>
> 当我们使用index API更新文档，可以一次性读取原始文档，做我们的修改，然后重新索引整个文档。最近的索引请求将获胜：无论最后哪一个文档被索引，都将被唯一存储在 Elasticsearch 中。如果其他人同时更改这个文档，他们的更改将丢失。
>
> 很多时候这是没有问题的。也许我们的主数据存储是一个关系型数据库，我们只是将数据复制到Elasticsearch中并使其可被搜索。也许两个人同时更改相同的文档的几率很小。或者对于我们的业务来说偶尔丢失更改并不是很严重的问题。
>
> 但有时丢失了一个变更就是非常严重的。试想我们使用Elasticsearch 存储我们网上商城商品库存的数量，每次我们卖一个商品的时候，我们在 Elasticsearch 中将库存数量减少。有一天，管理层决定做一次促销。突然地，我们一秒要卖好几个商品。假设有两个web程序并行运行，每一个都同时处理所有商品的销售。
>
> web_1 对stock_count所做的更改已经丢失，因为 web_2不知道它的 stock_count的拷贝已经过期。结果我们会认为有超过商品的实际数量的库存，因为卖给顾客的库存商品并不存在，我们将让他们非常失望。
>
> 变更越频繁，读数据和更新数据的间隙越长，也就越可能丢失变更。在数据库领域中，有两种方法通常被用来确保并发更新时变更不会丢失：
>
> > **悲观并发控制**
> >
> > 这种方法被关系型数据库广泛使用，它假定有变更冲突可能发生，因此阻塞访问资源以防止冲突。一个典型的例子是读取一行数据之前先将其锁住，确保只有放置锁的线程能够对这行数据进行修改。
> >
> > **乐观并发控制**
> >
> > Elasticsearch 中使用的这种方法假定冲突是不可能发生的，并且不会阻塞正在尝试的操作。然而，如果源数据在读写当中被修改，更新将会失败。应用程序接下来将决定该如何解决冲突。例如，可以重试更新、使用新的数据、或者将相关情况报告给用户。
>
> **乐观并发控制**
>
> Elasticsearch是分布式的。当文档创建、更新或删除时，新版本的文档必须复制到集群中的其他节点。Elasticsearch也是异步和并发的，这意味着这些复制请求被并行发送，并且到达目的地时也许顺序是乱的。Elasticsearch需要一种方法确保文档的旧版本不会覆盖新的版本。
>
> 当我们之前讨论index , GET和DELETE请求时，我们指出每个文档都有一个**_version**（版本号），当文档被修改时版本号递增。Elasticsearch使用这个version号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略。
>
> 我们可以利用version号来确保应用中相互冲突的变更不会导致数据丢失。我们通过指定想要修改文档的 version号来达到这个目的。如果该版本不是当前版本号，我们的请求将会失败。
>
> **创建索引**
>
> ```sql
> PUT http://127.0.0.1:9200/shopping/_create/1001
> ```
>
> 返回结果
>
> ```sql
> {
>     "_index": "shopping",
>     "_type": "_doc",
>     "_id": "1001",
>     "_version": 1,
>     "result": "created",
>     "_shards": {
>         "total": 2,
>         "successful": 1,
>         "failed": 0
>     },
>     "_seq_no": 10,
>     "_primary_term": 15
> }
> ```
>
> **更新数据**
>
> ```sql
> POST http://127.0.0.1:9200/shopping/_update/1001{
>     "doc":{
>         "title":"华为手机"
>     }
> }
> ```
>
> 返回结果：
>
> ```sql
> {
>     "_index": "shopping",
>     "_type": "_doc",
>     "_id": "1001",
>     "_version": 2, // 变化
>     "result": "updated",
>     "_shards": {
>         "total": 2,
>         "successful": 1,
>         "failed": 0
>     },
>     "_seq_no": 11, // 记录
>     "_primary_term": 15 // 记录
> }
> ```
>
> **新版本使用的防止冲突更新方法：**
>
> ```sql
> POST http://127.0.0.1:9200/shopping/_update/1001?if_seq_no=11&if_primary_term=15{ // 上一个的输出值
>     "doc":{
>         "title":"华为手机2"
>     }
> }
> ```
>
> 返回结果：
>
> ```sql
> {
>     "_index": "shopping",
>     "_type": "_doc",
>     "_id": "1001",
>     "_version": 3,
>     "result": "updated",
>     "_shards": {
>         "total": 2,
>         "successful": 1,
>         "failed": 0
>     },
>     "_seq_no": 12,
>     "_primary_term": 16
> }
> ```
>
> **外部系统版本控制**
>
> 一个常见的设置是使用其它数据库作为主要的数据存储，使用Elasticsearch做数据检索，这意味着主数据库的所有更改发生时都需要被复制到Elasticsearch，如果多个进程负责这一数据同步，你可能遇到类似于之前描述的并发问题。
>
> 如果你的主数据库已经有了版本号，或一个能作为版本号的字段值比如timestamp，那么你就可以在 Elasticsearch 中通过增加 `version_type=extermal`到查询字符串的方式重用这些相同的版本号，版本号必须是大于零的整数，且小于`9.2E+18`。
>
> 外部版本号的处理方式和我们之前讨论的内部版本号的处理方式有些不同，Elasticsearch不是检查当前`_version`和请求中指定的版本号是否相同，而是检查当前`_version`是否小于指定的版本号。如果请求成功，外部的版本号作为文档的新`_version`进行存储。
>
> ```sql
> POST http://127.0.0.1:9200/shopping/_doc/1001?version=300&version_type=external{ // 版本号高于现有的
> 	"title":"华为手机2"
> }
> ```
>
> 返回结果：
>
> ```sql
> {
>     "_index": "shopping",
>     "_type": "_doc",
>     "_id": "1001",
>     "_version": 300,
>     "result": "updated",
>     "_shards": {
>         "total": 2,
>         "successful": 1,
>         "failed": 0
>     },
>     "_seq_no": 13,
>     "_primary_term": 16
> }
> ```
>
> 
>
> **Kibana**
>
> Kibana是一个免费且开放的用户界面，能够让你对Elasticsearch 数据进行可视化，并让你在Elastic Stack 中进行导航。你可以进行各种操作，从跟踪查询负载，到理解请求如何流经你的整个应用，都能轻松完成。
>





> **Elasticsearch优化**
>
> **硬件选择**
>
> Elasticsearch 的基础是 Lucene，所有的索引和文档数据是存储在本地的磁盘中，具体的路径可在 ES 的配置文件…/config/elasticsearch.yml中配置，如下：
>
> ```
> # Path to directory where to store the data (separate multiple locations by comma):
> path.data: /path/to/data
> # Path to log files:
> path.logs: /path/to/logs
> ```
>
> 磁盘在现代服务器上通常都是瓶颈。Elasticsearch重度使用磁盘，你的磁盘能处理的吞吐量越大，你的节点就越稳定。这里有一些优化磁盘I/O的技巧：
>
>     1 使用SSD(固态硬盘)就像其他地方提过的，他们比机械磁盘优秀多了。
>     2 使用RAID 0。条带化RAID会提高磁盘IO，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验RAID，因为副本已经提供了这个功能。
>     3 另外，使用多块硬盘，并允许Elasticsearch 通过多个path data目录配置把数据条带化分配到它们上面。
>     4 不要使用远程挂载的存储，比如NFS或者SMB/CIFS。这个引入的延迟对性能来说完全是背道而驰的。
>
> 
>
> **分片策略**
>
> **合理设置分片数**
>
> 分片和副本的设计为 ES 提供了支持分布式和故障转移的特性，但并不意味着分片和副本是可以无限分配的。而且索引的分片完成分配后由于索引的路由机制，我们是不能重新修改分片数的。
>
> 可能有人会说，我不知道这个索引将来会变得多大，并且过后我也不能更改索引的大小，所以为了保险起见，还是给它设为 1000 个分片吧。但是需要知道的是，一个分片并不是没有代价的。需要了解：
>
>     一个分片的底层即为一个 Lucene 索引，会消耗一定文件句柄、内存、以及 CPU运转。
>     
>     每一个搜索请求都需要命中索引中的每一个分片，如果每一个分片都处于不同的节点还好， 但如果多个分片都需要在同一个节点上竞争使用相同的资源就有些糟糕了。因为分片太多，节点数太少。
>     
>     用于计算相关度的词项统计信息是基于分片的。如果有许多分片，每一个都只有很少的数据会导致很低的相关度。
>
> 一个业务索引具体需要分配多少分片可能需要架构师和技术人员对业务的增长有个预先的判断，横向扩展应当分阶段进行。为下一阶段准备好足够的资源。 只有当你进入到下一个阶段，你才有时间思考需要作出哪些改变来达到这个阶段。一般来说，我们遵循一些原则：
>
>     1 控制每个分片占用的硬盘容量不超过 ES 的最大 JVM 的堆空间设置（一般设置不超过 32G，参考下文的 JVM 设置原则），因此，如果索引的总容量在 500G 左右，那分片大小在 16 个左右即可；当然，最好同时考虑原则 2。
>     2 考虑一下 node 数量，一般一个节点有时候就是一台物理机，如果分片数过多，大大超过了节点数，很可能会导致一个节点上存在多个分片，一旦该节点故障，即使保持了 1 个以上的副本，同样有可能会导致数据丢失，集群无法恢复。所以， 一般都设置分片数不超过节点数的 3 倍。
>     3 主分片，副本和节点最大数之间数量，我们分配的时候可以参考以下关系：
>     节点数<=主分片数 *（副本数+1）
>
> **推迟分片分配**
>
> 对于节点瞬时中断的问题，默认情况，集群会等待一分钟来查看节点是否会重新加入，如果这个节点在此期间重新加入，重新加入的节点会保持其现有的分片数据，不会触发新的分片分配。这样就可以减少 ES 在自动再平衡可用分片时所带来的极大开销。
>
> 通过修改参数 delayed_timeout ，可以延长再均衡的时间，可以全局设置也可以在索引级别进行修改：
>
> ```sql
> PUT /_all/_settings{
> 	"settings": {
> 		"index.unassigned.node_left.delayed_timeout": "5m"
> 	}
> }
> ```
>
> 
>
> **路由选择**
>
> 当我们查询文档的时候， Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？它其实是通过下面这个公式来计算出来：
>
>     shard = hash(routing) % number_of_primary_shards
>
> routing 默认值是文档的 id，也可以采用自定义值，比如用户 id。
>
> **不带routing查询**
>
> 在查询的时候因为不知道要查询的数据具体在哪个分片上，所以整个过程分为2个步骤
>
>     分发：请求到达协调节点后，协调节点将查询请求分发到每个分片上。
>     聚合：协调节点搜集到每个分片上查询结果，在将查询的结果进行排序，之后给用户返回结果。
>
> **带routing查询**
>
> 查询的时候，可以直接根据routing 信息定位到某个分配查询，不需要查询所有的分配，经过协调节点排序。向上面自定义的用户查询，如果routing 设置为userid 的话，就可以直接查询出数据来，效率提升很多。
>
> 
>
> **写入速度优化**
>
> ES 的默认配置，是综合了数据可靠性、写入速度、搜索实时性等因素。实际使用时，我们需要根据公司要求，进行偏向性的优化。
>
> 针对于搜索性能要求不高，但是对写入要求较高的场景，我们需要尽可能的选择恰当写优化策略。综合来说，可以考虑以下几个方面来提升写索引的性能：
>
>     1 加大Translog Flush，目的是降低Iops、Writeblock。
>     2 增加Index Refesh间隔，目的是减少Segment Merge的次数。
>     3 调整Bulk 线程池和队列。
>     4 优化节点间的任务分布。
>     5 优化Lucene层的索引建立，目的是降低CPU及IO。
>
> **优化存储设备**
>
> ES 是一种密集使用磁盘的应用，在段合并的时候会频繁操作磁盘，所以对磁盘要求较高，当磁盘速度提升之后，集群的整体性能会大幅度提高。
>
> **合理使用合并**
>
> Lucene 以段的形式存储数据。当有新的数据写入索引时， Lucene 就会自动创建一个新的段。随着数据量的变化，段的数量会越来越多，消耗的多文件句柄数及 CPU 就越多，查询效率就会下降。
>
> 由于 Lucene 段合并的计算量庞大，会消耗大量的 I/O，所以 ES 默认采用较保守的策略，让后台定期进行段合并。
>
> **减少 Refresh 的次数**
>
> Lucene 在新增数据时，采用了延迟写入的策略，默认情况下索引的refresh_interval 为1 秒。Lucene 将待写入的数据先写到内存中，超过 1 秒（默认）时就会触发一次 Refresh，然后 Refresh 会把内存中的的数据刷新到操作系统的文件缓存系统中。
>
> 如果我们对搜索的实效性要求不高，可以将 Refresh 周期延长，例如 30 秒。这样还可以有效地减少段刷新次数，但这同时意味着需要消耗更多的 Heap 内存。
>
> **加大 Flush 设置**
>
> Flush 的主要目的是把文件缓存系统中的段持久化到硬盘，当 Translog 的数据量达到 512MB 或者 30 分钟时，会触发一次 Flush`index.translog.flush_threshold_size` 参数的默认值是 512MB，我们进行修改。
>
> 增加参数值意味着文件缓存系统中可能需要存储更多的数据，所以我们需要为操作系统的文件缓存系统留下足够的空间。
>
> **减少副本的数量**
>
> ES 为了保证集群的可用性，提供了 Replicas（副本）支持，然而每个副本也会执行分析、索引及可能的合并过程，所以 Replicas 的数量会严重影响写索引的效率。
>
> 当写索引时，需要把写入的数据都同步到副本节点，副本节点越多，写索引的效率就越慢。如果我们需要大批量进行写入操作，可以先禁止Replica复制，设置
> `index.number_of_replicas: 0 `关闭副本。在写入完成后， Replica 修改回正常的状态。
>
> 
>
> **内存设置**
>
> ES 默认安装后设置的内存是 1GB，对于任何一个现实业务来说，这个设置都太小了。如果是通过解压安装的 ES，则在 ES 安装文件中包含一个 `jvm.option` 文件，添加如下命令来设置 ES 的堆大小， Xms 表示堆的初始大小， Xmx 表示可分配的最大内存，都是 1GB。
>
> 确保 Xmx 和 Xms 的大小是相同的，其目的是为了能够在 Java 垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源，可以减轻伸缩堆大小带来的压力。
>
> 假设你有一个 64G 内存的机器，按照正常思维思考，你可能会认为把 64G 内存都给ES 比较好，但现实是这样吗， 越大越好？虽然内存对 ES 来说是非常重要的，但是答案是否定的！
>
> 因为 ES 堆内存的分配需要满足以下两个原则：
>
>     1 不要超过物理内存的 50%： Lucene 的设计目的是把底层 OS 里的数据缓存到内存中。Lucene 的段是分别存储到单个文件中的，这些文件都是不会变化的，所以很利于缓存，同时操作系统也会把这些段文件缓存起来，以便更快的访问。如果我们设置的堆内存过大， Lucene 可用的内存将会减少，就会严重影响降低 Lucene 的全文本查询性能。
>     
>     2 堆内存的大小最好不要超过 32GB：在 Java 中，所有对象都分配在堆上，然后有一个 Klass Pointer 指针指向它的类元数据。这个指针在 64 位的操作系统上为 64 位， 64 位的操作系统可以使用更多的内存（2^64）。在 32 位
>     的系统上为 32 位， 32 位的操作系统的最大寻址空间为 4GB（2^32）。
>     但是 64 位的指针意味着更大的浪费，因为你的指针本身大了。浪费内存不算，更糟糕的是，更大的指针在主内存和缓存器（例如 LLC, L1 等）之间移动数据的时候，会占用更多的带宽。
>
> 最终我们都会采用 31 G 设置
>
>     -Xms 31g
>     -Xmx 31g
>
> 假设你有个机器有 128 GB 的内存，你可以创建两个节点，每个节点内存分配不超过 32 GB。也就是说不超过 64 GB 内存给 ES 的堆内存，剩下的超过 64 GB 的内存给 Lucene。
>
> 
>
> **重要配置**
>
> **名称   					  默认值			  		介绍**
>
> **cluster.name**	elasticsearch	配置 ES 的集群名称，默认值是 ES，建议改成与所存数据相关的名称， ES 会自动发现在同一网段下的 集群名称相同的节点。
>
> **node.name**	node-1	集群中的节点名，在同一个集群中不能重复。节点 的名称一旦设置，就不能再改变了。当然，也可以 设 置 成 服 务 器 的 主 机 名 称 ， 例 如 node.name:${HOSTNAME}。
>
> **node.master**	true	指定该节点是否有资格被选举成为 Master 节点，默 认是 True，如果被设置为 True，则只是有资格成为 Master 节点，具体能否成为 Master 节点，需要通 过选举产生。
>
> **node.data**	true	指定该节点是否存储索引数据，默认为 True。数据 的增、删、改、查都是在 Data 节点完成的。
>
> **index.number_of_shards**	1	设置都索引分片个数，默认是 1 片。也可以在创建 索引时设置该值，具体设置为多大都值要根据数据 量的大小来定。如果数据量不大，则设置成 1 时效 率最高
>
> **index.number_of_replicas**	1	设置默认的索引副本个数，默认为 1 个。副本数越 多，集群的可用性越好，但是写索引时需要同步的 数据越多。
>
> **transport.tcp.compress**	true	设置在节点间传输数据时是否压缩，默认为 False， 不压缩
>
> **discovery.zen.minimum_master_nodes**	1	设置在选举 Master 节点时需要参与的最少的候选 主节点数，默认为 1。如果使用默认值，则当网络 不稳定时有可能会出现脑裂。 合 理 的 数 值 为 (master_eligible_nodes/2)+1 ， 其 中 master_eligible_nodes 表示集群中的候选主节点数
>
> **discovery.zen.ping.timeout**	3s	设置在集群中自动发现其他节点时 Ping 连接的超 时时间，默认为 3 秒。 在较差的网络环境下需要设置得大一点，防止因误 判该节点的存活状态而导致分片的转移
>
> 
>
> 
>
> **面试题**
>
> **为什么要使用 Elasticsearch？**
>
> 系统中的数据， 随着业务的发展，时间的推移， 将会非常多， 而业务中往往采用模糊查询进行数据的搜索， 而模糊查询会导致查询引擎放弃索引，导致系统查询数据时都是**全表扫描**，在百万级别的数据库中，查询效率是非常低下的，而我们使用 ES 做一个全文索引，将经常查询的系统功能的某些字段，比如说电商系统的商品表中商品名，描述、价格还有 id 这些字段我们放入 ES 索引库里，可以提高查询速度。
>
> 
>
> **Elasticsearch 的 master 选举流程？**
>
> 1 Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含-一个主机列表以控制哪些节点需要ping通）这两部分。
> 2 对所有可以成为master的节点（node master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。
> 3 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。
> 4 master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。
>
> 
>
> **Elasticsearch 集群脑裂问题？**
>
> **“脑裂”问题可能的成因**  多个master
>
> 1 网络问题：集群间的网络延迟导致一些节点访问不到master, 认为master 挂掉了从而选举出新的master,并对master上的分片和副本标红，分配新的主分片。
> 2 节点负载：主节点的角色既为master又为data,访问量较大时可能会导致ES停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。
> 3 内存回收：data 节点上的ES进程占用的内存较大，引发JVM的大规模内存回收，造成ES进程失去响应。
>
> **脑裂问题解决方案**
>
> 1 减少误判：discovery.zen ping_ timeout 节点状态的响应时间，默认为3s，可以适当调大，如果master在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如6s，discovery.zen.ping_timeout:6），可适当减少误判。
>
> 2 选举触发：`discovery.zen.minimum. _master_ nodes:1`，该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值，且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为(n / 2) +1, n为主节点个数（即有资格成为主节点的节点个数）。
>
> 3 角色分离：即master节点与data节点分离，限制角色
>     主节点配置为：node master: true，node data: false
>     从节点配置为：node master: false，node data: true
>
> 
>
> **Elasticsearch 索引文档的流程？**
>
>     1 协调节点默认使用文档 ID 参与计算（也支持通过 routing），以便为路由提供合适的分片：shard = hash(document_id) % (num_of_primary_shards)
>     2 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 Memory Buffer，然后定时（默认是每隔 1 秒）写入到 Filesystem Cache，这个从 Memory Buffer 到 Filesystem Cache 的过程就叫做 refresh；
>     3 当然在某些情况下，存在 Momery Buffer 和 Filesystem Cache 的数据可能会丢失， ES 是通过 translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中，当 Filesystemcache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush；
>     4 在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync 将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。
>     5 flush 默认触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512M）时；
>
> **Elasticsearch 更新和删除文档的流程？**
>
>     删除和更新也都是写操作，但是 Elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更；
>     1 磁盘上的每个段都有一个相应的.del 文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del 文件中被标记为删除的文档将不会被写入新段。
>     2 在新的文档被创建时， Elasticsearch 会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。
>
> **Elasticsearch 搜索的流程？**
>
>     搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；
>     1 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。 PS：在搜索的时候是会查询Filesystem Cache 的，但是有部分数据还在 Memory Buffer，所以搜索是近实时的。
>     2 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
>     3 接下来就是取回阶段， 协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。
>     
>     Query Then Fetch 的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确， DFS Query Then Fetch 增加了一个预查询的处理，询问 Term 和 Document frequency，这个评分更准确，但是性能会变差。
>
> **Elasticsearch 在部署时，对 Linux 的设置有哪些优化方法？**
>
>     1 64 GB 内存的机器是非常理想的， 但是 32 GB 和 16 GB 机器也是很常见的。少于 8 GB 会适得其反。
>     
>     2 如果你要在更快的 CPUs 和更多的核心之间选择，选择更多的核心更好。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。
>     
>     3 如果你负担得起 SSD，它将远远超出任何旋转介质。 基于 SSD 的节点，查询和索引性能都有提升。如果你负担得起， SSD 是一个好的选择。
>     
>     4 即使数据中心们近在咫尺，也要避免集群跨越多个数据中心。绝对要避免集群跨越大的地理距离。
>     
>     5 请确保运行你应用程序的 JVM 和服务器的 JVM 是完全一样的。 在 Elasticsearch 的几个地方，使用 Java 的本地序列化。
>     
>     6 通过设置 `gateway.recover_after_nodes``gateway.expected_nodes` `gateway.recover_after_time` 可以在集群重启的时候避免过多的分片交换，这可能会让数据恢复从数个小时缩短为几秒钟。
>     
>     7 Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。最好使用单播代替组播。
>     
>     8 不要随意修改垃圾回收器（CMS）和各个线程池的大小。
>     
>     9 把你的内存的（少于）一半给 Lucene（但不要超过 32 GB！），通过 ES_HEAP_SIZE 环境变量设置。
>     
>     10 内存交换到磁盘对服务器性能来说是致命的。如果内存交换到磁盘上，一个 100 微秒的操作可能变成 10 毫秒。 再想想那么多 10 微秒的操作时延累加起来。 不难看出 swapping 对于性能是多么可怕。
>     
>     11 Lucene 使用了大量的文件。同时， Elasticsearch 在节点和 HTTP 客户端之间进行通信也使用了大量的套接字。 所有这一切都需要足够的文件描述符。你应该增加你的文件描述符，设置一个很大的值，如 64,000。
>
> **GC 方面，在使用 Elasticsearch 时要注意什么？**
>
> ```
> 1 倒排词典的索引需要常驻内存，无法 GC，需要监控 data node 上 segment memory 增长趋势。
> 
> 2 各类缓存， field cache, filter cache, indexing cache, bulk queue 等等，要设置合理的大小，并且要应该根据最坏的情况来看 heap 是否够用，也就是各类缓存全部占满的时候，还有 heap 空间可以分配给其他任务吗？避免采用 clear cache 等“自欺欺人”的方式来释放内存。
> 
> 3 避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用 scan & scroll api 来实现。
> 
> 4 cluster stats 驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过 tribe node 连接。
> 
> 5 想知道 heap 够不够，必须结合实际应用场景，并对集群的 heap 使用情况做持续的监控。
> ```
>
> **在并发情况下， Elasticsearch 如果保证读写一致？**
>
>     1 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
>     
>     2 另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
>     
>     3 对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。
>
> **如何监控 Elasticsearch 集群状态？**
>
>     elasticsearch-head 插件。
>     通过 Kibana 监控 Elasticsearch。你可以实时查看你的集群健康状态和性能，也可以分析过去的集群、索引和节点指标
>
> **是否了解字典树？**
>
> ```
> 字典树又称单词查找树， Trie 树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。
> 
> Trie 的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有 3 个基本性质：
> 
>     1 根节点不包含字符，除根节点外每一个节点都只包含一个字符。
>     2 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。
>     3 每个节点的所有子节点包含的字符都不相同。
> 
> 对于中文的字典树，每个节点的子节点用一个哈希表存储，这样就不用浪费太大的空间，而且查询速度上可以保留哈希的复杂度 O(1)。
> ```
>
> **Elasticsearch 中的集群、节点、索引、文档、类型是什么？**
>
>     1 集群是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。集群由唯一名 称标识，默认情况下为"elasticsearch"。此名称很重要，因为如果节点设置为按名称加入集群，则该节点只能是集群的一部分。
>     2 节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。
>     3 索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。MySQL =>数据库，Elasticsearch=>索引。
>     4 文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构(字段)，但是对于通用字段应该具有相同的数据类型。MySQL => Databases => Tables => Columns / Rows，Elasticsearch=> Indices => Types =>具有属性的文档Doc。
>     5 类型是索引的逻辑类别/分区，其语义完全取决于用户。
>
> **Elasticsearch 中的倒排索引是什么？**
>
> ```
> 倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。ES中的倒排索引其实就是 lucene 的倒排索引，区别于传统的正向索引， 倒排索引会再存储数据时将关键词和数据进行关联，保存到倒排表中，然后查询时，将查询内容进行分词后在倒排表中进行查询，最后匹配数据即可。
> ```
>
> 