**Redis介绍**

Redis是一个开源的内存数据库，Redis提供了多种不同类型的数据结构，很多业务场景下的问题都可以很自然地映射到这些数据结构上。除此之外，通过复制、持久化和客户端分片等特性，我们可以很方便地将Redis扩展成一个能够包含数百GB数据、每秒处理上百万次请求的系统。

**Redis支持的数据结构**

Redis支持诸如字符串（strings）、哈希（hashes）、列表（lists）、集合（sets）、带范围查询的排序集合（sorted sets）、位图（bitmaps）、hyperloglogs、带半径查询和流的地理空间索引等数据结构（geospatial indexes）。

**Redis应用场景**

> - 缓存系统，减轻主数据库（MySQL）的压力。
> - 计数场景，比如微博、抖音中的关注数和粉丝数。
> - 热门排行榜，需要排序的场景特别适合使用ZSET。
> - 利用LIST可以实现队列的功能。
>

谈到Redis服务器的高可用，如何保证备份的机器是原始服务器的完整备份呢？这时候就需要哨兵和复制。

**哨兵(Sentinel)**：可以管理多个Redis服务器，它提供了监控，提醒以及自动的故障转移的功能。是Redis集群架构中非常重要的一个组件，哨兵的出现主要是解决了主从复制出现故障时需要人为干预的问题。

**复制(Replication)**：则是负责让一个Redis服务器可以配备多个备份的服务器。

Redis正是利用这两个功能来保证Redis的高可用

**Redis哨兵主要功能**

> 1）集群监控：负责监控Redis master和slave进程是否正常工作
> 2）消息通知：如果某个Redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员
> 3）故障转移：如果master node挂掉了，会自动转移到slave node上
> 4）配置中心：如果故障转移发生了，通知client客户端新的master地址

**Redis哨兵的高可用**

原理：当主节点出现故障时，由Redis Sentinel自动完成故障发现和转移，并通知应用方，实现高可用性。

> 1. 哨兵机制建立了多个哨兵节点(进程)，共同监控数据节点的运行状况。
> 2. 同时哨兵节点之间也互相通信，交换对主从节点的监控状况。
> 3. 每隔1秒每个哨兵会向整个集群：Master主服务器+Slave从服务器+其他Sentinel（哨兵）进程，发送一次ping命令做一次心跳检测。
>

这个就是哨兵用来判断节点是否正常的重要依据，涉及两个新的概念：**主观下线和客观下线**。

> **主观下线：一个哨兵节点判定主节点down掉是主观下线。**
>
> **客观下线：只有半数哨兵节点都主观判定主节点down掉，此时多个哨兵节点交换主观判定结果，才会判定主节点客观下线。**
>
> 基本上哪个哨兵节点最先判断出这个主节点客观下线，就会在各个哨兵节点中发起投票机制Raft算法（选举算法），最终被投为领导者的哨兵节点完成主从自动化切换的过程。
>

**Redis 复制(Replication)**

> Redis为了解决单点数据库问题，会把数据复制多个副本部署到其他节点上，通过复制，实现Redis的高可用性，实现对数据的冗余备份，保证数据和服务的高度可靠性。
>
> ①从数据库向主数据库发送sync(数据同步)命令。
>
> ②主数据库接收同步命令后，会保存快照，创建一个RDB文件。
>
> ③当主数据库执行完保持快照后，会向从数据库发送RDB文件，而从数据库会接收并载入该文件。
>
> ④主数据库将缓冲区的所有写命令发给从服务器执行。
>
> ⑤以上处理完之后，之后主数据库每执行一个写命令，都会将被执行的写命令发送给从数据库。
>
> 注意：在Redis2.8之后，主从断开重连后会根据断开之前最新的命令偏移量进行增量复制
>

**Redis 主从复制、哨兵和集群三者区别**

主从复制是为了数据备份，哨兵是为了高可用，Redis主服务器挂了哨兵可以切换，集群则是因为单实例能力有限，搞多个分散压力，简短总结如下：

> 主从模式：备份数据、负载均衡，一个Master可以有多个Slaves。sentinel发现master挂了后，就会从slave中重新选举一个master。cluster是为了解决单机Redis容量有限的问题，将数据按一定的规则分配到多台机器。sentinel着眼于高可用，Cluster提高并发量。
>
> **1. 主从模式**：读写分离，备份，一个Master可以有多个Slaves。
>
> **2. 哨兵sentinel**：监控，自动转移，哨兵发现主服务器挂了后，就会从slave中重新选举一个主服务器。
>
> **3. 集群**：为了解决单机Redis容量有限的问题，将数据按一定的规则分配到多台机器，内存/QPS不受限于单机，可受益于分布式集群高扩展性。

###### 1、Redis简介：

随着Web2.0的时代的到来，用户访问量大幅度提升，同时产生了大量的用户数据。加上后来的智能移动设备的普及，所有的互联网平台都面临了巨大的性能挑战。Redis是一种数据库。是能够存储数据、管理数据的一种软件。底层存储机制和mysql不同

![图片1](F:\markdown笔记\redis\图片1.png)

###### 2、数据库应用的发展历程：从正式数据库产生开始

> **单机数据库时代：**一台电脑安装一个数据库实例 sqlserver等，一个应用对应一个数据库服务器
>
> **Memcached缓存、水平切分时代：**应用和数据库服务器中加一个缓存 解决经常访问的数据的访问效率问题，但是数据量较大；水平切分解决数据量大的问题：将一个数据库服务器拆分为多个，一个应用按照不同业务存储在不同服务器
>
> 水平切分解决数据量大的问题：将一个数据库服务器拆分为多个，一个应用按照不同业务存储在不同服务器
>
> **读写分离时代：**但是若是订单表，本身就特别大，并发能力特别弱，所以可以拆分，几个表负责读，几个负责写，几个负责删除，谁闲着找谁，用同步机制保证ACID，负责写的为主负责读的为从，主同步到从
>
> **分表分库时代(集群):** 某一天或某一周的数据存在一个表中，同类型的数据不存储在同一个表中，因为数据量太大了
>
> 前面的都是关系型数据库时代 以表为单位存储
>
> 非关系型数据库(NoSql)： 彻底改变底层存储机制。不再采用关系数据模型，而是采用聚合数据结构存储数据。 redis、mongoDB、HBase

######  3、Nosql数据模型：

> 关系型数据库：表
>
> 非关系型数据库：聚合模型---把一组相关联的数据作为一个整体进行存储和管理。NoSQL 不依赖业务逻辑方式存储，而以简单的key-value模式存储。因此大大的增加了数据库的扩展能力。
>
> 文档 BSON：数据保存到键值对中、数据和数据之间用逗号隔开，{}表示对象，[]表示数组。
>
> K-V键值对
>
> 列簇
>
> 图表模型等。
>
> Redis采用的是K-V模型存储数据的。

**NoSQL适用场景**

> l 对数据高并发的读写
>
> l 海量数据的读写
>
> l 对数据高可扩展性的

**NoSQL不适用场景**

> l 需要事务支持
>
> l 基于sql的结构化查询存储，处理复杂的关系,需要即席查询。
>
> l （用不着sql的和用了sql也不行的情况，请考虑用NoSql）

**Memcache**

> 很早出现的NoSql数据库
>
> 数据都在内存中，一般不持久化
>
> 支持简单的key-value模式，支持类型单一
>
> 一般是作为缓存数据库辅助持久化的数据库

**Redis**

> 几乎覆盖了Memcached的绝大部分功能
>
> 数据都在内存中，支持持久化，主要用作备份恢复
>
> 除了支持简单的key-value模式，还支持多种数据结构的存储，比如 list、set、hash、zset等。
>
> 一般是作为缓存数据库辅助持久化的数据库

**MongoDB**

> 高性能、开源、模式自由(schema  free)的文档型数据库
>
> 数据都在内存中， 如果内存不足，把不常用的数据保存到硬盘
>
> 虽然是key-value模式，但是对value（尤其是json）提供了丰富的查询功能
>
> 支持二进制数据及大型对象
>
> 可以根据数据的特点替代RDBMS，成为独立的数据库。或者配合RDBMS，存储特定的数据。

###### 4、Redis是一个用C语言编写的、开源的、基于内存运行并支持持久化的、高性能的NoSQL数据库，也是当前热门的NoSQL数据库之一。Redis中的数据大部分时间都是存储在内存中的，适合存储频繁访问、数据量比较小的数据。

###### 5、Redis特点

> 1、支持数据持久化
>
> Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。
>
> 2、支持多种数据结构
>
> Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
>
> 3、支持数据备份
>
> Redis支持数据的备份，即master-slave模式的数据备份。

###### 6、启动redis服务

> 进入E:\redis> redis.windows.conf 配置文件可修改
>
> 1)服务端启动： `redis-server.exe redis.windows.conf`启动服务端 
> 2)客户端启动： `redis-cli.exe -h 127.0.0.1 -p 6379`  # 指定主机上的指定端口的redis

###### 7、关闭redis服务：

`ctrl+c`

###### 8、redis客户端：默认不需要密码连接

> 通过网络连接到Redis服务器，向redis服务端发送命令，并且显示redis服务处理结果。
> redis-cli：是redis自带客户端，使用命令`redis-cli.exe -h 127.0.0.1 -p 6379` 就可以启动redis的客户端程序。用于与服务端交互，我们可以使用该客户端来执行redis的各种命令。

###### 9、退出客户端：

> 在客户端执行命令：exit或者quit

###### 10、redis的基本知识：

> 1)、测试redis服务的性能：redis-benchmark
> 2)、查看redis服务是否正常运行：客户端连接服务器之后发送 ping  如果正常 服务器返回pong
> 3)、查看redis服务器的统计信息：
>        info 查看redis服务的所有统计信息
>        info [信息段] 查看redis服务器的指定的统计信息，如：info CPU
> 4)、redis的数据库实例(16个库)：
>
> > 作用类似于mysql的数据库实例，但是redis中的数据库实例**只能由redis服务来创建和维护**，开发人员不能修改和自行创建数据库实例；各个库不能自定义命名，只能用序号表示，redis中各个库不是完全独立的，使用时最好一个应用使用一个redis实例，不建议一个redis实例中保存多个应用的数据。
> >
> > 默认情况下，redis会自动创建16个数据库实例，并且给这些数据库实例进行编号，从0开始，一直到15，使用时通过编号来使用数据库；
> >
> > 可以通过配置文件redis.conf，指定redis自动创建的数据库个数；redis的每一个数据库实例本身占用的存储空间是很少的，所以也不造成存储空间的太多浪费。
> >
> > 默认情况下，redis客户端连接的是**编号是0**的数据库实例；可以使用select index切换数据库实例。
> >
> > ```redis
> > 127.0.0.1:6379> select 1
> > OK
> > 127.0.0.1:6379[1]> set k1 v1
> > OK
> > 127.0.0.1:6379[1]> get k1
> > "v1"
> > 127.0.0.1:6379[1]> select 0
> > OK
> > 127.0.0.1:6379> get k1
> > (nil)
> > ```
>
> 5)、查看当前数据库实例中所有key的数量：`dbsize`
>
> 127.0.0.1:6379[1]> dbsize
> (integer) 1
>
> 6)、查看当前数据库实例中所有的key：`keys * `
>
> 127.0.0.1:6379[1]> keys *
> 1) "k1"
>
> 7)、清空数据库key：`flushdb`
> 8)、清空所有的数据库key：`flushall`
> 9)、查看redis中所有的配置信息：`config get *`
>        查看redis中的指定的配置信息：`config get port`
>
> 127.0.0.1:6379[1]> config get port
> 1) "port"
> 2) "6379"

redis英文版命令大全：https://redis.io/commands

redis中文版命令大全：http://redisdoc.com/

###### 11、Redis的五种数据结构

> 程序是用来处理数据的，Redis数据库是用来存储数据的；程序处理完的数据要存储到redis中，不同特点的数据要存储在Redis中不同类型的数据结构中。
>
> **字符串**：字符串类型是Redis中最基本的数据结构，它能存储任何类型的数据，包括二进制数据，序列化后的数据，JSON化的对象甚至是一张图片。最大512M。 **单key单value**
>
> **list列表**：Redis列表是简单的字符串列表，按照插入顺序排序，元素可以重复。可以添加一个元素到列表的头部（左边）或者尾部（右边）,底层是个链表结构。**单key多value value有序 顺序和放入的顺序有关**
>
> **set集合**：Redis的set是string类型的无序无重复集合。**单key多value value无序**
>
> **hash**：Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。**单key value是对象{k1:v1,k2:v2,...} **
>
> **zset**：Redis 有序集合zset和集合set一样也是string类型元素的集合，且不允许重复的成员。不同的是zset的每个元素都会关联一个分数（分数可以重复），redis通过分数来为集合中的成员进行从小到大的排序。**单key多value value有序 按某个标准排序**

###### 12、redis中的操作命令：

> **1)、redis中有关key的操作命令：**
>
> **a)查看数据库中的key**：`keys pattern`
> |  *：匹配0个或者多个字符 
>
> > `keys *`  查看数据库中所有的key
> >
> > `keys k*`:查看数据库中所有以k开头的key
> >
> > `keys h*o`：查看数据库中所有以h开头、以o结尾的key
>
> |  ?： 匹配1个字符
>
> `keys h?o`: 查看数据库中所有以h开头、以o结尾的、并且中间只有一个字符的key
>
> |  []：匹配[]里边的1个字符
>
>  `keys h[abc]llo`：查看数据库中所有以h开头以llo结尾，并且h后边只能取abc中的一个字符的key
>
> **b)判断key在数据库中是否存在**：`exists key` 
>
> `exists k1`如果存在，则返回1；如果不存在，则返回0 
>
> `exists key [key key ....]` 返回值是存在的key的数量
>
> `exists k1 k2 k3 hello`
>
> **c)移动指定key到指定的数据库实例**：`move key index`  用的不多，因为一个项目对应一个数据库实例，最好数据不要交流 
>
> `move k 1`
>
> **d)查看指定key的剩余生存时间**：
>
> `ttl key` time to live
>
> `ttl k1`
>
> 如果key没有设置生存时间，返回-1，如果key不存在，返回-2
>
> **e)设置key的最大生存时间**：`expire key seconds`
> `expire k2 20`
>
> **f)查看指定key的数据类型**：`type key`
> `type k1` 五种数据类型
>
> **g)重命名key**： `rename key newkey`
> `rename hello k2`
>
> **h)删除指定的key**：`del key [key key .....]`
> 返回值是实际删除的key的数量，key不存在就忽略
> `del k1 k2 k3 k4`



> **2)、redis中有关string类型数据的操作命令：** **单key-单value**
>
> **a)将string类型的数据设置到redis中**：`set 键 值`
> `set zsname zhangsan`
> `set zsage 30 `如果key已经存在，则后来的value会把以前的value覆盖掉
>
> **b)从redis中获取string类型的数据**：`get 键`
> `get zsname`
>
> **c)追加字符串**：`append key value`
> 返回追加之后的字符串长度，如果key不存在，相当于set，新创建一个key，并且把value值设置为value。
> `set phone 1389999`
> `append phone 8888` 所以phone变为了13899998888
>
> **d)获取字符串数据的长度**：`strlen key`
> `strlen phone`
>
> **e)将字符串数值进行加1运算**：`incr key`
> 返回加1运算之后的数据，如果key不存在，首先设置一个key，值初始化为0，然后进行incr运算。要求key所表示value必须是数值，否则，报错
> `incr zsage`
>
> **f)将字符串数值进行减1运算**：`decr key`
> 返回减1运算之后的数据，如果key不存在，首先设置一个key，值初始化为0，然后进行decr运算。要求key所表示value必须是数值，否则，报错
>
> `decr zsage`
>
> **g)将字符串数值进行加offset运算**：`incrby key offset`
> 返回加offset运算之后的数据，如果key不存在，首先设置一个key，值初始化为0，然后进行incrby运算。要求key所表示value必须是数值，否则，报错
> `incrby zsage 10`
>
> **h)将字符串数值进行减offset运算**：`decrby key offset`
> 返回减offset运算之后的数据，如果key不存在，首先设置一个key，值初始化为0，然后进行decrby运算。要求key所表示value必须是数值，否则，报错
> `decrby zsage 10`
>
> **i)闭区间获取字符串key中从startIndex到endIndex的字符组成的子字符串：**
>
> `getrange key startIndex endIndex`
>
> 下标自左至右，从0开始，依次往后，最后一个字符的下标是字符串长多-1；
> 字符串中每一个下标也可以是负数，负下标表示自右至左，从-1开始，依次往前，最右边一个字符的下标是-1
> `zsname = zhangsan`
> `getrange zsname 2 5` angs
> `getrange zsname 2 -3` angs
> `getrange zsname 0 -1` zhangsan
>
> **j)用value覆盖从下标为startIndex开始的字符串，能覆盖几个字符就覆盖几个字符**：
>
> `setrange key startIndex value`
> `setrange zsname 5 xiaosan`   // zhangxiaosan
> `setrange zsname 5 lao`       // zhanglaoosan
>
> **k)设置字符串数据的同时，设置它最大生命周期 当key存在时覆盖** ：`setex key seconds value`
> `setex k1 20 v1`
>
> **l)设置string类型的数据value到redis数据库中，当key不存在时设置成功，否则，则放弃设置**：`setnx key value`
> `setnx zsage 20`
>
> **m)批量将string类型的数据设置到redis中：**`mset 键1 值1 键2 值2 .....`
> `mset k1 v1 k2 v2 k3 v3 k4 v4 k5 v5`
>
> **n)批量从redis中获取string类型的数据：**`mget 键1 键2 键3.....`
> `mget k1 k2 k3 k4 k5 k6 zsname zs age totalRows` 没有的话返回nil
>
> **o)批量设置string类型的数据value到redis数据库中，当所有key都不存在时设置成功，否则(只要有一个key已经存在)，则全部放弃设置：** `msetnx 键1 值1 键2 值2 .....`
> `msetnx kk1 vv1 kk2 vv2 kk3 vv3 k1 v1`



> **3)、redis中有关list类型数据的操作命令：单key-多有序value**
>
> 一个key对应多个value；多个value之间有顺序，最左侧是表头，最右侧是表尾；每一个元素都有下标，表头元素的下标是0，依次往后排序，最后一个元素下标是列表长度-1；每一个元素的下标又可以用负数表示，负下标表示从表尾计算，最后一个元素下标用-1表示；元素在列表中的顺序或者下标由放入的顺序来决定。通过key和下标来操作数据。 
>
> **a)将一个或者多个值依次插入到列表的表头(左侧)**：`lpush key value [value value .....]`
> ` lpush list01 1 2 3`  结果：3 2 1
> ` lpush list01 4 5 `   结果：5 4 3 2 1
>
> **b)获取指定列表中指定下标区间的元素 闭区间**：`lrange key startIndex endIndex`
> `lrange list01 1 3`  结果：4 3 2
> `lrange list01 1 -2` 结果: 4 3 2
> `lrange list01 0 -1` 结果：5 4 3 2 1
>
> **c)将一个或者多个值依次插入到列表的表尾(右侧)：**`rpush key value [value value .....]`
> `rpush list02 a b c` 结果：a b c
> ` rpush list02 d e `  结果：a b c d e
> `lpush list02 m n `  结果: n m a b c d e
>
> **d)从指定列表中移除并且返回表头元素：**`lpop key`
> `lpop list02`
>
> **e)从指定列表中移除并且返回表尾元素：**`rpop key`
> `rpop list02`
>
> **f)获取指定列表中指定下标的元素：**`lindex key index`
> `lindex list01 2`  结果：3
>
> **g)获取指定列表的长度：**`llen key`
> `llen list01`
>
> **h)根据count值移除指定列表中跟value相等的数据：**
>
> `lrem key count value`
>
> count>0：从列表的左侧移除count个跟value相等的数据；
>
> count<0：从列表的右侧移除count个跟vlaue相等的数据；
>
> count=0：从列表中移除所有跟value相等的数据
>
> `lpush list03 a a b c a d e a b b`  结果：b b a e d a c b a a
> `lrem list03 2 a`  结果：b b e d c b a a
> `lrem list03 -1 a` 结果：b b e d c b a
> `lrem list03 0 a`  结果：b b e d c b
>
> **i)截取指定列表中指定下标区间的元素组成新的列表，并且赋值给key：**
>
> `ltrim key startIndex endIndex`
> `lpush list04 1 2 3 4 5`  结果：5 4 3 2 1
> `ltrim list04 1 3`
> `lrange list04 0 -1`      结果：4 3 2
>
> **j)将指定列表中指定下标的元素设置为指定值：** `lset key index value`
> `lset list04 1 10`
>
> **k)将value插入到指定列表中位于pivot元素之前/之后的位置：** 
>
> `linsert key before/after pivot vlaue`
> `linsert list04 before 10 50`
> `linsert list04 after 10 60`



> **4)、redis中有关set类型数据的操作命令：单key-多无序value**
>
> 一个key对应多个vlaue；value之间没有顺序，并且不能重复；通过key直接操作集合，元素无下标。
>
> **a)将一个或者多个元素添加到指定的集合中：**`sadd key value [value value ....]`
>
> 如果元素已经存在，则会忽略。 
> 返回成功加入的元素的个数
> `sadd set01 a b c a`  结果：a b c
> `sadd set01 b d e`
>
> **b)获取指定集合中所有的元素：**`smembers key`
> `smembers set01`
>
> **c)判断指定元素在指定集合中是否存在：**`sismember key member`
> `sismember set01 f`  存在，返回1，不存在，返回0
>
> **d)获取指定集合的长度：**`scard key`
> `scard set01`
>
> **e)移除指定集合中一个或者多个元素：**`srem key member [member .....]`
> `srem set01 b d m`  不存在的元素会被忽略，返回成功移除的个数
>
> **f)随机获取指定集合中的一个或者多个元素：**`srandmember key [count]` 抽奖活动
> count>0：随机获取的多个元素之间不能重复
> count<0: 随机获取的多个元素之间可能重复
> `sadd set02 1 2 3 4 5 6 7 8`
> `srandmember set02` 随机输出一个元素
> `srandmember set02 3` 随机输出3个元素 且不能重复
> `srandmember set02 -3`随机输出3个元素 且可以重复
>
> **g)从指定集合中随机移除一个或者多个元素：**`spop key [count]`
> `spop set02` 如果不写count 则随机移除一个元素 返回移除的值
>
> **h)将指定集合中的指定元素移动到另一个元素：**`smove source dest member`
> `smove set01 set02 a` 将集合set01的a元素移动到set02中
>
> **i)获取第一个集合中有、但是其它集合中都没有的元素组成的新集合：差集**
>
> `sdiff key key [key key ....]`
>
> `sdiff set01 set02 set03`  返回set01中有 set02和set03中都没有的元素
>
> **j)获取所有指定集合中都有的元素组成的新集合：**
>
> `sinter key key [key key ....]`
> `sinter set01 set02 set03` 返回set01  set02和set03中都有的元素
>
> **k)获取所有指定集合中所有元素组成的大集合：**
>
> `sunion key key [key key .....]`
> `sunion set01 set02 set03` 返回set01  set02和set03中所有的元素集合



> **5)、redis中有关hash类型数据的操作命令：单key:field-value field-value field-value **
>
> **a)将一个或者多个field-vlaue对设置到哈希表中：**`hset key filed1 value1 [field2 value2 ....] `如果key field已经存在，把value会把以前的值覆盖掉
> `hset stu1001 id 1001`
> `hset stu1001 name zhangsan age 20`
>
> **b)获取指定哈希表中指定field的值：**`hget key field`
> `hget stu1001 id`
>
> **c)批量将多个field-value对设置到哈希表中：和hset用法完全相同** `hmset key filed1 value1 [field2 value2 ....] `
> `hmset stu1002 id 1002 name lisi age 20`
>
> **d)批量获取指定哈希表中的field的值：**`hmget key field1 [field2 field3 ....]`
> `hmget stu1001 id name age`
>
> **e)获取指定哈希表中所有的field和value：**`hgetall key`
> `hgetall stu1002`
>
> **f)从指定哈希表中删除一个或者多个field：**`hdel key field1 [field2 field3 ....]`
> `hdel stu1002 name age`
>
> **g)获取指定哈希表中所有的filed个数：**`hlen key`
> `hlen stu1001`
>
> **h)判断指定哈希表中是否存在某一个field：**`hexists key field`
> `hexists stu1001 name`
>
> **i)获取指定哈希表中所有的field列表：**`hkeys key`
> `hkeys stu1001`
>
> **j)获取指定哈希表中所有的value列表：**`hvals key`
> `hvals stu1001`
>
> **k)对指定哈希表中指定field值进行整数加法运算**：`hincrby key field int`
> `hincrby stu1001 age 5`
>
> **l)对指定哈希表中指定field值进行浮点数加法运算：**`hincrbyfloat key field float`
> `hset stu1001 score 80.5`
> `hincrbyfloat stu1001 score 5.5`
>
> **m)将一个field-vlaue对设置到哈希表中，当key-field已经存在时，则放弃设置；否则，设置field-value**：`hsetnx key field value`
> `hsetnx stu1001 age 30`



> **6)、redis中有关zset类型数据的操作命令：有序集合**
>
> **跳跃表（跳表）**
>
> 1、简介
>
> ?	有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。
>
> 2、实例
>
> ?	对比有序链表和跳跃表，从链表中查询出51
>
> （1） 有序链表
>
> ![img](file:///F:\markdown笔记\redis\wps8C63.tmp.jpg) 
>
> 要查找值为51的元素，需要从第一个元素开始依次查找、比较才能找到。共需要6次比较。
>
> （2） 跳跃表
>
> ![img](file:///F:\markdown笔记\redis\wps8C64.tmp.jpg) 
>
> 从第2层开始，1节点比51节点小，向后比较。
>
> 21节点比51节点小，继续向后比较，后面就是NULL了，所以从21节点向下到第1层
>
> 在第1层，41节点比51节点小，继续向后，61节点比51节点大，所以从41向下
>
> 在第0层，51节点为要查找的节点，节点被找到，共查找4次。从此可以看出跳跃表比有序链表效率要高
>
> 
>
> 本质上是集合，所有元素不能重复；每一个元素都关联一个分数，redis会根据分数对元素进行自动排序；分数可以重复；既然有序集合中每一个元素都有顺序，那么也都有下标；有序集合中元素的排序规则又与列表中元素的排序规则不一样。 对学生的成绩进行排序
>
> **a)将一个或者多个member及其score值加入有序集合**：`zadd key score member [score member ....]`  如果元素已经存在，则把分数覆盖
> `zadd zset01 20 z1 30 z2 50 z3 40 z4`
>
> **b)获取指定有序集合中指定下标区间的元素**：`zrange key startIndex endIndex [withscores]`
> `zrange zset01 0 -1`  按成绩从小到大返回学生的名字
> `zrange zset01 0 -1 withscores` 按成绩从小到大返回学生的名字加分数
>
> **c)获取指定有序集合中指定分数区间(闭区间)的元素**：`zrangebyscore key min max [withscores]`
> `zrangebyscore zset01 30 50 withscores`  获取成绩从30到50的学生的名字加分数
>
> **d)删除指定有序集合中一个或者多个元素**：`zrem key member [member......]`
> `zrem zset01 z3 z4`
>
> **e)获取指定有序集合中所有元素的个数**：`zcard key`
> `zcard zset01`
>
> **f)获取指定有序集合中分数在指定区间内的元素的个数**：`zcount key min max`
> `zcount zset01 20 50`
>
> **g)获取指定有序集合中指定元素的排名(按照分数从小到大的排名，排名从0开始)**： `zrank key member`
> `zrank zset01 z4` 
>
> **h)获取指定有序集合中指定元素的分数**：`zscore key member`
> `zscore zset01 z4`
>
> **i)获取指定有序集合中指定元素的排名(按照分数从大到小的排名，排名从0开始)：**`zrevrank key membe`
> `zrevrank zset01 z4 `



###### 13、redis的配置文件

> **1)、redis安装完成之后**，在redis的根目录会提供一个配置文件(redis.windows.conf )；可以配置一些redis服务端运行时的一些参数；redis服务可以参考配置文件中的参数进行运行；只有启动redis服务器指定使用的配置文件，参数才会生效；否则，redis会采用默认的参数运行。
>
> **2)、redis配置文件中关于网络的配置：**
> port：配置redis服务运行的端口号；如果不配置port，则redis服务默认使用6379端口。
> bind：配置客户端连接redis服务时，所能使用的ip地址，默认可以使用redis服务器所在主机上任何一个ip。默认情况下，不配置bind，客户端连接redis服务时，通过服务器上任何一个ip都能连接到redis服务；一般情况下，bind都是配置服务器上某一个真实ip，为了安全。一旦配置了bind，客户端就只能通过bind指定的ip地址连接redis服务。
>
> `redis-cli.exe` 连接127.0.0.1本机上的6379端口服务
>
> 一旦redis服务配置了port和bind(如果port不是6379、bind也不是127.0.0.1)，客户端连接redis服务时，就要指定端口和ip：
> `redis-cli.exe -h bind绑定的ip地址 -p port设置的端口`连接bind绑定的ip地址主机上的port设置的端口redis服务；
>
> 客户端关闭redis服务时：`redis-cli.exe -h bind绑定的ip地址 -p port设置的端口 shutdown`
> `redis-cli.exe -h 192.168.11.128 -p 6380 shutdown`
>
> **tcp-keepalive**：连接保活策略 ，由于客户端向服务端的连接是长连接，服务端每隔多久向客户端发起一次ACK请求 以检查客户端是否挂掉，如果挂了则会关闭连接。
>
> **3)、常规配置：**
>
> loglevel：配置日志输出级别，开发阶段配置debug，上线阶段配置notice或者warning.
> logfile：指定日志输出文件。redis在运行过程中，会输出一些日志信息；默认情况下，这些日志信息会输出到控制台；我们可以使用logfile配置日志文件，使redis把日志信息输出到指定文件中。
> databases：配置redis服务默认创建的数据库实例个数，默认值是16。
>
> **4)、安全配置：**
> requirepass：设置访问redis服务时所使用的密码；默认不使用。此参数必须在protected-mode=yes时才起作用。一旦设置了密码验证，客户端连接redis服务时，必须使用密码连接：`redis-cli.exe -h ip -p port -a pwd`



###### 14、redis的持久化：

> redis是内存数据库，它把数据存储在内存中，这样在加快读取速度的同时也对数据安全性产生了新的问题，即当redis所在服务器发生宕机后，redis数据库里的所有数据将会全部丢失。为了解决这个问题，redis提供了持久化功能――RDB和AOF（Append Only File）。redis提供持久化策略，在适当的时机采用适当手段把内存中的数据持久化到磁盘中，每次redis服务启动时，都可以把磁盘上的数据再次加载内存中使用。
>
> **1、RDB策略：**
>
> RDB策略是redis默认的持久化策略，redis服务开启时这种持久化策略就已经默认开启了。**在指定时间间隔内，redis服务执行指定次数的写操作，会自动触发一次持久化操作**。将内存中的数据写入到磁盘中。即在指定目录下生成一个dump.rdb文件。Redis重启会通过加载dump.rdb文件来恢复数据。**RDB的缺点是最后一次持久化后的数据可能丢失。**
>
> ```go
> // RDB原理：
> Redis会复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程，来进行持久化。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。
> 
> // RDB保存的文件：
> RDB保存的文件是dump.rdb文件,位置保存在Redis的启动目录。Redis每次同步数据到磁盘都会生成一个dump.rdb文件，新的dump.rdb会覆盖旧的dump.rdb文件。
> 
> // 配置RDB 持久化策略
> /*
> 1、save <seconds> <changes>：配置复合的快照触发条件，即Redis在seconds秒内key改变changes次，Redis把快照内的数据保存到磁盘中一次。默认的策略是：
> 1分钟内改变了1万次
> 或者5分钟内改变了10次
> 或者15分钟内改变了1次
> 如果要禁用Redis的持久化功能，则把所有的save配置都注释掉。
> 2、stop-writes-on-bgsave-error：当bgsave快照操作出错时停止写数据到磁盘，这样能保证内存数据和磁盘数据的一致性，但如果不在乎这种一致性，要在bgsave快照操作出错时继续写操作，这里需要配置为no。
> 3、rdbcompression：设置对于存储到磁盘中的快照是否进行压缩，设置为yes时，Redis会采用LZF算法进行压缩；如果不想消耗CPU进行压缩的话，可以设置为no，关闭此功能。
> 4、rdbchecksum：在存储快照以后，还可以让Redis使用CRC64算法来进行数据校验，但这样会消耗一定的性能，如果系统比较在意性能的提升，可以设置为no，关闭此功能。
> 5、dbfilename：Redis持久化数据生成的文件名，默认是dump.rdb，也可以自己配置。
> 6、dir：Redis持久化数据生成文件保存的目录，默认是./即redis的启动目录，也可以自己配置。
> */
> 在客户端执行FLUSHDB或者FLUSHALL或者SHUTDOWN时，也会把快照中的数据保存到dump.rdb，只不过这种操作已经把数据清空了，保存的也是空文件，没有意义。
> 
> // 手动保存RDB快照
> save命令执行一个同步保存操作，将当前Redis实例的所有数据快照(snapshot)以RDB文件的形式保存到硬盘。由于save指令会阻塞所有客户端，所以保存数据库的任务通常由BGSAVE命令异步地执行，而save作为保存数据的最后手段来使用，当负责保存数据的后台子进程不幸出现问题时使用。
> 
> // RDB数据恢复
> 通过脚本将Redis产生的dump.rdb文件备份(cp dump.rdb dump_bak.rdb)，每次启动Redis前，把备份的dump.rdb文件替换到Redis相应的目录(在redis.conf中配的的dir目录)下，Redis启动时会加载dump.rdb文件，并且把数据读到内存中。
> 
> // RDB小结
> Redis默认开启RDB持久化方式，适合大规模的数据恢复但它的数据一致性和完整性较差。
> ```
>
> **2、AOF策略**：
>
> AOF(Append Only File)，它的出现是为了弥补RDB的不足（数据的不一致性），所以它采用日志的形式来记录每个写操作(读操作不记录),并追加到文件中,只许追加文件但不可以改写文件。Redis 重启会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。效率低下，redis默认不开启。AOF保存的文件是appendonly.aof文件 ,位置保存在Redis的启动目录。如果开启了AOF，Redis每次记录写操作都会往appendonly.aof文件追加新的日志内容。往磁盘进行写操作
>
> ```go
> // 配置AOF持久化策略
> 1、appendonly：配置是否开启AOF，yes表示开启，no表示关闭。默认是no。
> 2、appendfilename：AOF保存文件名
> 3、appendfsync：AOF异步持久化策略
>  always：同步持久化，每次发生数据变化会立刻写入到磁盘中。性能较差但数据完整性比较好（慢，安全）
>  everysec：出厂默认推荐，每秒异步记录一次（默认值）
>  no：不即时同步，由操作系统决定何时同步。
> 4、no-appendfsync-on-rewrite：重写时是否可以运用appendsync，默认no，可以保证数据的安全性。
> 
> // AOF数据恢复
> 通过脚本将Redis产生的appendonly.aof文件备份(cp appendonly.aof appendonly_bak.aof)，每次启动Redis前，把备份的appendonly.aof文件替换到Redis相应的目录(在redis.conf中配的的dir目录)下，只要开启AOF的功能，Redis每次启动，会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。但在实际开发中，可能因为某些原因导致appendonly.aof 文件格式异常，从而导致数据还原失败，可以通过命令redis-check-aof --fix appendonly.aof 进行修复 。会把出现异常的部分往后所有写操作日志去掉。
> 
> // AOF的重写
> AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制,当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。AOF文件持续增长而过大时，会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)。重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此设定Redis要满足一定条件才会进行重写。 Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。当然，也可以在配置文件中进行配置。
> 会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，redis4.0版本后的重写，是指上就是把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作。
> 
> // AOF小结：
> Redis需要手动开启AOF持久化方式，AOF的数据完整性比RDB高，但记录内容多了，会影响数据恢复的效率。关于Redis持久化的使用：若只打算用Redis做缓存，可以关闭持久化。若打算使用Redis的持久化，建议RDB和AOF都开启。其实RDB更适合做数据的备份，留一后手。AOF出问题了，还有RDB。AOF与RDB模式可以同时启用，这并不冲突。如果AOF是可用的，那Redis启动时将自动加载AOF，这个文件能够提供更好的持久性保障。
> ```
>
> 小结：根据数据的特点决定开启哪种持久化策略；一般情况，开启RDB足够了。官方推荐两个都启用。如果对数据不敏感，可以选单独用RDB。不建议单独用 AOF，因为可能会出现Bug。如果只是做纯内存缓存，可以都不用。
>
> ```shell
> 重写流程
> （1）bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。
> （2）主进程fork出子进程执行重写操作，保证主进程不会阻塞。
> （3）子进程遍历redis内存中数据到临时文件，客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。
> （4）
>   1).子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。
>   2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件。
> （5）使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。
> ```



###### 15、Redis的事务：

> 数据库的事务：把一组数据库命令放在一起执行，保证操作原子性，要么同时成功，要么同时失败。
>
> Redis的事务：允许把一组redis命令放在一起，将命令进行序列化，然后一起执行，**保证部分原子性。**

**Redis的事务：**

```go
// multi 
用来标记一个事务的开始。Redis会将后续的命令逐个放入队列中，然后使用EXEC命令原子化地执行这个命令序列。组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消。如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。

// exec 
用来执行事务队列中所有的命令。在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。
如果在把命令压入队列的过程中报错，则整个队列中的命令都不会执行，执行结果报错；如果在压队列的过程中正常，在执行队列中某一个命令报错，则只会影响本条命令的执行结果，其它命令正常运行；
返回值：这个命令的返回值是一个数组，其中的每个元素分别是原子化事务中的每个命令的返回值。 
// redis的事务只能保证部分原子性：
a)如果一组命令中，有在压入事务队列过程中发生错误的命令，则本事务中所有的命令都不执行，能够保证事务的原子性。
multi
set k3 v3
seta kk vv
set k4 v4
exec
b)如果一组命令中，在压入队列过程中正常，但是在执行事务队列命令时发生了错误，则只会影响发生错误的命令，不会影响其它命令的执行，不能够保证事务的原子性。
multi
set k3 v3
incr k3 // string无法自增 所以执行时不执行
set k4 v4
exec

// discard：清除所有已经压入队列中的命令，并且结束整个事务。
multi
set k5 v5 
set k6 v6
discard

银行卡余额 先查 再删除，若同时有多个用户需要修改同一个账户，就需要加锁
// watch：监控某一个键，当事务在执行过程中，此键代码的值发生变化，则本事务放弃执行；否则，正常执行。当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的。如果被监控的key值在本事务外有修改时，则本事务所有指令都不会被执行。Watch命令相当于关系型数据库中的乐观锁。
加一个字段 每次改之前先查version，修改时条件为version和之前相同 并且修改余额加version
不同时，重新查 重新赋值
`update table set balance - balance-dept,version = version + 1 where id = xxxx and version = 100`
set balance 100 // 初始化数据
set balance2 1000
watch balance // 监控balance
multi // 开启事务
decrby balance 50
incrby balance2 50
exec // 执行事务，如果在此期间balance被别人修改 则放弃执行事务

// unwatch：放弃监控所有的键。清除所有先前为一个事务监控的键。如果在watch命令之后你调用了EXEC或DISCARD命令，那么就不需要手动调用UNWATCH命令。
watch version
unwach // 取消监控所有key
multi
decrby balance 50
incrby balance2 50
exec

// 事务总结
1、单独的隔离操作：事务中的所有命令都会序列化、顺序地执行。事务在执行过程中，不会被其它客户端发来的命令请求所打断，除非使用watch命令监控某些键。
2、不保证事务的原子性：redis同一个事务中如果一条命令执行失败，其后的命令仍然可能会被执行，redis的事务没有回滚。Redis已经在系统内部进行功能简化，这样可以确保更快的运行速度，因为Redis不需要事务回滚的能力。

悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。
乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis就是利用这种check-and-set机制实现事务的。


10.6.Redis事务三特性
*单独的隔离操作 
事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 
*没有隔离级别的概念 
队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行
*不保证原子性 
事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 
```



###### 16、redis消息的发布与订阅：

> Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。Redis 客户端可以订阅任意数量的频道。redis客户端订阅频道，消息的发布者往频道上发布消息，所有订阅此频道的客户端都能够接受到消息。
>
> **客户端间消息的通信**
>
> 1)subscribe：订阅一个或者多个频道的消息。返回值：订阅的消息
>
> `subscribe ch1 ch2 ch3 `
>
> 2)publish：将消息发布到指定频道。返回值：数字。接收到消息订阅者的数量。
>
> `publish ch1 hello`
>
> 3)psubcribe：订阅一个或多个符合给定模式的频道。模式以 * 作为通配符，例如：news.* 匹配所有以 news. 开头的频道。返回值：订阅的信息。
>
> `psubscribe news.*`



###### 17、redis的集群 高可用：6个9 99.9999% 全年停机不超过32秒

**从redis 3.0之后版本支持redis-cluster集群，至少需要3(Master)+3(Slave)才能建立集群**

Redis Cluster集群节点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。

> 1、所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。
>
> 2、节点的fail是通过集群中超过半数的节点检测失效时才生效。 
>
> 3、客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。 
>
> 4、redis-cluster把所有的物理节点映射到[0-16383]slot上（不一定是平均分配）,cluster 负责维护 
>
> 5、Redis集群预分好16384个哈希槽，当需要在 Redis 集群中放置一个 key-value 时， redis 先对key 使用crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。



###### 主从复制：主少从多、主写从读、读写分离、主写同步复制到从。

> 主机数据更新后根据配置和策略，自动同步到从机的master/slave机制，Master以写为主，Slave以读为主。多个请求发送到多个服务器进行处理
>
> **搭建一主二从原理**
>
> 1、设从(库)不设主(库)      从机上执行 slaveof 主库IP 主库端口
>
> 2、主写从读、读写分离
>
> 3、主断从待命、从断重新设
>
> **搭建一主二从redis集群：**
>
> **1)搭建三台redis服务：**
>
> > 使用一个redis模拟三台redis服务
> > 提供三份redis配置文件：redis6379.conf、redis6380.conf、redis6381.conf
> > 修改三份配置文件：以redis6379.conf为例，改的内容
> >
> > ```
> > bind 127.0.0.1
> > port 6379
> > logfile "6379.log"
> > dbfilename dump6379.rdb
> > ```
> >
> > 分别使用三个redis配置文件，启动三个redis服务
>
> **2)通过redis客户端分别连接三台redis服务：**
>
> > `redis-cli.exe -h 127.0.0.1 -p 6379`
> > `redis-cli.exe -h 127.0.0.1 -p 6380`
> > `redis-cli.exe -h 127.0.0.1 -p 6381`
>
> **3)查看三台redis服务在集群中的主从角色：**
> `info replication`
> 默认情况下，所有的redis服务都是主机，即都能写和读，但是都还没有从机。
>
> **4)先在6379进行写操作:**
> `set k1 v1`
> 三台redis服务互相独立，互不影响，另外两个无k1 v1。
>
> **5)设置主从关系：设从不设主 6379为主机**
>
> 在6380上执行：`slaveof 127.0.0.1 6379`
> 在6381上执行：`slaveof 127.0.0.1 6379`
>
> 查看6380和6381服务的主从角色：`info replication`。此时6380 和6381已经有主机上已有的数据k1 v1了，此时为全量复制
>
> **6)全量复制：一旦主从关系确定，会自动把主库上已有的数据同步复制到从库。** 
>
> 在6380和6381上执行：`keys *`
>
> **7)增量复制：主库写数据会自动同步到从库。**
>
> 在6379上执行：`set k2 v2`
> 在6380和6381上执行：`keys *` 自动复制 
>
> **8)主写从读，读写分离：** 
>
> 在6380和6381上执行：`set k3 v3`  ===>报错  因为从只能读
>
> **9)主机宕机、从机原地待命:**
>
> 关闭6379服务：`redis-cli.exe -h 127.0.0.1 -p 6379 shutdown`
>
> 从机角色还是从属于6379的从机 只不过连接状态变为了down，不影响读只不过数据不进行更新了
>
> **10)主机恢复、一切恢复正常：**
>
> 重启6379服务：`redis-server`
>
> 客户端连接6379：`redis-cli -h 127.0.0.1 -p 6379`
>
> 从机角色还是从属于6379的从机 只不过连接状态变为了up
>
> **11)从机宕机、主机少一个从机、其它从机不变：**
>
> 关闭6380服务： `redis-cli.exe -h 127.0.0.1 -p 6380 shutdown`
>
> 查看6379服务的主从角色：info replication  发现从机数量减少一个
>
> **12)从机恢复、需要重新设置主从关系：**
>
> 重启6380服务：`redis-server.exe redis6380.conf &`
> 客户端连接6380：`redis-cli.exe -h 127.0.0.1 -p 6380` 此时变为主机 需要重新设置，在6380上执行： slaveof 127.0.0.1 6379
>
> **13)从机上位：** 主机出现问题 从机代替主机
>
> > **a)主机宕机、从机原地待命：**
> >
> > 关闭6379服务：`redis-cli.exe -h 127.0.0.1 -p 6379 shutdown`
> >
> > **b)从机断开原来主从关系：**
> >
> > 在6380上执行：`slaveof no one`
> > 查看6380服务的主从角色：`info replication `  此时6380变为主机
> >
> > **c)重新设置主从关系：**
> >
> > 在6381上执行：`slaveof 127.0.0.1 6380`
> >
> > **d)之前主机恢复、变成孤家寡人：** 后面可以做主机也可以做从机
> >
> > 重启6379服务：`redis-server.exe redis6379.conf &`
> > 客户端连接6379：`redis-cli.exe -h 127.0.0.1 -p 6379`
> >
> > **e)天堂变地狱：**让他先做从机
> >
> > 在6379上执行：`slaveof 127.0.0.1 6381`  
> > 在6381上执行：`info replication`   既是主机又是从机 6379的主机 6380的从机
>
> ![图片2](F:\markdown笔记\redis\图片2.png)
>
> 一台主机配置多台从机，一台从机又可以配置多台从机，从而形成一个庞大的集群架构。
> 减轻一台主机的压力，但是增加了服务间的延迟时间。
>
> Redis的主从复制最大的缺点就是延迟，主机负责写，从机负责备份，这个过程有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，从机器数量的增加也会使这个问题更加严重。

Slave启动成功连接到master后会发送一个sync命令，Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步

**全量复制**

slave启动成功连接到master后会发送一个sync命令；Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步；slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。只要是重新连接master,一次完全同步（全量复制)将被自动执行。

**增量复制**

Master将新的所有收集到的修改命令依次传给slave,完成同步。但是只要是重新连接master,一次完全同步（全量复制)将被自动执行

**高并发**

> **高并发**（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS （Query Per Second），并发用户数等。 
>
> **响应时间：**系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是 系统的响应时间。 
>
> **吞吐量：**单位时间内处理的请求数量。 
>
> **QPS**：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。 
>
> **并发用户数：** 同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在一定程度上代表了系统的并发用户数。 
>
> **提升系统的并发能力** 
>
> 提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。 
>
> **垂直扩展** 
>
> 提升单机处理能力。垂直扩展的方式又有两种： 
>
> 1）增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
>
> 2）提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间； 
>
> 总结：不管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是水平扩展。 
>
> **水平扩展** 
>
> 水平扩展：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，难点在于：如何在架构各层进行可水平扩展的设计

**高可用高性能**







###### 18、redis哨兵模式：主机宕机、从机上位的自动版。哨兵模式三大任务：监控，提醒，自动故障迁移

> 从机上位的自动版。Redis提供了哨兵的命令，哨兵命令是一个独立的进程，哨兵通过发送命令，来监控主从服务器的运行状态，如果检测到master故障了根据投票数自动将某一个slave转换为master，然后通过消息订阅模式通知其它slave，让它们切换主机。然而，一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多哨兵进行监控。
>
> **什么时候整个集群不可用(cluster_state:fail)**
>
> 如果集群任意master挂掉,且当前master没有slave.集群进入fail状态,也可以理解成集群的slot映射[0-16383]不完整时进入fail状态。
>
>  如果集群超过半数以上master挂掉，无论是否有slave，集群进入fail状态. 
>
> ```
> 1、不时地监控redis是否按照预期良好地运行; 
> 2、如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 
> 3、能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave的话) 中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的新地址。
> 4、哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。
> ```
>
> **1)搭建一主二从集群架构**
>
> ```
> **1)搭建三台redis服务：**
> 
> > 使用一个redis模拟三台redis服务
> > 提供三份redis配置文件：redis6379.conf、redis6380.conf、redis6381.conf
> > 修改三份配置文件：以redis6379.conf为例，改的内容
> >
> > ```
> > bind 127.0.0.1
> > port 6379
> > logfile "6379.log"
> > dbfilename dump6379.rdb
> > ```
> >
> > 分别使用三个redis配置文件，启动三个redis服务
> 
> **2)通过redis客户端分别连接三台redis服务：**
> 
> > `redis-cli.exe -h 127.0.0.1 -p 6379`
> > `redis-cli.exe -h 127.0.0.1 -p 6380`
> > `redis-cli.exe -h 127.0.0.1 -p 6381`
> 
> **3)查看三台redis服务在集群中的主从角色：**
> `info replication`
> 默认情况下，所有的redis服务都是主机，即都能写和读，但是都还没有从机。
> 
> **4)先在6379进行写操作:**
> `set k1 v1`
> 三台redis服务互相独立，互不影响，另外两个无k1 v1。
> 
> **5)设置主从关系：设从不设主 6379为主机**
> 
> 在6380上执行：`slaveof 127.0.0.1 6379`
> 在6381上执行：`slaveof 127.0.0.1 6379`
> 
> 查看6380和6381服务的主从角色：`info replication`。此时6380 和6381已经有主机上已有的数据k1 v1了，此时为全量复制
> ```
>
> **2)提供哨兵配置文件：**
>
> 在redis安装目下创建配置文件：redis_sentinel.conf，并编辑里边的内容：`sentinel monitor dc-redis 127.0.0.1 6379 1`表示：指定监控主机的ip地址，port端口，得到哨兵的投票数(当哨兵投票数大于或者等于此数时切换主从关系)。
>
> **3)启动哨兵服务：**
>
> `redis-sentinel redis_sentinel.conf`
>
> **4)主机宕机：**
>
> 关闭6379服务：`redis-cli.exe -h 127.0.0.1 -p 6379 shutdown`
>
> 哨兵程序自动选择从机上位。
>
> **5)之前主机恢复：自动从属于新的主机。**
>
> 重启6379服务：`redis-server.exe redis6379.conf &`
> 客户端连接6379：`redis-cli.exe -h 127.0.0.1 -p 6379`
>
> 
>
> 由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。
>
> 
>
> Redis 集群实现了对Redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。
>
> Redis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。







###### **19、Redis缓存与数据库一致性**

> **一、实时同步** 
>
> 对强一致要求比较高的，应采用实时同步方案，即查询缓存查询不到再从DB查询，保存到缓存；更新缓 
>
> 存时，先更新数据库，再将缓存的设置过期(建议不要去更新缓存内容，直接设置缓存过期)。 
>
> **二、异步队列** 
>
> 对于并发程度较高的，可采用异步队列的方式同步，可采用kafka等消息中间件处理消息生产和消费。 
>
> 用户进行高并发操作（读写）走Redis，MYSQL进行数据异步处理。 例如进行定时任务： 每天凌晨1点 将Redis中数据得到，更新到MYSQL(一次） 
>
> 或者使用消息队列： RabbitMQ RocketMQ Kafka 。作用： 异步、流量销峰 





###### **Redis新数据类型**

> **Bitmaps**
>
> 现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 例如“abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、 01100010和01100011，如下图
>
> ![img](file:///F:\markdown笔记\redis\wps611A.tmp.jpg) 
>
> 合理地使用操作位能够有效地提高内存使用率和开发效率。Redis提供了Bitmaps这个“数据类型”可以实现对位的操作：
>
> （1） Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。
>
> （2） Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。
>
> **1、setbit**
>
> （1）格式
>
> `setbit<key><offset><value>`设置Bitmaps中某个偏移量的值（0或1）offset:偏移量从0开始
>
> （2）实例
>
> 每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id。 
>
> 很多应用的用户id以一个指定数字（例如10000） 开头， 直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费， 通常的做法是每次做setbit操作时将用户id减去这个指定数字。在第一次初始化Bitmaps时， 假如偏移量非常大， 那么整个初始化过程执行会比较慢， 可能会造成Redis的阻塞。
>
> **2、getbit**
>
> （1）格式
>
> `getbit<key><offset>`获取Bitmaps中某个偏移量的值
>
> （2）实例
>
> 获取id=8的用户是否在2020-11-06这天访问过， 返回0说明没有访问过
>
> **3、bitcount**
>
> 统计字符串被设置为1的bit数。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，start、end 是指bit组的字节的下标数，二者皆包含。
>
> （1）格式
>
> `bitcount<key>[start end]` 统计字符串从start字节到end字节比特值为1的数量 
>
> （2）实例
>
> 计算2022-11-06这天的独立访问用户数量





**缓存穿透**

**问题描述**

**缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。** 

> **解决方案：**
>
> （1） **对空值缓存：**如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。缺点：对内存占有消耗过大。
>
> （2） **设置可访问的名单（白名单）：**
>
> 使用bitmaps类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。
>
> **采用布隆过滤器**：(布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量(位图)和一系列随机映射函数（哈希函数）。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。)将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。
>
> （3） **进行实时监控：**当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务
>
> 用户为什么能在前端发送一个后端不存在的数据？？需要进行逻辑处理。
>
> 真实URL `http://localhost:8080/user?id=1001 `加密后的1001为afdafda79u92dsvdsaf 所以前端显示`http://localhost:8080/user?id=afdafda79u92dsvdsaa `
>
> 后端：afdafda79u92dsvdsaf解密得到100，若前端恶意拼接，解密失败，数据格式不正确



**缓存击穿**

**问题描述**

**热点key:某个key访问非常频繁，当key失效的时候有大量线程来构建缓存，导致负载增加，系统崩溃。**

**解决方案**

key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题。

> 1 使用锁，单机用synchronized,lock等，分布式用分布式锁。
>
> 2 缓存过期时间不设置，而是设置在key对应的value里。如果检测到存的时间超过过期时间则异步更新缓存。 
>
> 3 在value设置一个比过期时间t0小的过期时间值t1，当t1过期的时候，延长t1并做更新缓存操作。 
>
> 4 数据预热



**缓存雪崩**

**缓存大量失效的时候，引发大量查询数据库**

**解决方案**

如果缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。 这个没有完美解决办法，但可以分析用户行为，尽量让失效时间点均匀分布。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。 缓存失效时的雪崩效应对底层系统的冲击非常可怕！

> （1） **使用锁或队列**：
>
> 用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况
>
> （2） **设置过期标志更新缓存：**
>
> 记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。
>
> （3） **将缓存失效时间分散开：**
>
> 比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
>
> （4）**数据预热** 
>
> 可以通过缓存reload机制，预先去更新缓存，再即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀



**缓存倾斜** 

缓存倾斜又称为：热点key倾斜。 缓存中存在这个key,但是由于这个key突然成为高热点key,比如明星离婚，这样导致大量的用户突然高并发的访问这个高热点key所在的那台缓存服务器，最终导致那台缓存服务器崩掉，继而请求又到达下一个缓存服务器，下一个缓存服务器又承受不住而崩掉，最终导致整个缓存模块崩掉。（是缓存崩掉了，跟数据库关系不大） 

> **数据倾斜的原因:** 
>
> 1. 存在bigkey 
>
>    ?	业务层避免bigkey 数据量大的key
>
>    ?	将集合类型的bigkey拆分为多个小集合 
>
> 2. slot手工分配不均 
>
> **方案一：**
>
> 将一些特别热点的key直接放在客户端进行存储，设置过期时间，过期后再从redis中查询。 
>
> **方案二：**负载均衡
>
> 我们可以将这个热点key复制出多个子key，每个子key的value值一样，查询的时候使用hash取模算法，将压力分摊到不同的节点。或者存储在二级缓存 比如jvm缓存中 
>
> **方案三：**
>
> 增加实例配置/集群配置 





**分布式锁**

**问题描述**

随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！

分布式锁主流的实现方案：

> \1. 基于数据库实现分布式锁
>
> \2. 基于缓存（Redis等）
>
> \3. 基于Zookeeper
>
> 每一种分布式锁解决方案都有各自的优缺点：
>
> \1. 性能：redis最高
>
> \2. 可靠性：zookeeper最高

这里，我们就基于redis实现分布式锁。

> 使用Redis实现分布式锁最简单的方案是在获取锁之前先查询一下以该锁为key对应的value存不存在。`SET my_key my_value NX PX milliseconds`其中，NX表示只有当键key不存在的时候才会设置key的值，PX表示设置键key的过期时间，单位是毫秒。
>
> 如果存在，则说明该锁被其他客户端获取了，否则的话就尝试获取锁，获取锁的方法很简单，只要以该锁为key，设置一个随机的值就行了。设置最长TTL。
>
> 比如，我们有一批任务需要由多个分布式线程处理，每个任务都有一个taskId，为了保证每个任务只被执行一次，在工作线程执行任务之前，先获取该任务的锁，锁的key可以为taskId。
>
> 但是：考虑这样一种情况：客户端A获取锁的时候设置了key的过期时间为2秒，然后客户端A在获取到锁之后，业务逻辑方法doSomething执行了3秒（大于2秒），当执行完业务逻辑方法的时候，客户端A获取的锁已经被Redis过期机制自动释放了，因此客户端A在获取锁经过2秒之后，该锁可能已经被其他客户端获取到了。当客户端A执行完doSomething方法之后接下来就是执行releaseLock方法释放锁了，由于前面说了，该锁可能已经被其他客户端获取到了，因此这个时候释放锁就有可能释放的是其他客户端获取到的锁。 
>
> 会出现释放了**别的客户端申请的锁**的问题，那么该如何进行改进呢？
>
> 有一个很简单的方法是，我们设置key的时候，将value设置为一个随机值r，当释放锁，也就是删除key的时候，不是直接删除，而是先判断该key对应的value是否等于先前设置的随机值，只有当两者相等的时候才删除该key，由于每个客户端产生的随机值是不一样的，这样一来就不会误释放别的客户端申请的锁了。 

在redis主从结构下，出于性能的考虑，redis采用的是主从异步复制的策略，这会导致短时间内主库和从库数据短暂的不一致。试想，当某一客户端刚刚加锁完毕，redis主库还没有来得及和从库同步就挂了，之后从库中**新选拔出的主库是没有对应锁记录**的，这就可能导致多个客户端加锁成功，破坏了锁的互斥性。