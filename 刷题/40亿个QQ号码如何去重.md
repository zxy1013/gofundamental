文件中有40亿个QQ号码，请设计算法对QQ号码去重，相同的QQ号码仅保留一个，内存限制1G。

##### **方法一：排序**

很自然地，最简单的方式是对所有的QQ号码进行排序，重复的QQ号码必然相邻，保留第一个，去掉后面重复的就行。可是，面试官要问你，去重一定要排序吗？显然，排序的时间复杂度太高了，无法通过腾讯面试。

##### **方法二：hashmap**

既然直接排序的时间复杂度太高，那就用hashmap吧，具体思路是把QQ号码记录到hashmap中：

> mapFlag[123] = true
>
> mapFlag[567] = true
>
> mapFlag[123] = true
>
> mapFlag[890] = true

由于hashmap的去重性质，可知实际自动变成了：

> mapFlag[123] = true
>
> mapFlag[567] = true
>
> mapFlag[890] = true

很显然，只有123，567，890存在，所以这也就是去重后的结果。可是，面试官又要问你了：实际要存40亿QQ号码，1G的内存够分配这么多空间吗？显然不行，无法通过腾讯面试。

##### **方法三：文件切割**

显然，这是海量数据问题。看过很多面经的求职者，自然想到文件切割的方式，避免内存过大。可是，绞尽脑汁思考，要么使用文件间的归并排序，要么使用桶排序，反正最终是能排序的。既然排序好了，那就能实现去重了，貌似就万事大吉了。我只能坦白地说，高兴得有点早哦。接着，面试官又要问你：这么多的文件操作，效率自然不高啊。显然，无法通过腾讯面试。

##### **方法四：bitmap**

来看绝招！我们可以对hashmap进行优化，采用bitmap这种数据结构，可以顺利地同时解决时间问题和空间问题。在很多实际项目中，bitmap经常用到。我看了不少组件的源码，发现很多地方都有bitmap实现，bitmap图解如下：

![图片](F:\markdown笔记\image\640.png)

这是一个unsigned char类型，可以看到，共有8位，取值范围是[0, 255]，如上这个unsigned char的值是255，它能标识0~7这些数字都存在。同理，如下这个unsigned char类型的值是254，它对应的含义是：1~7这些数字存在，而数字0不存在：

![图片](F:\markdown笔记\image\641.png)

由此可见，一个unsigned char类型的数据，可以标识0~7这8个整数的存在与否。以此类推：

- 一个unsigned int `32bit`类型数据可以标识0~31这32个整数的存在与否。
- 两个unsigned int类型数据可以标识0~63这64个整数的存在与否。

显然，可以推导出来：512MB(`512*1000000*8 = 2^9*10^6*2^3 = 2^32`)大小足够标识所有QQ号码的存在与否，请注意：QQ号码的理论最大值为2^32 - 1，大概是43亿左右。

接下来的问题就很简单了：用512MB的unsigned int数组来记录文件中QQ号码的存在与否，形成一个bitmap，比如：

> bitmapFlag[123] = 1
>
> bitmapFlag[567] = 1
>
> bitmapFlag[123] = 1
>
> bitmapFlag[890] = 1

实际上就是：

> bitmapFlag[123] = 1
>
> bitmapFlag[567] = 1
>
> bitmapFlag[890] = 1

然后从小到大遍历所有正整数(4字节)，当bitmapFlag值为1时，就表明该数是存在的。而且，从上面的过程可以看到，自动实现了去重。显然，这种方式可以通过腾讯的面试。

##### **扩展练习一**

文件中有40亿个互不相同的QQ号码，请设计算法对QQ号码进行排序，内存限制1G。很显然，直接用bitmap, 标记这40亿个QQ号码的存在性，然后从小到大遍历正整数，当bitmapFlag的值为1时，就输出该值，输出后的正整数序列就是排序后的结果。请注意，这里必须限制40亿个QQ号码互不相同。通过bitmap记录，客观上就自动完成了排序功能。

##### **扩展练习二**

文件中有40亿个互不相同的QQ号码，求这些QQ号码的中位数，内存限制1G。直接用bitmap排序，当场搞定中位数。

##### **扩展练习三**

文件中有40亿个互不相同的QQ号码，求这些QQ号码的top-K，内存限制1G。直接用bitmap排序，当场搞定top-K问题。

##### **扩展练习四**

文件中有80亿个QQ号码，试判断其中是否存在相同的QQ号码，内存限制1G。我知道，一些吸取了经验教训的人肯定说，直接bitmap啊。然而，又一次错了。根据容斥原理可知：因为QQ号码的个数是43亿左右(理论值2^32 - 1)，所以80亿个QQ号码必然存在相同的QQ号码。



##### **如何给100亿个数字排序** 

今天要给100亿个数字排序，100亿个 int 型数字放在文件里面大概有 37.2GB，非常大，内存一次装不下了。那么肯定是要拆分成小的文件一个一个来处理，最终在合并成一个排好序的大文件。 

**实现思路**

> 1.把这个37GB的大文件，用哈希分成1000个小文件，每个小文件平均38MB左右（理想情况），把100亿个数字对1000取模，模出来的结果在0到999之间，每个结果对应一个文件，所以我这里取的哈希函数是 h = x % 1000，哈希函数取得"好"，能使冲突减小，结果分布均匀。 
>
> 2.拆分完了之后，得到一些几十MB的小文件，那么就可以放进内存里排序了，可以用快速排序，归并排序，堆排序等等。 
>
> 3.1000个小文件内部排好序之后，就要把这些内部有序的小文件，合并成一个大的文件，可以用**二叉堆**来做1000路合并的操作，每个小文件是一路，合并后的大文件仍然有序。 首先遍历1000个文件，每个文件里面取第一个数字，组成 (数字, 文件号) 这样的组合加入到堆里（假设是从小到大排序，用小顶堆），遍历完后堆里有1000个 (数字，文件号) 这样的元素 ，然后不断从堆顶拿元素出来，每拿出一个元素，把它的文件号读取出来，然后去对应的文件里，加一个元素进入堆，直到那个文件被读取完。拿出来的元素当然追加到最终结果的文件里。 按照上面的操作，直到堆被取空了，此时最终结果文件里的全部数字就是有序的了。 

**思维拓展**

> 类似的100亿个数字求和，求中位数，求平均数，套路就是一样的了。 
>
> 求和：统计每个小文件的和，返回给master再求和就可以了。 
>
> 求平均数：上面能求和了，再除以100亿就是平均数了 
>
> 求中位数：在排序的基础上，遍历到中间的那个数就是中位数了。

**不对数字进行哈希，直接平均分成1000份，进行内部排序后，直接进行 k 路归并排序，也是可以的。** 



##### **统计海量数据中出现次数最多的前10个IP**

**场景** 

> 这是一个 ip 地址 127.0.0.1 
>
> 假设有100亿个这样的 ip 地址存在文件中 
>
> 这个文件大小大约是 100GB 

**问题：要统计出100亿个ip中，重复出现次数最多的前10个** 

**分析** 

100GB 几乎不可能一次加载进内存进行操作，所以必须要拆分，那么可以利用分治的思想，把规模大的问题化小，然后解决各个小的问题，最后得出结果。 

**实现思路**

1. ipv4 地址是一个 32 位的整数，可以用 uint 保存。 我先设计一个哈希函数，把100个G的文件分成10000份，每份大约是 10MB，可以加载进内存了。 例如：我设计一个简单的哈希函数是 f(ip) = ip % 10000，(ip 是个32位整数) ，那么 5 % 10000 = 5，不管 5 在哪个地方 5 % 10000 的结果都是 5，这就保证了相同的 ip 会被放在同一个子文件中，方便统计，相同的元素经过同一个哈希函数，得出的哈希值是一样的。那么我把100亿个 ip，都进行 ip % 10000 的操作，就完成了 100GB 文件分解成 10000个子文件的任务了。当然实际中哈希函数的选取很重要，尽量使得元素分布均匀， 哈希冲突少的函数才是最好的。 记住，我把上面这个分解的过程叫做 **Map**，由一台叫 **master** 的计算机完成这个工作。 

2. 10MB 的小文件加进内存，统计出出现次数最多的那个ip。10MB 的小文件里面存着很多 ip，他们虽然是乱序的，但是相同的 ip 会映射到同一个文件中来！ 那么可以用二叉树统计出现次数，二叉树节点保存（ip, count）的信息，把所有 ip 插入到二叉树中，如果这个 ip 不存在，那么新建一个节点, count 标记 1，如果有，那么把 count++，最终遍历一遍树，就能找出 count 最大的 ip 了。 我把这个过程叫做 **Reduce**，由很多台叫 **worker** 的计算机来完成。 每个 worker 至少要找出最大的前10个 ip 返回给 master，master 最后会收集到 10000 * 10 个 ip，大约 400KB，然后再找出最大的前 10 个 ip 就可以了。 

3. 最简单的遍历10遍，每次拿个最大值出来就可以了，或者用快速排序，堆排序，归并排序等等方法，找出最大前 k 个数也行。 