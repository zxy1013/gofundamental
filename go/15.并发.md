**并发**

并发是编程里面一个非常重要的概念，Go语言在语言层面天生支持并发，这也是Go语言流行的一个很重要的原因。

**并发与并行**

并发：同一时间段内执行多个任务。

并行：同一时刻执行多个任务。

Go语言的并发通过`goroutine`实现。`goroutine`类似于线程，属于用户态的线程，我们可以根据需要创建成千上万个`goroutine`并发工作。`goroutine`是由Go语言的运行时（runtime）调度完成，而其余语言中的线程是由操作系统调度完成。Go语言还提供`channel`在多个`goroutine`间进行通信。`goroutine`和`channel`是 Go 语言秉承的 CSP（Communicating Sequential Process）并发模式的重要实现基础。

**goroutine**

在java/c++中要实现并发编程的时候，通常需要自己维护一个线程池，并且需要自己去包装一个又一个的任务，同时需要自己去调度线程执行任务并维护上下文切换，这一切通常会耗费程序员大量的心智。那么能不能有一种机制，程序员只需要定义很多个任务，让系统去帮助我们把这些任务分配到CPU上实现并发执行呢？

Go语言中的`goroutine`就是这样一种机制，`goroutine`的概念类似于线程，但 `goroutine`是由Go的运行时（runtime）调度和管理的。Go程序会智能地将 goroutine 中的任务合理地分配给每个CPU。Go语言之所以被称为现代化的编程语言，就是因为它在语言层面已经内置了调度和上下文切换的机制。在Go语言编程中不需要去自己写进程、线程、协程，当需要让某个任务并发执行的时候，只需要把这个任务包装成一个函数，开启一个`goroutine`去执行这个函数就可以了

**使用goroutine**

Go语言中使用`goroutine`非常简单，只需要在调用函数的时候在前面加上`go`关键字，就可以为一个函数创建一个`goroutine`。一个`goroutine`必定对应一个函数，可以创建多个`goroutine`去执行相同的函数。

**启动单个goroutine**

启动goroutine的方式非常简单，只需要在调用的函数（普通函数和匿名函数）前面加上一个`go`关键字。在程序启动时，Go程序就会为`main()`函数创建一个默认的`goroutine`。当main()函数返回的时候该`goroutine`就结束了，所有在`main()`函数中启动的`goroutine`会一同结束。所以我们要想办法让main函数等一等hello函数，最简单粗暴的方式就是`time.Sleep`了。我们在创建新的goroutine的时候需要花费一些时间，而此时main函数所在的`goroutine`是继续执行的。

**启动多个goroutine**

使用`sync.WaitGroup`来实现goroutine的同步

**sync.WaitGroup**

在代码中生硬的使用`time.Sleep`肯定是不合适的，Go语言中可以使用`sync.WaitGroup`来实现并发任务的同步。 `sync.WaitGroup`有以下几个方法：

| 方法名                          | 功能                |
| ------------------------------- | ------------------- |
| (wg * WaitGroup) Add(delta int) | 计数器+delta        |
| (wg *WaitGroup) Done()          | 计数器-1            |
| (wg *WaitGroup) Wait()          | 阻塞直到计数器变为0 |

`sync.WaitGroup`内部维护着一个计数器，计数器的值可以增加和减少。例如当我们启动了N 个并发任务时，就将计数器值增加N。每个任务完成时通过调用Done()方法将计数器减1。通过调用Wait()来等待并发任务执行完，当计数器值为0时，表示所有并发任务已经完成。需要注意`sync.WaitGroup`是一个结构体，传递的时候要传递指针。

```go
package main
import (
	"fmt"
	"runtime"
	"sync"
	"time"
)

var wg sync.WaitGroup // 记录子goroutine的个数

func hello() {
	fmt.Println("Hello Goroutine!")
}
func helloc(i int){
	fmt.Printf("Hello Goroutine %d\n",i)
	wg.Done() // goroutine结束就登记-1 告诉他goroutine执行完毕
}

func main() {
	runtime.GOMAXPROCS(1) //  指定只占用一个CPU核心
	go a()
	go b()
	time.Sleep(time.Second)
}
func main() { // 开启主goroutine执行main函数
	// 串行执行 执行的结果是打印完`Hello Goroutine!`后打印`main goroutine done!`。
	hello()
	fmt.Println("main goroutine done!")

	// 并发执行 在调用hello函数前面加上关键字`go`，也就是启动一个goroutine去执行hello这个函数。
	// 这次只打印了 main goroutine done!
	// Go程序会为`main()`函数创建一个默认的`goroutine`。当main()函数返回的时候该`goroutine`就结束了，所有在`main()`函数中启动的`goroutine`会一同结束。
	go hello()  // 启动一个goroutine去执行hello函数
	fmt.Println("main goroutine done!")

	// 要想让main函数等一等hello函数，最简单粗暴的方式就是`time.Sleep`了。
	// 先打印`main goroutine done!`，然后紧接着打印`Hello Goroutine!`。
	// 因为在创建新的goroutine的时候需要花费一些时间，而此时main函数所在的`goroutine`是继续执行的。
	time.Sleep(time.Second) // 主goroutine等待一s

	// 使用`sync.WaitGroup`来实现goroutine的同步等待 定义全局变量 var wg sync.WaitGroup
	// 可以一次全部登记完毕
	wg.Add(10)
	for i := 0; i < 10; i++ {
		// wg.Add(1) // 启动一个goroutine个数就登记+1
		go helloc(i) // 打印出来的i顺序不固定
	}
	wg.Wait() // 阻塞 等待所有登记的子goroutine都结束 个数为0

	// 匿名函数闭包
	// 此时打印出来的i均为10 因为闭包函数里面使用的i为外部变量 当创建好goroutine时外部的i可能已经进行了很多次循环了
	wg.Add(10)
	for i := 0; i < 10; i++ {
		go func() {
			fmt.Println("hello ",i)
			wg.Done()
		}()
	}
	wg.Wait()

	// 需要传递值 每次打印传递进来的变量
	wg.Add(10)
	for i := 0; i < 10; i++ {
		go func(i int) {
			fmt.Println("hello ",i)
			wg.Done()
		}(i)
	}
	wg.Wait()


}
```

**goroutine与线程**

OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB）,一个`goroutine`的栈在其生命周期开始时只有很小的栈（典型情况下2KB），`goroutine`的栈不是固定的，他可以按需增大和缩小，`goroutine`的栈大小限制可以达到1GB，虽然极少会用到这么大。所以在Go语言中一次创建十万左右的`goroutine`也是可以的。

**goroutine调度**

`GPM`是Go语言运行时（runtime）层面的实现，是go语言自己实现的一套调度系统。区别于操作系统调度OS线程。

- `G`很好理解，就是个goroutine的，里面除了存放本goroutine信息外 还有与所在P的绑定等信息。
- `P`管理着一组goroutine队列，P里面会存储当前goroutine运行的上下文环境（函数指针，堆栈地址及地址边界），P会对自己管理的goroutine队列做一些调度（比如把占用CPU时间较长的goroutine暂停、运行后续的goroutine等等）当自己的队列消费完了就去全局队列里取，如果全局队列里也消费完了会去其他P的队列里抢任务。
- `M（machine）`是Go运行时（runtime）对操作系统内核线程的虚拟， M与内核线程一般是一一映射的关系， 一个groutine最终是要放到M上执行的；

P与M一般也是一一对应的。他们关系是： P管理着一组G挂载在M上运行。当一个G长久阻塞在一个M上时，runtime会新建一个M，阻塞G所在的P会把其他的G 挂载在新建的M上。当旧的G阻塞完成或者认为其已经死掉时 回收旧的M。P的个数是通过`runtime.GOMAXPROCS`设定（最大256），Go1.5版本之后默认为物理线程数。 在并发量大的时候会增加一些P和M，但不会太多，切换太频繁的话得不偿失。单从线程调度讲，Go语言相比起其他语言的优势在于OS线程是由OS内核来调度的，`goroutine`则是由Go运行时（runtime）自己的调度器调度的，这个调度器使用一个称为m:n调度的技术（复用/调度m个goroutine到n个OS线程）。 其一大特点是goroutine的调度是在用户态下完成的，  不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放，都是在用户态维护着一块大的内存池，  不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。  另一方面充分利用了多核的硬件资源，近似的把若干goroutine均分在物理线程上，  再加上本身goroutine的超轻量，以上种种保证了go调度方面的性能。

**GOMAXPROCS**

Go运行时的调度器使用`GOMAXPROCS`参数来确定需要使用多少个OS线程来同时执行Go代码。默认值是机器上的CPU核心数。例如在一个8核心的机器上，调度器会把Go代码同时调度到8个OS线程上（GOMAXPROCS是m:n调度中的n）。Go语言中可以通过`runtime.GOMAXPROCS()`函数设置当前程序并发时占用的CPU逻辑核心数。Go1.5版本之前，默认使用的是单核心执行。Go1.5版本之后，默认使用全部的CPU逻辑核心数。可以通过将任务分配到不同的CPU逻辑核心上实现并行的效果

```go
// GOMAXPROCS
func a() {
	for i := 1; i < 10; i++ {
		fmt.Println("A:", i)
	}
	wg.Done()
}
func b() {
	for i := 1; i < 10; i++ {
		fmt.Println("B:", i)
	}
	wg.Done()
}
 
// 调用
	// 只有一个CPU核心，此时是做完一个任务再做另一个任务。
	runtime.GOMAXPROCS(1)
	wg.Add(2)
	go a()
	go b()
	wg.Wait()
	//  此时两个任务并行执行
	runtime.GOMAXPROCS(2)
	wg.Add(2)
	go a()
	go b()
	wg.Wait()
```

Go语言中的操作系统线程和goroutine的关系：

1. 一个操作系统线程对应用户态多个goroutine。
2. go程序可以同时使用多个操作系统线程。
3. goroutine和OS线程是多对多的关系，即m:n。m个goroutine安排到n个线程中

**channel**

单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义，虽然可以使用共享内存进行数据交换，但是共享内存在不同的`goroutine`中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。Go语言的并发模型是`CSP（Communicating Sequential Processes）`，提倡**通过通信共享内存**而不是**通过共享内存而实现通信**。如果说`goroutine`是Go程序并发的执行体，`channel`就是它们之间的连接。`channel`是可以让一个`goroutine`发送特定值到另一个`goroutine`的通信机制。Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。

**channel类型**

`channel`是一种类型，一种引用类型，需要make初始化。声明通道类型的格式如下：

```go
var 变量 chan 元素类型
```

**创建channel**

通道是引用类型，通道类型的空值是`nil`。声明的通道后需要使用`make`函数初始化 slice map chan 之后才能使用。创建channel的格式如下：channel的缓冲大小是可选的。

```go
make(chan 元素类型, [缓冲大小])
```

**channel操作**

通道有发送（send）、接收(receive）和关闭（close）三种操作。发送和接收都使用`<-`符号。

**发送** 将一个值发送到通道中。

**接收** 从一个通道中接收值。

**关闭** 通过调用内置的`close`函数来关闭通道。

关于关闭通道需要注意的事情是，只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。

关闭后的通道有以下特点：

1. 对一个关闭的通道再发送值就会导致panic。

2. 对一个关闭的通道进行接收会一直获取值直到通道为空。

3. 对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。

4. 关闭一个已经关闭的通道会导致panic。

   ```go
   func main()  {
   	// 声明通道
   	var ch1 chan int // 声明一个传递整型的通道
   	fmt.Println(ch1) // 通道是引用类型，通道类型的空值是`nil` <nil>
   	ch1 = make(chan int,2) // 初始化ch1
   	// var ch2 chan []int // 声明一个传递int切片的通道
   
   	// 创建channel
   	// 声明的通道后需要使用`make`函数初始化
   	ch3 := make(chan bool) // channel的缓冲大小是可选的
   	fmt.Println(ch3) // 0xc000048120
   	// channel操作
   	ch1 <- 10 // 把10发送到ch1中
   	ch1 <- 20 // 把20发送到ch1中
   	x := <- ch1 // 从ch1中接收值并赋值给变量x
   	<-ch1       // 从ch1中接收值，忽略结果
   	fmt.Println(x) // 10
   	close(ch1) // 关闭通道
   }
   ```

**无缓冲的通道**

无缓冲的通道又称为阻塞的通道 同步通道

```go
func main() {
	ch := make(chan int)
	ch <- 10
	fmt.Println("发送成功") // fatal error: all goroutines are asleep - deadlock!
}
```

上面这段代码能够通过编译，但是执行的时候会出现错误。为什么会出现`deadlock`错误呢？因为我们使用`ch := make(chan int)`创建的是无缓冲的通道，无缓冲的通道只有在有人接收值的时候才能发送值。上面的代码会阻塞在`ch <- 10`这一行代码形成死锁，那如何解决这个问题呢？一种方法是启用一个`goroutine`去接收值

```go
func recv(c chan int) {
	ret := <-c
	fmt.Println("接收成功", ret)
}
func main() {
	ch := make(chan int)
	go recv(ch) // 启用goroutine从通道接收值
	ch <- 10
	fmt.Println("发送成功")
}
```

无缓冲通道上的发送操作会阻塞，直到另一个`goroutine`在该通道上执行接收操作，这时值才能发送成功，两个`goroutine`将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个`goroutine`在该通道上发送一个值。使用无缓冲通道进行通信将导致发送和接收的`goroutine`同步化。因此，无缓冲通道也被称为`同步通道`。

**有缓冲的通道**

解决上面问题的方法还有一种就是使用有缓冲区的通道。我们可以在使用make函数初始化通道的时候为其指定通道的容量，只要通道的容量大于零，那么该通道就是有缓冲的通道，通道的容量表示通道中能存放元素的数量。就像你小区的快递柜只有那么个多格子，格子满了就装不下了，就阻塞了，等到别人取走一个快递员就能往里面放一个。我们可以使用内置的`len`函数获取通道内元素的数量，使用`cap`函数获取通道的容量

**for range从通道循环取值**

当向通道中发送完数据时，我们可以通过`close`函数来关闭通道。当通道被关闭时，再往该通道发送值会引发`panic`，从该通道取值的操作会先取完通道中的值，再然后取到的值一直都是对应类型的零值。那如何判断一个通道是否被关闭了呢？i, ok := <-ch1 ok为false。有两种方式在接收值的时候判断该通道是否被关闭，不过我们通常使用的是`for range`的方式。使用`for range`遍历通道，当通道被关闭的时候就会退出`for range`。

```go
	/*两个goroutine
	1.生成0-100的数发送给channel
	2.从channel中取出数据计算平方把结果发送给channel2
	*/
	ch4 := make(chan int,100)
	ch5 := make(chan int,100)
	go f1(ch4)
	go f2(ch4,ch5)
	// 取值实现2
	for ret:=range ch5{
		fmt.Println(ret)
	}

// 生成0-100的数发送给channel
func f1(ch chan int){
	for i:=0;i<100;i++{
		ch<-i
	}
	close(ch)
}
// 从channel中取出数据计算平方把结果发送给channel2
func f2(ch1 chan int,ch2 chan int)  {
	for{
		tep,ok :=<-ch1
		if !ok{
			break
		}
		ch2 <- tep*tep
	}
	close(ch2)
}
```

**单向通道**

有的时候我们会将通道作为参数在多个任务函数间传递，很多时候我们在不同的任务函数中使用通道都会对其进行限制，比如限制通道在函数中只能发送或只能接收。Go语言中提供了**单向通道**来处理这种情况。

```go
// 生成0-100的数发送给channel
func f1(ch chan<-int){  // 只写单向通道
	for i:=0;i<100;i++{
		ch<-i
	}
	close(ch)
}
// 从channel中取出数据计算平方把结果发送给channel2
func f2(ch1 <- chan int,ch2 chan<-int)  { // ch1 <- chanint 只读
    // ch1 <- 3 // 错误 只读
	for{
		tep,ok :=<-ch1
		if !ok{
			break
		}
		ch2 <- tep*tep
	}
	close(ch2)
}
```

chan<- int`是一个只写单向通道（只能对其写入int类型值），可以对其执行发送操作但是不能执行接收操作；` `<-chan int`是一个只读单向通道（只能从其读取int类型值），可以对其执行接收操作但是不能执行发送操作。在函数传参中可以将双向通道转换为单向通道，但反过来是不可以的。

**通道总结**

`channel`常见的异常总结,关闭已经关闭的`channel`也会引发`panic`。![channel异常总结](https://www.liwenzhou.com/images/Go/concurrence/channel01.png)

**worker pool（goroutine池）**

在工作中我们通常会使用可以指定启动的goroutine数量–---`worker pool`模式，控制`goroutine`的数量，防止`goroutine`泄漏和暴涨。

```go
	// work pool
	jobs := make(chan int, 100)
	results := make(chan int, 100)
	// 开启3个goroutine
	for w := 1; w <= 3; w++ {
		go worker(w, jobs, results)
	}
	// 发送5个任务
	for j := 1; j <= 5; j++ {
		jobs <- j
	}
	close(jobs)
	// 输出结果
	for a := 1; a <= 5; a++ {
		<-results
	}


// worker pool
func worker(id int, jobs <- chan int, results chan<- int) {
	for j := range jobs { // 每个goroutine先领取一个任务 完成后再去jobs中领取
		fmt.Printf("worker:%d start job:%d\n", id, j)
		time.Sleep(time.Second*2)
		results <- j * 2
	}
}
```

**select多路复用**

在某些场景下我们需要同时从多个通道接收数据。通道在接收数据时，如果没有数据可以接收将会发生阻塞。

```go
for{
    // 尝试从ch1接收值
    data, ok := <-ch1
    // 尝试从ch2接收值
    data, ok := <-ch2
    …
}
```

这种方式虽然可以实现从多个通道接收值的需求，但是运行性能会差很多。为了应对这种场景，Go内置了`select`关键字，可以同时响应多个通道的操作。`select`的使用类似于switch语句，它有一系列case分支和一个默认的分支。每个case会对应一个通道的通信（接收或发送）过程。如果没有完成的case和默认分支，`select`会一直等待，直到某个`case`的通信操作完成时，就会执行`case`分支对应的语句。若同时有多个case完成，则随机选择一个。

```go
select{
    case <-ch1:
        ...
    case data := <-ch2:
        ...
    case ch3 <- data:
        ...
    default:
        默认操作
}
```

```go
	// select
	ch6 := make(chan int, 1)
	for i := 0; i < 10; i++ {
		select {
		case x := <-ch6: // 取值
			fmt.Println(x) // 0 2 4 6 8
		case ch6 <- i: // 发送值
		default:
			fmt.Println("shasha")
		}
	}

/*
i = 0   case2满足 送入channel 0
i = 1   case1满足 取出channel 0
i = 2   case2满足 送入channel 2
i = 3   case1满足 取出channel 2
....
*/
```

使用`select`语句能提高代码的可读性。

- 可处理一个或多个channel的发送/接收操作。
- 如果多个`case`同时满足，`select`会随机选择一个。
- 对于没有`case`的`select{}`会一直等待，可用于阻塞main函数。



**Go语言在select语句中实现优先级**

> Go 语言中的 `select`语句用于监控并选择一组`case`语句执行相应的代码。它看起来类似于`switch`语句，但是`select`语句中所有`case`中的表达式都必须是`channel`的发送或接收操作。一个典型的`select`使用示例如下：
>
> ```go
> select {
> case <-ch1:
> 	fmt.Println("liwenzhou.com")
> case ch2 <- 1:
> 	fmt.Println("q1mi")
> }
> ```
>
> Go 语言中的 `select` 关键字也能够让当前 `goroutine` 同时等待`ch1` 的可读和`ch2`的可写，在`ch1`和`ch2`状态改变之前，`select` 会一直阻塞下去，直到其中的一个 `channel` 转为就绪状态时执行对应`case`分支的代码。如果多个`channel`同时就绪的话则随机选择一个`case`执行。
>
> 除了上面展示的典型示例外，接下来我们逐一介绍一些`select`的特殊示例。
>
> **空select**
>
> 空`select`指的是内部不包含任何`case`，例如：
>
> ```go
> select{
> }
> ```
>
> 空的 `select` 语句会直接阻塞当前的`goroutine`，使得该`goroutine`进入无法被唤醒的永久休眠状态。
>
> **只有一个case**
>
> 如果`select`中只包含一个`case`，那么该`select`就变成了一个**阻塞的**`channel`读/写操作。
>
> ```go
> select {
> case <-ch1:
> 	fmt.Println("liwenzhou.com")
> }
> ```
>
> 上面的代码，当`ch1`可读时会执行打印操作，否则就会阻塞。
>
> **有default语句**
>
> 如果`select`中还可以包含`default`语句，用于当其他`case`都不满足时执行一些默认操作。
>
> ```go
> select {
> case <-ch1:
> 	fmt.Println("liwenzhou.com")
> default:
> 	time.Sleep(time.Second)
> }
> ```
>
> 上面的代码，当`ch1`可读时会执行打印操作，否则就执行`default`语句中的代码，这里就相当于做了一个非阻塞的`channel`读取操作。
>
> **总结**
>
> 1. `select` 不存在任何的 `case`：永久阻塞当前 goroutine
>
> 2. `select` 只存在一个 `case`：阻塞的发送/接收
>
> 3. `select` 存在多个 `case`：随机选择一个满足条件的`case`执行
>
> 4. `select` 存在 `default`，其他`case`都不满足时：执行`default`语句中的代码
>
>    
>
> **如何在select中实现优先级**
>
> 已知，当`select` 存在多个 `case`时会随机选择一个满足条件的`case`执行。
>
> 现在我们有一个需求：我们有一个函数会持续不间断地从`ch1`和`ch2`中分别接收任务1和任务2。如何确保当`ch1`和`ch2`同时达到就绪状态时，优先执行任务1，在没有任务1的时候再去执行任务2呢？
>
> 高级Go语言程序员小明挠了挠头写出了如下函数：
>
> ```go
> func worker(ch1, ch2 <-chan int, stopCh chan struct{}) {
> 	for {
> 		select {
>             case <-stopCh:
>                 return
>             case job1 := <-ch1:
>                 fmt.Println(job1)
>             default:
>                 select {
>                     case job2 := <-ch2:
>                         fmt.Println(job2)
>                     default:
>                 }
> 		}
> 	}
> }
> ```
>
> 上面的代码通过嵌套两个`select`实现了”优先级”，看起来是满足题目要求的。但是这代码有点问题，如果`ch1`和`ch2`都没有达到就绪状态的话，整个程序不会阻塞而是进入了死循环。怎么办呢？
>
> 小明又挠了挠头，又写下了另一个解决方案：
>
> ```go
> func worker2(ch1, ch2 <-chan int, stopCh chan struct{}) {
> 	for {
> 		select {
>             case <-stopCh:
>                 return
>             case job1 := <-ch1:
>                 fmt.Println(job1)
>             case job2 := <-ch2:
>                 priority:
>                     for {
>                         select {
>                             case job1 := <-ch1:
>                                 fmt.Println(job1)
>                             default:
>                                 break priority
>                         }
>                     }
>                     fmt.Println(job2)
>         }
> 	}
> }
> ```
>
> 这一次，小明不仅使用了嵌套的`select`，还组合使用了`for`循环和`LABEL`来实现题目的要求。上面的代码在外层`select`选中执行`job2 := <-ch2`时，进入到内层`select`循环继续尝试执行`job1 := <-ch1`,当`ch1`就绪时就会执行job1，否则跳出内层`select`执行job2。
>
> ## 实际应用场景
>
> 上面的需求虽然是我编的，但是关于在`select`中实现优先级在实际生产中是有实际应用场景的，例如[K8s的controller](https://github.com/kubernetes/kubernetes/blob/7509c4eb478a3ab94ff26be2b4068da53212d538/pkg/controller/nodelifecycle/scheduler/taint_manager.go#L244)中就有关于上面这个技巧的实际使用示例，这里在关于`select`中实现优先级相关代码的关键处都已添加了注释，具体逻辑这里就不展开细说了。
>
> ```go
> // kubernetes/pkg/controller/nodelifecycle/scheduler/taint_manager.go 
> func (tc *NoExecuteTaintManager) worker(worker int, done func(), stopCh <-chan struct{}) {
> 	defer done()
> 	// 当处理具体事件的时候，我们会希望 Node 的更新操作优先于 Pod 的更新
> 	// 因为 NodeUpdates 与 NoExecuteTaintManager无关应该尽快处理
> 	// -- 我们不希望用户(或系统)等到PodUpdate队列被耗尽后，才开始从受污染的Node中清除pod。
> 	for {
> 		select {
> 		case <-stopCh:
> 			return
> 		case nodeUpdate := <-tc.nodeUpdateChannels[worker]:
> 			tc.handleNodeUpdate(nodeUpdate)
> 			tc.nodeUpdateQueue.Done(nodeUpdate)
> 		case podUpdate := <-tc.podUpdateChannels[worker]:
> 			// 如果我们发现了一个 Pod 需要更新，我么你需要先清空 Node 队列.
> 		priority:
> 			for {
> 				select {
> 				case nodeUpdate := <-tc.nodeUpdateChannels[worker]:
> 					tc.handleNodeUpdate(nodeUpdate)
> 					tc.nodeUpdateQueue.Done(nodeUpdate)
> 				default:
> 					break priority
> 				}
> 			}
> 			// 在 Node 队列清空后我们再处理 podUpdate.
> 			tc.handlePodUpdate(podUpdate)
> 			tc.podUpdateQueue.Done(podUpdate)
> 		}
> 	}
> }
> ```
>
> ## 总结
>
> 本文回顾了Go语言中`select`语句的一些用法，并延伸出了一个如何在`select`中实现优先级的小技巧，希望能对大家有所帮助。



**并发安全和锁**

有时候在Go代码中可能会存在多个`goroutine`同时操作一个资源（临界区），这种情况会发生`竞态问题`（数据竞态）。开启两个`goroutine`去累加变量x的值，这两个`goroutine`在访问和修改`x`变量的时候就会存在数据竞争，导致最后的结果与期待的不符。

```go
// 多个`goroutine`同时操作一全局变量
var (
    x int64
 	wg sync.WaitGroup
)

func add() {
	for i := 0; i < 5000; i++ {
		x = x + 1 // 三步：1.取x的值 2.x的值+1 3.把值送回给x
	}
	wg.Done()
}
func main() {
	wg.Add(2)
	go add()
	go add()
	wg.Wait()
	fmt.Println(x) // 每次结果不同
}
```

**互斥锁**

互斥锁是一种常用的控制共享资源访问的方法，它能够保证同时只有一个`goroutine`可以访问共享资源。Go语言中使用`sync`包的`Mutex`类型来实现互斥锁。 使用互斥锁来修复上面代码的问题，使用互斥锁能够保证同一时间有且只有一个`goroutine`进入临界区，其他的`goroutine`则在等待锁；当互斥锁释放后，等待的`goroutine`才可以获取锁进入临界区，多个`goroutine`同时等待一个锁时，唤醒的策略是随机的。

```go
// 多个`goroutine`同时操作一全局变量
var (
    x int64
 	wg sync.WaitGroup
    lock sync.Mutex // 互斥锁
)
func add() {
	for i := 0; i < 5000; i++ {
		lock.Lock() // 加锁
		x = x + 1
		lock.Unlock() // 解锁
	}
	wg.Done()
}
func main() {
	wg.Add(2)
	go add()
	go add()
	wg.Wait()
	fmt.Println(x)
}
```

**读写互斥锁**

互斥锁是完全互斥的，但是有很多实际的场景下是读多写少的，当我们并发的去读取一个资源不涉及资源修改的时候是没有必要加锁的，这种场景下使用读写锁是更好的一种选择。读写锁在Go语言中使用`sync`包中的`RWMutex`类型。读写锁分为两种：读锁和写锁。当一个goroutine获取读锁之后，其他的`goroutine`如果是获取读锁会继续获得锁，如果是获取写锁就会等待；当一个`goroutine`获取写锁之后，其他的`goroutine`无论是获取读锁还是写锁都会等待。需要注意的是读写锁非常适合读多写少的场景，如果读和写的操作差别不大，读写锁的优势就发挥不出来。

```go
var (
	x      int64
	wg     sync.WaitGroup
	lock   sync.Mutex // 互斥锁
	rwlock sync.RWMutex // 读写锁
)

// 读写锁
func write() {
	// lock.Lock()   // 加互斥锁
	rwlock.Lock() // 加写锁
	x = x + 1
	time.Sleep(10 * time.Millisecond) // 假设写操作耗时10毫秒
	rwlock.Unlock()                   // 解写锁
	// lock.Unlock()                  // 解互斥锁
	wg.Done()
}

func read() {
	// lock.Lock()                  // 加互斥锁
	rwlock.RLock()               // 加读锁
	time.Sleep(time.Millisecond) // 假设读操作耗时1毫秒
	rwlock.RUnlock()             // 解读锁
	// lock.Unlock()             // 解互斥锁
	wg.Done()
}

func main() {
	// 读写锁 当读操作大于写操作时 效率快于互斥锁
	start := time.Now()
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go write()
	}
	for i := 0; i < 1000; i++ {
		wg.Add(1)
		go read()
	}
	wg.Wait()
	end := time.Now()
	fmt.Println(end.Sub(start))
}
```

**sync.Once**

在编程的很多场景下需要确保某些操作在高并发的场景下只执行一次，例如只加载一次配置文件、只关闭一次通道等。Go语言中的`sync`包中提供了一个针对只执行一次场景的解决方案–`sync.Once`。`sync.Once`只有一个`Do`方法，如果要执行的函数`f`需要传递参数就需要搭配闭包来使用。`sync.Once`其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证初始化操作的时候是并发安全的并且初始化操作也不会被执行多次。

```go
func (o *Once) Do(f func()) {}
```

**加载配置文件示例**

延迟一个开销很大的初始化操作到真正用到它的时候再执行是一个很好的实践。因为预先初始化一个变量（比如在init函数中完成初始化）会增加程序的启动耗时，而且有可能实际执行过程中这个变量没有用上，那么这个初始化操作就不是必须要做的。

```go
var icons map[string]image.Image

func loadIcons() { // 从文件加载图片
	icons = map[string]image.Image{
		"left":  loadIcon("left.png"),
		"up":    loadIcon("up.png"),
		"right": loadIcon("right.png"),
		"down":  loadIcon("down.png"),
	}
}

// Icon 被多个goroutine调用时不是并发安全的
func Icon(name string) image.Image {
	if icons == nil {
		loadIcons() // 加载后返回
	}
	return icons[name]
}
```

多个`goroutine`并发调用Icon函数时不是并发安全的，现代的编译器和CPU可能会在保证每个`goroutine`都满足串行一致的基础上自由地重排访问内存的顺序。loadIcons函数可能会被重排为以下结果：

```go
func loadIcons() {
	icons = make(map[string]image.Image) // 此时不为nil 要是此时有某个goroutine访问Icon函数 if判断不满足 且icons[name]中没值    
	icons["left"] = loadIcon("left.png")
	icons["up"] = loadIcon("up.png")
	icons["right"] = loadIcon("right.png")
	icons["down"] = loadIcon("down.png")
}
```

在这种情况下就会出现即使判断了`icons`不是nil也不意味着变量初始化完成了。考虑到这种情况，我们能想到的办法就是添加互斥锁，保证初始化`icons`的时候不会被其他的`goroutine`操作，但是这样做又会引发性能问题。使用`sync.Once`改造的示例代码如下：

```go
var icons map[string]image.Image
var loadIconsOnce sync.Once

func loadIcons() {
	icons = map[string]image.Image{
		"left":  loadIcon("left.png"),
		"up":    loadIcon("up.png"),
		"right": loadIcon("right.png"),
		"down":  loadIcon("down.png"),
	}
}

// Icon 是并发安全的
func Icon(name string) image.Image {
	loadIconsOnce.Do(loadIcons) // 先判断函数loadIcons是否被执行过 会有标志位记录 如果执行过继续下行代码 如果没执行 加锁执行
	return icons[name]
}
```

**并发安全的单例模式**

下面是借助`sync.Once`实现的并发安全的单例模式：实现

```go
// 并发安全的单例模式
type singleton struct {
	name string
	age int
}
var instance *singleton
var once sync.Once
func GetInstance() *singleton { // 实例化singleton
	once.Do(func() {
		instance = &singleton{}
	})
	return instance
}

// 调用
	// 单例模式
	x := GetInstance()
	x.name = "zzz"
	fmt.Printf("x = %#v\n", x) // x = &main.singleton{name:"zzz", age:0}
```

**sync.Map**

Go语言中内置的map不是并发安全的。

```go
// 内置的Map非并发安全
var m = make(map[string]int)

func get(key string) int { // 取值
	return m[key]
}
func set(key string, value int) { // 存值
	m[key] = value
}

func main() {
	wg := sync.WaitGroup{}
	for i := 0; i < 25; i++ {
		wg.Add(1)
		go func(n int) {
			set(string(n), n+100) // 设置键值对
			fmt.Printf("k=:%v,v:=%v\n", n, get(string(n))) // 取键值对
			wg.Done()
		}(i)
	}
	wg.Wait()
}
```

上面的代码开启少量几个`goroutine`的时候可能没什么问题，当并发多了之后执行上面的代码就会报`fatal error: concurrent map writes`错误。像这种场景下就需要为map加锁来保证并发的安全性了，Go语言的`sync`包中提供了一个开箱即用的并发安全版map–`sync.Map`。开箱即用表示不用像内置的map一样使用make函数初始化就能直接使用。同时`sync.Map`内置了诸如`Store`、`Load`、`LoadOrStore`、`Delete`、`Range`等操作方法。

```go
// sync.Map并发安全
var m2 = sync.Map{}

func main() {
	wg := sync.WaitGroup{}
	for i := 0; i < 20; i++ {
		wg.Add(1)
		go func(n int) {
			m2.Store(string(n), n) // 存储
			value, _ := m2.Load(string(n)) // 获取
			fmt.Printf("k=:%v,v:=%v\n", n, value)
			wg.Done()
		}(i)
	}
	wg.Wait()
}
```

**原子操作**

在上面的代码中的我们通过锁操作来实现同步。而锁机制的底层是基于原子操作的，其一般直接通过CPU指令实现。Go语言中原子操作由内置的标准库`sync/atomic`提供。`atomic`包提供了底层的原子级内存操作，对于同步算法的实现很有用。这些函数必须谨慎地保证正确使用。除了某些特殊的底层应用，使用通道或者sync包的函数/类型实现同步更好。

我们填写一个示例来比较下互斥锁和原子操作的性能。

```go
package main

import (
	"fmt"
	"sync"
	"sync/atomic"
	"time"
)

type Counter interface {
	Inc()
	Load() int64
}

// 普通版
type CommonCounter struct {
	counter int64
}

func (c *CommonCounter) Inc() { // 增加 写操作
	c.counter++
}

func (c *CommonCounter) Load() int64 { // 读操作
	return c.counter
}

// 互斥锁版
type MutexCounter struct {
	counter int64
	lock    sync.Mutex
}

func (m *MutexCounter) Inc() {
	m.lock.Lock()
	defer m.lock.Unlock() // 最后执行
	m.counter++
}

func (m *MutexCounter) Load() int64 {
	m.lock.Lock()
	defer m.lock.Unlock()
	return m.counter
}

// 原子操作版
type AtomicCounter struct {
	counter int64
}

func (a *AtomicCounter) Inc() {
	atomic.AddInt64(&a.counter, 1) // 原子操作
}

func (a *AtomicCounter) Load() int64 {
	return atomic.LoadInt64(&a.counter)
}

func test(c Counter) {
	var wg sync.WaitGroup // 多线程
	start := time.Now()
	// fmt.Println(c)
	for i := 0; i < 1000; i++ { // 10000个
		wg.Add(1)
		go func() {
			c.Inc() // 增加
			wg.Done()
		}()
	}
	wg.Wait()
	end := time.Now()
	fmt.Println(c.Load(), end.Sub(start))
}

func main() {
	c1 := CommonCounter{} // 非并发安全  999 1.0882ms
	test(&c1)
	c2 := MutexCounter{} // 使用互斥锁实现并发安全 1000 503.1µs
	test(&c2)
	c3 := AtomicCounter{} // 并发安全且比互斥锁效率更高 1000 0s
	test(&c3)
}
```

