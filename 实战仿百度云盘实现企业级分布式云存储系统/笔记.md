> 1 秒传：多次上传相同文件(文件名可以不同，内容相同)，可实现秒传功能
>
> 2 分块上传是并行传输的，断点续传需要基于分块上传
>
> 3 Ceph表示私有云存储集群，海量数据可以用OSS公有云

**简单文件上传系统**

两个参与的角色：用户和云端

云端分为：与用户进行传输交互的server以及用于存储数据文件的本地存储

**文件元数据需要存储在mysql数据库中，防止断电丢失** 

**高级功能**：读写分离 负载均衡

mysql 安装模式可以分为单点模式 主从模式 多主模式

```shell
docker pull mysql:5.7
# 启动主库
docker run --name master -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=zxy19981013 mysql:5.7
# 启动从库
docker run --name slave -d -p 3300:3306 -e MYSQL_ROOT_PASSWORD=zxy19981013 mysql:5.7
# 查看启动情况0
docker ps
docker logs master
```

`netstat -tanlp `  查看Local Address   -h 和 -p

```bash
# 进入master容器
docker exec -it master /bin/bash
# 进入mysql配置目录
cd /etc/mysql
# docker内部安装vim
apt-get update
apt-get install vim
# 安装成功后，编辑my.cnf文件
vim my.cnf

[mysqld]
# 同一局域网内注意要唯一
server-id=100  
# 开启二进制日志功能，可以随便取（关键）
log-bin=master-bin
binlog-format=ROW # 二级制日志格式，有三种 row，statement，mixed

# 配置完成后，需要重启mysql服务使其修改的配置文件生效，使用如下命令使mysql进行重启
service mysql restart
# 重启会导致docker容器停止，使用如下命令重新启动容器：
docker start master
# 创建数据库同步账户，使用docker命令重新进入到Master容器内部：
docker exec -it master /bin/bash
# 在Master数据库创建数据同步用户，授予用户 slave REPLICATION SLAVE权限和REPLICATION CLIENT权限，用于在主从库之间同步数据。登录到mysql客户端：
mysql -uroot -p
# 创建用户并授权：
mysql> CREATE USER 'slave'@'%' IDENTIFIED BY 'zxy19981013';
mysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';
# 至此，Master配置完成。




# 进入slave容器
docker exec -it slave /bin/bash
# 类似于Master，进入到etc/mysql路径，使用vim命令编辑my.cnf文件：
# 进入mysql配置目录
cd /etc/mysql
# docker内部安装vim
apt-get update
apt-get install vim
# 安装成功后，编辑my.cnf文件
vim my.cnf

[mysqld]
## 设置server_id,注意要唯一
server-id=101  
## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用
log-bin=mysql-slave-bin   
## relay_log配置中继日志
relay_log=mysql-relay-bin  
read_only=1  ## 设置为只读,该项如果不设置，表示slave可读可写

# 配置完成后，需要重启mysql服务使其修改的配置文件生效，使用如下命令使mysql进行重启
service mysql restart
# 重启会导致docker容器停止，使用如下命令重新启动容器：
docker start slave



# 开启Master-Slave主从复制
# 进入Master库mysql客户端：查看Master状态：记住File和Position，后面需要用到。master-bin.000001 |  617
docker exec -it master /bin/bash
mysql -uroot -p
show master status;
# 进入到Slave库myslq客户端，执行如下命令：
docker exec -it slave /bin/bash
mysql -uroot -p
# master_host 是下面的容器实例IP
change master to master_host='172.17.0.2', master_user='slave', master_password='zxy19981013', master_port=3306, master_log_file='master-bin.000001', master_log_pos=617, master_connect_retry=30;
# 开启主从复制过程
start slave;
# 查询主从同步状态
show slave status \G;
```

**获取容器实例IP**

```shell
docker inspect --format='{{.NetworkSettings.IPAddress}}' master
172.17.0.2
docker inspect --format='{{.NetworkSettings.IPAddress}}' slave
172.17.0.3
```

**测试主从同步**

**主数据库**

```sql
mysql> create database test1 default character set utf8;         
mysql> show databases;   
mysql> use test1;
mysql> create table test (`user` varchar(64) not null,`age` int(11) not null) default charset utf8;
mysql> show tables;
mysql> insert into test(user,age)values('xiaoming',18);
mysql> show master status;
```

**从数据库**

```sql
mysql> show databases;  
mysql> use test1;
mysql> show tables;
mysql> select * from test;
mysql> show slave status \G;
```

查看主从数据库的position  Read_Master_Log_Pos，相同表示同步完成。

**表设计**

文件表设计

```sql
mysql> create database fileserver default character set utf8;  
mysql> use fileserver;
mysql> CREATE TABLE `tbl_file`(
	`id` int(11) NOT NULL AUTO_INCREMENT,
    `file_sha1` char(40) NOT NULL DEFAULT''COMMENT'文件hash',
    `file_name` varchar(256) NOT NULL DEFAULT''COMMENT'文件名',
    `file_size` bigint(20) NOT NULL DEFAULT'0'COMMENT'文件大小',
    `file_addr` varchar(1024) NOT NULL DEFAULT''COMMENT'文件存储位置',
    `create_at` datetime DEFAULT NOW()COMMENT'创建日期',
    `update_at` datetime DEFAULT NOW()on update current_timestamp()COMMENT'更新日期',
    `status` int(11) NOT NULL DEFAULT'0'COMMENT'状态(可用/禁用/已删除)',
    `ext1` int(11) DEFAULT'0'COMMENT'备用字段1',
    `ext2` text COMMENT'备用字段2',
    PRIMARY KEY(`id`),
    UNIQUE KEY`idx_file_hash`(`file_sha1`),
    KEY `idx_status`(`status`)
)ENGINE=innoDB DEFAULT CHARSET = utf8;
mysql> show tables;
mysql> show create table tbl_file;
```

**MYSQL 分库分表**

**水平分表：**若想增加分表个数，需要增加额外的分表逻辑，使得旧数据在原有的表中，新数据按照新逻辑分表。

**垂直分表：** 不同列分为不同的表



**账号系统与鉴权及用户表**

**账号系统的功能** 

用户经过鉴权后进行api接口访问

> 支持用户注册登录
>
> 支持用户session鉴权，完成登录之后访问其他的api接口
>
> 用户数据隔离

**用户表设计**

```sql
mysql> CREATE TABLE `tbl_user`(
	`id` int(11) NOT NULL AUTO_INCREMENT,
    `user_name` varchar(64) NOT NULL DEFAULT''COMMENT'用户名',
    `user_pwd` varchar(256) NOT NULL DEFAULT''COMMENT'用户encode后的密码',
    `email` varchar(64) DEFAULT''COMMENT'邮箱',
    `phone` varchar(128) DEFAULT''COMMENT'手机号',
    `email_validated` tinyint(1) DEFAULT 0 COMMENT'邮箱是否已验证',
    `phone_validated` tinyint(1) DEFAULT 0 COMMENT'手机号是否已验证',
    `signup_at` datetime DEFAULT CURRENT_TIMESTAMP on update current_timestamp()COMMENT'最后活跃时间戳',
    `profile` text COMMENT'用户属性',
    `status` int(11) NOT NULL DEFAULT'0'COMMENT'状态(启用/禁用/锁定/标记删除)',
    PRIMARY KEY(`id`),
    UNIQUE KEY`username`(`user_name`),
    KEY `idx_status`(`status`)
)ENGINE=innoDB DEFAULT CHARSET = utf8;
mysql> show tables;
mysql> show create table tbl_user;
```

**用户token表设计**

```sql
mysql> CREATE TABLE `tbl_user_token`(
	`id` int(11) NOT NULL AUTO_INCREMENT,
    `user_name` varchar(64) NOT NULL DEFAULT''COMMENT'用户名',
    `user_token` varchar(40) NOT NULL DEFAULT''COMMENT'用户登录token',
    PRIMARY KEY(`id`),
    UNIQUE KEY`idx_username`(`user_name`)
)ENGINE=innoDB DEFAULT CHARSET = utf8;
mysql> show tables;
mysql> show create table tbl_user_token;
```

对每个接口进行token校验会造成大量代码重复，所以需要使用拦截器实现统一验证逻辑。服务器接收到用户请求后，在真正转发到具体的handler处理器之前，将请求拦截下来，验证用户名以及token是否有效。验证成功后再转发到具体的handler函数处理器中进行逻辑处理。使token失效，直接将本地历史清空即可。

**文件校验值计算**

> 校验算法类型 校验值长度 校验值类别 安全级别(特指抗碰撞概率) 计算效率 应用场景
>
> CRC	32/64bit	校验码 多项式除法	低	高	数据传输校验
>
> MD5	108bit	哈希值 分块计算	中	中	文件校验 数据签名
>
> SHA1	160bit	哈希值 分块计算	高	低	文件校验 数据签名

**秒传原理**

> 1.文件上传：上传文件瞬间完成，之前有用户上传过相同文件，再次上传时服务器可以识别，并且将上传状态立马置为完成。免去传输状态。
>
> 2.离线下载：大文件可以在瞬间完成下载功能。
>
> 3.好友分享：云文件夹瞬间可以看到分享的文件。

> **关键点：**
>
> 1.需要记录每个文件的hash值，hash相同就可以省去重复传输过程。
>
> 2.用户文件关联，基于用户实现文件资源的隔离。

**架构：**唯一文件表存所有的文件信息meta，用户文件表存储用户文件关联关系

**用户文件表设计**

```sql
mysql> CREATE TABLE `tbl_user_file`(
	`id` int(11) NOT NULL PRIMARY KEY AUTO_INCREMENT,
	`user_name` varchar(64) NOT NULL,
    `file_sha1` varchar(64) NOT NULL DEFAULT''COMMENT'文件hash',
    `file_size` bigint(20) DEFAULT'0'COMMENT'文件大小',
    `file_name` varchar(256) NOT NULL DEFAULT''COMMENT'文件名',
    `upload_at` datetime DEFAULT CURRENT_TIMESTAMP COMMENT'上传日期',
    `last_update` datetime DEFAULT CURRENT_TIMESTAMP on update current_timestamp() COMMENT'最后修改时间',
    `status` int(11) NOT NULL DEFAULT'0'COMMENT'状态(正常/已删除/禁用)',
    UNIQUE KEY `idx_user_file`(`user_name`,`file_sha1`,`file_name`),
    KEY `idx_status`(`status`),
    KEY `idx_user_id`(`user_name`)
)ENGINE=innoDB DEFAULT CHARSET = utf8;
mysql> show tables;
mysql> show create table tbl_user_file;
```

**秒传**

> 客户端每次上传文件时请求秒传接口，秒传成功则结束上传流程，秒传失败，则请求正常的上传接口
>
> 秒传接口：
>
> 1.解析请求参数
>
> 2.从文件表中查询相同hash的文件记录
>
> 3.查不到记录则返回秒传失败
>
> 4.上传过则将文件信息写入用户文件表，返回秒传成功

**相同文件冲突**

> 1.允许不同用户同时上传同一个文件
>
> 2.先完成上传的先入库
>
> 3.后上传的只需要更新用户文件表，并删除已上传的文件

**文件分块上传与断点续传**

**分块上传：**文件分成多块，独立传输，全部上传完成后按顺序完成合并。

**断点续传：**传输暂停或异常中断后，可基于原来的进度重传。云端程序将已经传输的块存储好，下次传输只需要查询记录，找到未上传的进行重传。

> 小文件不建议分块上传
>
> 可以并行上传分块，并且可以无序传输，找到最优的分块个数
>
> 分块上传能极大的提高传输效率
>
> 可以减少传输失败后重试流量和时间
>
> 分块上传的信息可以存储在redis中，因为记录只需要在上传过程中保留，且修改查询较为频繁，查询速度要求较高。

**接口：**

初始化分块信息、上传分块、通过分块上传完成、取消上传分块、查看分块上传的整体状态。

初始化分块信息：判断是否已经上传过、生成唯一上传ID，标志某次上传的唯一性、缓存分块初始化信息。

```bash
docker pull redis
docker run --name redis -d -p 6379:6379 redis
docker exec -it redis /bin/bash
redis-cli
keys *
config set requirepass zxy19981013
```

取消上传分块

查看分块上传的整体状态

**Ceph搭建基于私有云的分布式存储**  可以作为核心文件数据的备份 或者归档日志

> 部署简单，测试环境下可以利用docker搭建一个基本可用的集群
>
> 开源
>
> 客户端支持多语言接入
>
> 可靠性高，多副本隔离存储，数据强一致性
>
> 性能高
>
> 数据分布式存储，充分利用存储节点上的计算能力，数据存储位置通过计算得出，位置分布均匀。可扩展性强
>



> 底层存储系统由大量存储节点组成，每个节点是一个存储操作系统，有硬件资源
>
> 低阶接口层对外提供访问接口 针对对象存储功能
>
> 应用接口层 restful api 对象存储接口

**基础组件**

```bash
# 创建ceph专用网络
docker network create --driver bridge --subnet 172.20.0.0/16 ceph-network
docker network inspect ceph-network
# 创建相关目录以及修改权限，用于挂载volume
mkdir -p /www/ceph /var/lib/ceph/osd /www/osd/
chown -R 64045:64045 /var/lib/ceph/osd
chown -R 64045:64045 /www/osd/
# 创建monitor节点
docker run -itd --name monnode --network ceph-network --ip 172.20.0.10 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph ceph/mon
# 在monitor节点上标识3个osd节点
docker exec monnode ceph osd create
docker exec monnode ceph osd create
docker exec monnode ceph osd create
# 创建osd节点
docker run -itd --name osdnode0 --network ceph-network -e CLUSTER=ceph -e WEIGHT=1.0 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph -v /www/osd/0:/var/lib/ceph/osd/ceph-0 ceph/osd

docker run -itd --name osdnode1 --network ceph-network -e CLUSTER=ceph -e WEIGHT=1.0 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph -v /www/osd/1:/var/lib/ceph/osd/ceph-1 ceph/osd

docker run -itd --name osdnode2 --network ceph-network -e CLUSTER=ceph -e WEIGHT=1.0 -e MON_NAME=monnode -e MON_IP=172.20.0.10 -v /www/ceph:/etc/ceph -v /www/osd/2:/var/lib/ceph/osd/ceph-2 ceph/osd

# 增加monitor节点，组件成集群
docker run -itd --name monnode_1 --network ceph-network --ip 172.20.0.11 -e MON_NAME=monnode_1 -e MON_IP=172.20.0.11 -v /www/ceph:/etc/ceph ceph/mon
docker run -itd --name monnode_2 --network ceph-network --ip 172.20.0.12 -e MON_NAME=monnode_2 -e MON_IP=172.20.0.12 -v /www/ceph:/etc/ceph ceph/mon

# 创建gateway网关
docker run -itd --name gwnode --network ceph-network --ip 172.20.0.9 -p 9080:80 -e RGW_NAME=gwnode -v /www/ceph:/etc/ceph ceph/radosgw
# 查看ceph集群状态
sleep 10 && docker exec monnode ceph -s

# 查看access key
docker exec -it gwnode radosgw-admin user create --uid=user1 --display-name=user1
```

先写同步 ，后改进为异步写入

**接入阿里云OSS–公有云分布式存储**

**选择阿里云OSS的原因**

> 提供对象存储服务，适用于存放各种数据文件
>
> 可靠性：服务可靠性，数据持久性
>
> 安全性：资源隔离存储，访问鉴权
>
> 易用性：标准restful风格API，多种语言SDK接入
>
> 处理能力：海量规模，图片处理，音视频转码(显示的照片列表是计算后的缩略图，或者视频的分辨率)
>

**OSS相关专业术语**

> Bucket		存储空间，存储对象的容器，存在oss上的数据必须属于某一个bucket
>
> Object		对象或者文件
>
> Endpoint		OSS访问域名
>
> Region		区域或者数据中心
>
> AccessKey		资源访问密钥
>
> Object Meta		文件元信息，即文件的描述类信息
>
> Data		文件数据
>
> Key		文件名
>
> ACL（Access Control List)		存储空间或者文件的权限(bucket object的权限public-read-write公共读写、public-read公共读私有写、private私有读写、default默认权限用bucket的权限)

**rabbit mq**

```bash
mkdir -p /www/rabbitmq
# 5672 rabbitmq的端口 15672暴露出来的UI管理端口 25672rabbitmq集群之间通讯的端口
docker run -d --hostname rabbit-node1 --name rabbit-node1 -p 5672:5672 -p 15672:15672 -v /www/rabbitmq:/var/lib/rabbitmq rabbitmq:management

# 192.168.220.128:15672 默认用户名 guest 密码 guest
```

**同步与异步**

> 客户端上传文件到服务器端，服务器端存储数据文件到OSS中，等待存储成功后服务器端返回结果给客户端。
>
> 客户端上传文件给服务器端，服务器端将其放入任务队列中，并写入临时存储中，返回响应给客户端，后续找时间上传到OSS。

**任务队列RabbitMQ**

> 一种开源的消息代理
>
> 一种面向消息的中间件
>
> 一种消息队列服务

**解决问题**

> 逻辑解耦 异步任务
>
> 消息持久化，重启不影响，先进先出消费消息
>
> 流量削峰，组成集群大规模消息处理

**特点：**

> 可靠性：消息持久化、传输确认(基于事务)、发布确认(发送者等待接受者返回确认才标记消息为成功发送)
>
> 可扩展性：多个节点可以组成一个集群，可动态更改
>
> 多语言客户端：几乎支持所有常用语言
>
> 管理界面：易用的用户界面，便于监控和管理

**关键术语**

> Exchange：消息交换机，决定消息按什么规则，路由到哪个队列
>
> Queue：消息载体，每个消息都会被投到一个或多个队列
>
> Binding：绑定，把exchange和queue按照路由规则绑定起来
>
> Routing key：路由关键字，exchange根据关键字来投递消息
>
> Channel：消息通道，客户端的每个连接建立多个channel，接收和发送消息都需要建立通道
>
> Producer：消息生产者，用于投递消息的程序
>
> Consumer：消息生产者，用于接收消息的程序

**转发模式** Exchange工作模式

> Fanout：类似广播，转发到所有绑定交换机的Queue
>
> Direct：类似单播，RoutingKey和BindingKey完全匹配
>
> Topic：类似组播，转发到符合通配符匹配的Queue
>
> Headers：请求头中的属性信息与消息头匹配，才能接收消息



> http://192.168.220.128:15672
>
> 创建交换机 uploadserver.trans 和 queue uploadserver.trans.ceph  uploadservertrans.ceph.err 绑定到 uploadserver.trans中 Routing key =ceph以及 Routing key =cepherr
>

**架构微服务化** 划分的粒度粗细需要根据实际业务场景划分。

微服务是一种分散治理的开发技术和理念，服务之间的交互通过api接口

![](F:\markdown笔记\实战仿百度云盘实现企业级分布式云存储系统\image\37.png)

**应用场景**

原有单体应用逻辑复杂，可以按业务逻辑进行划分

**优缺点**

> **优点**
>
> 化繁为简，分散治理
>
> 服务间松耦合，服务内高内聚
>
> 服务可独立构造、部署、升级，可局部更新
>
> 提高系统容错性，减少系统整体崩溃概率
>
> 易于实现异构系统
>
> **缺点**
>
> 增加了运维部署的工作量和难度
>
> 增加了系统间调用的逻辑的处理难度
>
> 日志更难收集和统计
>
> 额外引入了一些非业务模块服务：注册发现 配置中心 分布式日志收集

![](F:\markdown笔记\实战仿百度云盘实现企业级分布式云存储系统\image\39.png)

为什么要暴露上传和下载两个微服务给用户，而不是直接调用API网关，通过网关控制。考虑到流量问题，对于文件传输的场景，上传和下载需要足够带宽的支持，才能有良好的用户体验，如果所有的流量都经过api网关，网关可能会有问题，导致其他业务api都会遭到性能瓶颈。可能有的用户只想进行业务登录，但是发现也会出现问题。雪崩效应导致整个系统崩溃。

服务注册和发现对外暴露的ip和端口，理论上说是变化的，所以不可能将调用服务的ip和端口写死在配置文件中，所以每次获取服务时都需要向服务注册和发现动态请求最新的服务ip和端口，后进行rpc调用。

**框架**

框架可以建立更好的代码规范、统一代码风格、节约开发成本、提高编码效率

流行web框架：基于net/http封装 Beego Echo Gin

**Gin框架**

> 一个比较轻巧的web框架
>
> API比较友好
>
> 源码注释比较详细，有利于学习
>
> 对外部库依赖比较少，体积不大

![](F:\markdown笔记\实战仿百度云盘实现企业级分布式云存储系统\image\40.png)

![](F:\markdown笔记\实战仿百度云盘实现企业级分布式云存储系统\image\41.png)

root开启远程登陆权限

> 1、开启服务`/etc/init.d/ssh start`
>
> 查看ssh服务状态 `sudo service ssh status`正常是active（running）
>
> 2、修改ssh登陆配置`sudo vim /etc/ssh/sshd_config`
>
> 3、修改以下配置：`PermitRootLogin yes` `PasswordAuthentication yes` `Port 22`
>
> 4、重启ssh服务即可`sudo service ssh restart`
>

docker安装

> apt-get update
> sudo apt-get install -y docker.io
>
> // 等待安装完毕，现在我们使用下面的命令启动Docker
>
> systemctl start docker
>
> // 使用下面的命令，如果看到输出docker start/running 就表示安装成功。退出时：esc:wq  或ctrl+c
>
> sudo service docker status
>
> // 关闭docker
>
> systemctl stop docker
>
> // 核对docker版本
>
> docker version
>
> // 安装curl
>
> apt install curl
>
> // 配置DaoCloud
>
> curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s https://n1mngx9r.mirror.aliyuncs.com
>
> // 查看{"registry-mirrors": ["https://n1mngx9r.mirror.aliyuncs.com"]}
>
> cat /etc/docker/daemon.json
>
> // 重启docker
>
> systemctl restart docker
>
> // 输入 `fdisk -l` 查看系统所有的磁盘和磁盘分区情况 
>
> // 输入 `df -TH` 查看，哪个分区挂载在**根目录**下 
>
> VMware虚拟机Ubuntu根目录磁盘空间(/dev/sda1)扩容
>
> https://blog.csdn.net/xwmrqqq/article/details/109828166