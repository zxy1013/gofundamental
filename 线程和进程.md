### 事件！！！！！！！！！！！！！



**线程**   

操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。一个线程是一个execution context（执行上下文），即一个cpu执行时所需要的一串指令。线程是指进程内的一条执行线路，或者说是进程中可执行代码的单独单元，它是操作系统的基本调度单元。一个进程至少有一个线程，即主线程，也可以有多个线程协同工作。进程从主线程开始执行，进而可以创建一个或多个附加线程来执行该进程内的并发任务，这就是基于线程的多任务。

**线程的工作方式**

假设你正在读一本书，没有读完，你想休息一下，但是你想在回来时恢复到当时读的具体进度。有一个方法就是记下页数、行数与字数这三个数值，这些数值就是execution context。如果你的室友在你休息的时候，使用相同的方法读这本书。你和她只需要这三个数字记下来就可以在交替的时间共同阅读这本书了。

线程的工作方式与此类似。CPU会给你一个在同一时间能够做多个运算的幻觉，实际上它在每个运算上只花了极少的时间，本质上CPU同一时刻只干了一件事。它能这样做就是因为它有每个运算的execution context。就像你能够和你朋友共享同一本书一样，多任务也能共享同一块CPU。

**进程**

一个程序的执行实例就是一个进程。每一个进程提供执行程序所需的所有资源。（进程本质上是资源的集合）一个进程有一个虚拟的地址空间、可执行的代码、操作系统的接口、安全的上下文（记录启动该进程的用户和权限等等）、唯一的进程ID、环境变量、优先级类、最小和最大的工作空间（内存空间），还要有至少一个线程。每一个进程启动时都会最先产生一个线程，即主线程。然后主线程会再创建其他的子线程。进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配的基本单位，是操作系统结构的基础。在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。

    与进程相关的资源包括:
    内存页（同一个进程中的所有线程共享同一个内存空间）
    文件描述符(e.g. open sockets)
    安全凭证（e.g.启动该进程的用户ID）

**进程与线程区别**

1.同一个进程中的线程共享同一内存空间，但是进程之间是独立的。
2.同一个进程中的所有线程的数据是共享的（进程通讯），进程之间的数据是独立的。
3.对主线程的修改可能会影响其他线程的行为，但是父进程的修改（除了删除以外）不会影响其他子进程。
4.线程是一个上下文的执行指令，而进程则是与运算相关的一簇资源。
5.同一个进程的线程之间可以直接通信，但是进程之间的交流需要借助中间代理来实现。
6.创建新的线程很容易，但是创建新的进程需要对父进程做一次复制。
7.一个线程可以操作同一进程的其他线程，但是进程只能操作其子进程。
8.线程启动速度快，进程启动速度慢（但是两者运行速度没有可比性）。

进程是资源拥有的基本单位，线程是独立调度与独立运行的基本单位。进程是资源管理和分配基本单元线程是调度、执行的基本单元 。二者均可并发执行

**多线程**  线程可以与同进程的其他线程共享数据，但是它拥有自己的栈空间且拥有独立的执行序列，线程执行开销小，但是不利于资源管理和保护， 线程不可以跨机器迁移，因为线程是存在于单一的进程之中，只能在一个核上运行 

start() 	        			线程准备就绪，等待CPU调度
setName() 				为线程设置名称
getName() 				获取线程名称
setDaemon(True)     设置为守护线程
join() 						  逐个执行每个线程，执行完毕后继续往下执行
run() 						  线程被cpu调度后自动执行线程对象的run方法，如果想自定义线程类，直接重写run方法就行了

**Thread类**

**1.普通创建方式**

```
import threading
import time
def run(n):
	time.sleep(1)
	print("task", n)

timei = time.time()
t1 = threading.Thread(target=run, args=("t1",)) # args：参数
t2 = threading.Thread(target=run, args=("t2",))
t1.start()
t2.start()
print(time.time()-timei) # 由于没有join，print又属于主线程 所以值约为0 完毕后主线程退出 第三个例子使用join 主线程就会等这些子线程执行完之后再执行 主线程必须在子线程退出后才能退出
```

**2.继承threading.Thread来自定义线程类**

其本质是重构Thread类中的run方法

```
import threading
import time

class MyThread(threading.Thread):
    def __init__(self, n):
        super(MyThread, self).__init__()  # 重构run函数必须要写
        self.n = n
    def run(self):
        print("task", self.n)
        time.sleep(1)
        print('1s')
        
t1 = MyThread("t1")
t2 = MyThread("t2")
t1.start()
t2.start()
```

**3.计算子线程执行的时间**

sleep的时候不会占用cpu，在sleep的时候操作系统会把线程暂时挂起

```
import threading
import time

def run(n):
    print("task", n,threading.current_thread()) # 输出当前的线程
    time.sleep(1)
    print('1s')
 
strat_time = time.time()
t_obj = []   # 定义列表用于存放子线程实例
for i in range(3):
    t = threading.Thread(target=run, args=("t-%s" % i,))
    t.start()
    t_obj.append(t) 
    
for tmp in t_obj:
    tmp.join() # 为每个子线程添加join之后，主线程就会等这些子线程执行完之后再执行。子线程使用了join方法后，主线程必须在子线程退出后才能退出
print("cost:", time.time() - strat_time) # 1.0159633159637451
print(threading.current_thread())       # 输出当前线程 <_MainThread(MainThread, started 2016)>
```

**4.统计当前活跃的线程数**

由于主线程比子线程快很多，当主线程执行active_count()时，其他子线程都还没执行完毕，因此利用主线程统计的活跃的线程数num = sub_num(子线程数量)+1(主线程本身)

```
import threading
import time

def run(n):
    print("task", n)    
    time.sleep(2)       # 此时子线程停1s
    print("k")
    
for i in range(3):
    t = threading.Thread(target=run, args=("t-%s" % i,))
    t.start()
    
time.sleep(0.5)     # 主线程停0.5秒 否则可能无法监控就运行完毕
print(threading.active_count()) # 输出当前活跃的线程数
for i in threading.enumerate(): # 输出当前所有的活跃线程
    print(i)
```

此外我们还能发现在python内部默认会等待最后一个进程执行完后再执行exit()，或者说python内部在此时有一个隐藏的join()。

**5.守护线程**

使用setDaemon(True)把所有的子线程都变成了主线程的守护线程，总的来说就是别的线程运行完了就先退出，不用管我这个守护线程就行了。既然不用管我了，那就千万别对守护线程加join方法。主线程退出了，子线程也被强行退出了。 

```
import threading
import time

def run(n):
    print("task", n)
    time.sleep(5)  # 此时子线程停5s
    print('1')

for i in range(3):
    t = threading.Thread(target=run, args=("t-%s" % i,))
    t.setDaemon(True)  # 把子进程设置为守护线程，必须在start()之前设置
    t.start( )

time.sleep(0.5)  # 主线程停0.5秒
print(threading.active_count( ))  # 输出活跃的线程数
'''
task t-0
task t-1
task t-2
4
'''
```

当我们在程序运行中，执行一个主线程，如果主线程又创建一个子线程，主线程和子线程就分兵两路，分别运行，那么当主线程完成想退出时，会检验子线程是否完成。如果子线程未完成，则主线程会等待子线程完成后再退出。但是有时候我们需要的是只要主线程完成了，不管子线程是否完成，都要和主线程一起退出，这时就可以用setDaemon方法啦。join()：在子线程完成运行之前，这个子线程的父线程将一直被阻塞。

**6.GIL**

在非python环境中，单核情况下，同时只能有一个任务执行。多核时可以支持多个线程同时执行。但是在python中，无论有多少核，同时只能执行一个线程。究其原因，这就是由于GIL的存在导致的。GIL的全称是Global Interpreter Lock(全局解释器锁)，来源是python设计之初的考虑，为了数据安全所做的决定。某个线程想要执行，必须先拿到GIL，我们可以把GIL看作是“通行证”，并且在一个python进程中，GIL只有一个。拿不到通行证的线程，就不允许进入CPU执行。GIL只在cpython中才有，因为cpython调用的是c语言的原生线程，所以他不能直接操作cpu，只能利用GIL保证同一时间只能有一个线程拿到数据。而在pypy和jpython中是没有GIL的。

CPython 不可能容忍一个线程一直独占解释器，它会轮流执行 Python 线程。这样一来，用户看到的就是“伪”并行，即 Python 线程在交替执行，来模拟真正并行的线程。GIL 在 Python 程序的工作示例。其中，Thread 1、2、3 轮流执行，每一个线程在开始执行时，都会锁住 GIL，以阻止别的线程执行；同样的，每一个线程执行完一段后，会释放 GIL，以允许别的线程开始利用资源。CPython 中还有另一个机制，叫做间隔式检查（check_interval），意思是 CPython 解释器会去轮询检查线程 GIL 的锁住情况，每隔一段时间，Python 解释器就会强制当前线程去释放 GIL，这样别的线程才能有执行的机会。
如果你有个操作比如 x += 1，这个操作需要多个字节码操作，在执行这个操作的多条字节码期间的时候可能中途就换thread了，这样就出现了data races的情况了。

**Python多线程**：
python在使用多线程的时候，调用的是c语言的原生线程。

    拿到公共数据，申请GIL
    python解释器调用os原生线程
    os操作cpu执行运算
    当该线程执行时间到后，无论运算是否已经执行完，GIL都被要求释放
    进而由其他进程重复上面的过程
    等其他进程执行完后，又会切换到之前的线程（从他记录的上下文继续执行）
    整个过程是每个线程执行自己的运算，当执行时间到就进行切换（context switch）。
    python针对不同类型的代码执行效率也是不同的：
    1、CPU密集型代码(各种循环处理、计算等等)，在这种情况下，由于计算工作多，ticks计数很快就会达到阈值，然后触发GIL的释放与再竞争（多个线程来回切换当然是需要消耗资源的），所以python下的多线程对CPU密集型代码并不友好。
    2、IO密集型代码(文件处理、网络爬虫等涉及文件读写的操作)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。所以python的多线程对IO密集型代码比较友好。
    
    使用建议？
    
    python下想要充分利用多核CPU，就用多进程。因为每个进程有各自独立的GIL，互不干扰，这样就可以真正意义上的并行执行，在python中，多进程的执行效率优于多线程(仅仅针对多核CPU而言)。
    
    GIL在python中的版本差异：
    
    1、在python2.x里，GIL的释放逻辑是当前线程遇见IO操作或者ticks计数达到100时进行释放。（ticks可以看作是python自身的一个计数器，专门做用于GIL，每次释放后归零，这个计数可以通过sys.setcheckinterval 来调整）。而每次释放GIL锁，线程进行锁竞争、切换线程，会消耗资源。并且由于GIL锁存在，python里一个进程永远只能同时执行一个线程(拿到GIL的线程才能执行)，这就是为什么在多核CPU上，python的多线程效率并不高。
    2、在python3.x中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。

**7.线程锁**

由于线程之间是进行随机调度，当多个线程同时修改同一条数据时可能会出现脏数据，所以，出现了线程锁，即同一时刻允许一个线程执行操作。线程锁用于锁定资源，你可以定义多个锁, 当你需要独占某一资源时，任何一个锁都可以锁这个资源，就好比你用不同的锁都可以把相同的一个门锁住是一个道理。

由于线程之间是进行随机调度，如果有多个线程同时操作一个对象，如果没有很好地保护该对象，会造成程序结果的不可预期，我们也称此为“线程不安全”。

**临界区**（Critical  Section）：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；虽然临界区同步速度很快，但却只能用来同步本进程内的线程，不能同步多个进程中的线程。 

**互斥锁同步锁（mutex）**  分段加锁 只影响读写的地方加锁 可实现进程同步

为了方式上面情况的发生，就出现了互斥锁(Lock) 可能会死锁

```
import threading
import time

def run(n):
    lock.acquire()  # 获取锁
    global num
    num += 1
    lock.release()  # 释放锁

lock = threading.Lock()     #实例化一个锁对象
num = 0
t_obj = []  
for i in range(20000):
    t = threading.Thread(target=run, args=("t-%s" % i,))
    t.start()
    t_obj.append(t)
for t in t_obj:
    t.join()
print(num)
```

**递归锁**

RLcok类的用法和Lock类一模一样，但它支持嵌套，为了支持在同一线程中多次请求同一资源，python提供了“可重入锁”：threading.RLock。RLock内部维护着一个Lock和一个counter变量，counter记录了acquire的次数，从而使得资源可以被多次acquire。直到一个线程所有的acquire都被release，其他的线程才能获得资源。

```
import threading,time

class myThread(threading.Thread):
    def doA(self):
        rLock.acquire()
        print(self.name,"gotlockA1",time.ctime())
        time.sleep(2)
        rLock.acquire()
        print(self.name,"gotlockB1",time.ctime())
        rLock.release()
        rLock.release()

    def doB(self):
        rLock.acquire()
        print(self.name,"gotlockB2",time.ctime())
        time.sleep(2)
        rLock.acquire()
        print(self.name,"gotlockA2",time.ctime())
        rLock.release()
        rLock.release()

    def run(self):
        self.doA()
        self.doB()

if __name__=="__main__":
    rLock = threading.RLock()  # RLock对象，在同一线程内，程序不会堵塞。
    threads=[]
    for i in range(2):
        threads.append(myThread())
    for t in threads:
        t.start()
    for t in threads:
        t.join()
'''
Thread-20107 gotlockA1 Wed Sep  1 19:52:27 2021
Thread-20107 gotlockB1 Wed Sep  1 19:52:29 2021
Thread-20107 gotlockB2 Wed Sep  1 19:52:29 2021
Thread-20107 gotlockA2 Wed Sep  1 19:52:31 2021
Thread-20108 gotlockA1 Wed Sep  1 19:52:31 2021
Thread-20108 gotlockB1 Wed Sep  1 19:52:33 2021
Thread-20108 gotlockB2 Wed Sep  1 19:52:33 2021
Thread-20108 gotlockA2 Wed Sep  1 19:52:35 2021
'''
```

**8.信号量（BoundedSemaphore类）**可实现进程同步

互斥锁同时只允许一个线程更改数据，而Semaphore是同时允许一定数量的线程更改数据 ，比如厕所有3个坑，那最多只允许3个人上厕所，后面的人只能等里面有人出来了才能再进去。

```
import threading, time

count= 10
class myThread(threading.Thread):
	def run(self):
		global count
		if semaphore.acquire( ):
			print('--get num:', count)
			time.sleep(3) # 造成脏数据
			count = count - 1 # 对此公共变量进行-1操作
			semaphore.release( )  # +1

if __name__ == "__main__":
	semaphore = threading.Semaphore(5)  # 可以允许5个同时进入,可以用threading.BoundedSemaphore()
	thrs = [ ]
	for i in range(6):
		thrs.append(myThread( ))
	for t in thrs:
		t.start( )
# --get num: 10
--get num: 10
--get num: 10
--get num: 10
--get num: 10
--get num: 9
```

**9.事件（Event类）**可实现进程同步

python线程的事件用于主线程控制其他线程的执行，事件是一个简单的线程同步对象
clear 	将event设置为“False”
set 	   将event设置为“True”， 所有阻塞池的线程激活进入就绪状态，等待操作系统调度 
isSet     返回event的状态值 
wait 	 会一直监听flag，如果event.isSet()==False 将阻塞线程 

事件处理的机制：全局定义了一个“Flag”，当flag值为“False”，那么event.wait()就会阻塞，当flag值为“True”，那么event.wait()便不再阻塞。

```
# 利用Event类模拟红绿灯
import threading
import time

event = threading.Event()

def lighter():
    count = 0
    event.set()     # 初始值为绿灯
    while True:
        if 5 < count <=10 :
            event.clear()  # 红灯，清除标志位
            print("\33[41;1mred light is on...\033[0m")
        elif count > 10:
            event.set()  # 绿灯，设置标志位
            count = 0
        else:
            print("\33[42;1mgreen light is on...\033[0m")
        time.sleep(1)
        count += 1

def car(name):
    while True:
        if event.is_set():      # 判断是否设置了标志位
            print("[%s] running..."%name)
            time.sleep(1)
        else:
            print("[%s] sees red light,waiting..."%name)
            event.wait()
            print("[%s] green light is on,start going..."%name)

light = threading.Thread(target=lighter,)
light.start()
car = threading.Thread(target=car,args=("MINI",))
car.start()
```

**10.定时器（Timer类）**

定时器，指定n秒后执行某操作

```
from threading import Timer

def hello():
    print("hello, world")

t = Timer(1, hello)
t.start()  # after 1 seconds, "hello, world" will be printed
```

**多进程**

每个进程都是由父进程提供的。每启动一个子进程就从父进程克隆一份数据，但是进程之间的数据本身是不能共享的。子进程获得父进程的数据空间，堆和栈的复制品

```
from multiprocessing import Process
import os

def info(title):
    print(title)
    print('module name:', __name__)
    print('parent process:', os.getppid())  # 获取父进程id
    print('process id:', os.getpid())   # 获取自己的进程id

def f(name):
    info('\033[31;1mfunction f\033[0m')
    print('hello', name)

if __name__ == '__main__':
    info('\033[32;1mmain process line\033[0m')
    p = Process(target=f, args=('bob',))
    p.start()
    p.join()
```

**进程间通信**

由于进程之间数据是不共享的，所以不会出现多线程GIL带来的问题。多进程之间的通信通过Queue()或Pipe()来实现 进程同步：信号量 事件 互斥锁

**Queue()**

使用方法跟threading里的queue差不多

```
from multiprocessing import Process, Queue

def f(q):
    q.put([42, None, 'hello'])

if __name__ == '__main__':
    q = Queue()
    p = Process(target = f, args=(q,))
    p.start()
    print(q.get())    # prints "[42, None, 'hello']"
```

**Pipe**()

Pipe的本质是进程之间的数据传递，而不是数据共享，这和socket有点像。pipe()返回两个连接对象分别表示管道的两端，每端都有send()和recv()方法。如果两个进程试图在同一时间的同一端进行读取和写入那么，这可能会损坏管道中的数据。

```
from multiprocessing import Process, Pipe

def f(conn):
    conn.send([42, None, 'hello'])
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe() 
    p = Process(target=f, args=(child_conn,))
    p.start()
    print(parent_conn.recv())   # prints "[42, None, 'hello']"
```

**Manager**

通过Manager可实现进程间数据的共享。Manager()返回的manager对象会通过一个服务进程来使其他进程通过代理的方式操作python对象。manager对象支持 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value ,Array

```
from multiprocessing import Process, Manager

def f(d, l,n):
    d[n] = '1'
    d['2'] = 2
    d[0.25] = None
    l.append(n)

if __name__ == '__main__':
    with Manager() as manager:
        d = manager.dict()
        l = manager.list(range(5))  # [0, 1, 2, 3, 4]
        p_list = []
        for i in range(3):
            p = Process(target=f, args=(d, l,i))
            p.start()
            p_list.append(p)
        for res in p_list:
            res.join()
        print(d)  # {0: '1', '2': 2, 0.25: None, 1: '1', 2: '1'}
        print(l)  # [0, 1, 2, 3, 4, 0, 1, 2]

```

**进程锁（进程同步）**

数据输出的时候保证不同进程的输出内容在同一块屏幕正常显示，防止数据乱序的情况。获得内部锁的唯一途径是：进入这个内部锁保护的同步块或方法。减小竞争发生可能性的有效方式是尽可能缩短把持锁的时间

```
from multiprocessing import Process, Lock

def f(l, i):
    l.acquire()
    try:
        print('hello world', i)
    finally:
        l.release()

if __name__ == '__main__':
    lock = Lock()
    for num in range(10):
        Process(target=f, args=(lock, num)).start()
```

**进程池**

由于进程启动的开销比较大，使用多进程的时候会导致大量内存空间被消耗。为了防止这种情况发生可以使用进程池，（由于启动线程的开销比较小，所以不需要线程池这种概念，多线程只会频繁得切换cpu导致系统变慢，并不会占用过多的内存空间）

进程池中常用方法：
apply() 			同步执行（串行）
apply_async() 异步执行（并行）
terminate()     立刻关闭进程池
join() 			   主进程等待所有子进程执行完毕。必须在close或terminate()之后。
close() 		     等待所有进程结束后，才关闭进程池。

```
from multiprocessing import Process,Pool
import time

def Foo(i):
    time.sleep(2)
    print( i + 100 )
    return i + 100

def Bar(arg):
    print('-->exec done:',arg)

if __name__ == '__main__':
    pool = Pool(5)  # 允许进程池同时放入5个进程
    for i in range(10):
        pool.apply_async(func=Foo, args=(i,),callback=Bar) # 十个进程
        # func子进程执行完后，才会执行callback，否则callback不执行（而且callback是由父进程来执行的）
    print('end')
    pool.close()
    pool.join() # 主进程等待所有子进程执行完毕。必须在close()或terminate()之后。
```

进程池内部维护一个进程序列，当使用时，去进程池中获取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。在上面的程序中产生了10个进程，但是只能有5同时被放入进程池，剩下的都被暂时挂起，并不占用内存空间，等前面的五个进程执行完后，再执行剩下5个进程。

**协程**

线程和进程的操作是由程序触发系统接口，最后的执行者是系统，它本质上是操作系统提供的功能。而协程的操作则是程序员指定的，在python中通过yield，人为的实现并发处理。

    协程，又称微线程，纤程。英文名Coroutine。
    协程是一种用户态的轻量级线程。
    协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。因此：协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态， 换种说法：进入上一次离开时所处逻辑流的位置。

协程的好处

    无需线程上下文切换的开销
    无需原子操作锁定及同步的开销 “原子操作(atomic operation)是不需要synchronized”，所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch（切换到另一个线程）。原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序是不可以被打乱。视作整体是原子性的核心。方便切换控制流，简化编程模型。
    高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。

缺点：

    无法利用多核资源：协程的本质是个单线程,它不能同时将单个CPU的多个核用上,协程需要和进程配合才能运行在多CPU上.
    和多进程配合进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序

协程的适用场景：当程序中存在大量不需要CPU的操作时（IO）。
常用第三方模块gevent和greenlet。（本质上，gevent是对greenlet的高级封装，因此一般用它就行，这是一个相当高效的模块。）

**greenlet**

```
from greenlet import greenlet

def test1():
    print(12)
    gr2.switch()
    print(34)
    gr2.switch()

def test2():
    print(56)
    gr1.switch()
    print(78)

gr1 = greenlet(test1)
gr2 = greenlet(test2)
gr1.switch() # 切换到gr1
# 12 56 34 78
```

greenlet就是通过switch方法在不同的任务之间进行切换。

**gevent**

```
from gevent import monkey; monkey.patch_all()
import gevent
import requests

def f(url):
    print('GET: %s' % url)
    resp = requests.get(url)
    data = resp.text
    print('%d bytes received from %s.' % (len(data), url))

gevent.joinall([
    gevent.spawn(f, 'https://www.python.org/'),
    gevent.spawn(f, 'https://www.yahoo.com/'),
    gevent.spawn(f, 'https://github.com/'),
])
```

通过joinall将任务f和它的参数进行统一调度，实现单线程中的协程。



并发是逻辑上的同时发生（simultaneous），而并行是物理上的同时发生

**并发**：在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行。其中两种并发关系分别是同步和互斥，其中并发又有伪并发和真并发，伪并发是指单核处理器的并发，真并发是指多核处理器的并发。

互斥：进程间相互排斥的使用临界资源的现象，就叫互斥。

同步： 进程之间的关系不是相互排斥临界资源的关系，而是相互依赖的关系。进一步的说明：就是前一个进程的输出作为后一个进程的输入，当第一个进程没有输出时第二个进程必须等待。具有同步关系的一组并发进程相互发送的信息称为消息或事件。

**并行**：在单处理器中多道程序设计系统中，进程被交替执行，表现出一种并发的外部特种；在多处理器系统中，进程不仅可以交替执行，而且可以重叠执行。在多处理器上的程序才可实现并行处理。从而可知，**并行是针对多处理器而言**的。并行是同时发生的多个并发事件，具有并发的含义，但**并发不一定并行**，也亦是说并发事件之间不一定要同一时刻发生。当两个并行的线程，在没有任何约束的情况下，访问一个共享变量或者共享对象的一个域，而且至少要有一个操作是写操作，就可能发生数据竞争错误。

多线程：多线程是程序设计的逻辑层概念，它是进程中并发运行的一段代码。多线程可以实现线程间的切换执行。

异步：异步和同步是相对的，同步就是顺序执行，执行完一个再执行下一个，需要等待、协调运行。异步就是彼此独立,在等待某事件的过程中继续做自己的事，不需要等待这一事件完成后再工作。线程就是实现异步的一个方式。异步是让调用方法的主线程不需要同步等待另一线程的完成，从而可以让主线程干其它的事情。
异步和多线程并不是一个同等关系,异步是最终目的,多线程只是我们实现异步的一种手段。异步是当一个调用请求发送给被调用者,而调用者不用等待其结果的返回而可以做其它的事情。实现异步可以采用多线程技术或则交给另外的进程来处理。 

多个线程可同时操作一个数据，为了保证该数据的准确性，可将操作该数据的部分改为同步

可重入函数不可以调用不可重入函数

两个线程同时对简单类型全局变量进行写操作也需要互斥

实现可重入函数时， 引入的全局变量要用互斥量加以保护，自动变量局部作用域变量 不需要

**轮询调度算法**的原理是每一次把来自用户的请求轮流分配给内部中的服务器，从1开始，直到N(内部服务器个数)，然后重新开始循环。
**抢占式任务调度**允许调度程序根据某种原则去暂停某个正在执行的进程，将已分配给该进程的处理机重新分配给另一进程。

抢占方式的优点是，可以防止一个长进程长时间占用处理机，能为大多数进程提供更公平的服务，特别是能满足对响应时间有着较严格要求的实时任务的需求。
因为抢占式调度可能会暂停一些进程，需要记录进程的运行状态，较为复杂。轮询式只需要轮流分配资源，调度简单。

**无锁化编程**

```py
1.针对计数器，可以使用原子加 # 原子操作
2.只有一个生产者和一个消费者，那么就可以做到免锁访问环形缓冲区（Ring Buffer）#  生产者和消费者需要修改的位置是分开的（生产者加在尾部，消费者从头部消费），且只有一个读一个写，不会发生冲突。所以只有一点需要关注，就是尾部指针和头部指针每次需要比较以避免生产溢出或者过度消费，而简单变量的读操作都是原子的。 
3.RCU（Read-Copy-Update）# 新旧副本切换机制，对于旧副本可以采用延迟释放的做法 #  复制一份，修改完后，替换回去时只需替换一个指针或引用，锁住的粒度非常小。但有可能还有线程持有的是旧的指针，因此旧的副本需要延迟释放。 
4.CAS（Compare-and-Swap），如无锁栈，无锁队列等待 # 汇编级别支持的指令cmpxchg，锁定内存地址，比较地址中修改前的内容是否与修改时的值一致，如果不一致就说明有其他线程改动，需要重新做。如，内存地址0x123456中原来存放的是10101010，但CPU执行到cmpxchg指令时，发现内存中变成了11111111，那么就认为其他线程已经修改了这个地址的值，需要重新读取0x123456中的值11111111，再做一次cmpxchg，如果这次发现内存中仍然是11111111，那么cmpxchg就会把新的值写入到0x123456中去。这里面有个ABA问题，就是有线程改了2次从11111111 -> 10111111 ->  11111111，那么CAS操作是识别不了的，需要从业务层去避免
```

volatile变量具有synchronized的可见性特性，调用volatile变量时，使用前都会刷新该变量，保证变量的值为最新的。不保证互斥性,所以不具备原子特性  

**数据库以及线程发生死锁的必要条件**

互斥条件：一个资源每次只能被一个进程使用
请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。
循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

**数据库以及线程发生死锁的主要原因**

资源分配不当
进程运行推进的顺序不合适
系统资源不足

 **实时操作系统的基本特性** 

```
实时操作系统（RTOS）是指当外界事件或数据产生时，能够接受并以足够快的速度予以处理，其处理的结果又能在规定的时间之内来控制生产过程或对处理系统做出快速响应，调度一切可利用的资源完成实时任务，并控制所有实时任务协调一致运行的操作系统。提供及时响应和高可靠性是其主要特点。所谓“实时操作系统”，实际上是指操作系统工作时，其各种资源可以根据需要随时进行动态分配。由于各种资源可以进行动态分配，因此其处理事务的能力较强、速度较快。
提供及时响应和高可靠性是实时操作系统主要特点。实时操作系统有硬实时和软实时之分，硬实时要求在规定的时间内必须完成操作，这是在操作系统设计时保证的；软实时则只要按照任务的优先级，尽可能快地完成操作即可。
```

**分时操作系统的基本特性** 

```
分时操作系统是使一台计算机采用时间片轮转的方式同时为几个、几十个甚至几百个用户服务的一种操作系统。
把计算机与许多终端用户连接起来，分时操作系统将系统处理机时间与内存空间按一定的时间间隔，轮流地切换给各终端用户的程序使用。由于时间间隔很短，每个用户的感觉就像他独占计算机一样。分时操作系统的特点是可有效增加资源的使用率。
提供多路性：即众多联机用户可以同时使用同一台计算机
提供独占性：各终端用户感觉到自己独占了计算机
```

有三个线程T1,T2,T3,下面方法可以确保它们按顺序执行的有

# 正确答案: A B C  你的答案: B C (错误) 

先启动最后一个(T3调用T2,T2调用T1)
可以用线程类的join()方法在一个线程中启动另一个线程,另一个线程完成
先启动第一个(T3调用T2,T2调用T1)

```java
实际上先启动三个线程中哪一个都行，
因为在每个线程的run方法中用join方法限定了三个线程的执行顺序。
即便是第二个线程先启动执行了，由于t1.join()方法，
使得线程2需要等待线程1运行结束后才能继续运行。
所以三个线程的启动顺序无关紧要！！！
```

**eg:** 有两个线程，最初 n=0，一个线程执行 n++; n++; 另一个执行 n+=2; 问，最后可能的 n 值

大家要知道 C语言中的 ++ 和 += 并不是原子操作，而是通过多条微程序组成的，因此 ++ 和 += 在执行过程中可能被中断的 

第一种可能情况：现在假设两个线程顺序执行的那么结果显然是 4。  

第二种可能情况：再假设现在第一个n++ 已经执行完了 但是结果还没有写回内存 这个时候 n+=2 已经全部执行完  写进了内存 结束 然后回到n++的写回操作 这个时候内存就从2被改回1了，后面再来一次n++ 结果就为2。  

第三种可能情况： n+=2 先读取n的值到寄存器 即0入寄存器 这个时候被中断  第一个n++开始执行 并直到结束    内存被改成了1 ，然后 n+=2 继续执行 结束后内存变为2 第二个n++再执行 结果就是3了 