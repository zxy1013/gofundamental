**开发环境**

![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-10_09-54-00.png)

**git bash配置**

```bash
Administrator@PC-202003301339 MINGW64 ~
$ git config --global user.name "zxy1013"

Administrator@PC-202003301339 MINGW64 ~
$ git config --global user.email "1253141170@qq.com"

Administrator@PC-202003301339 MINGW64 ~
$ git config --global --list
```

**安装docker-compose**

```bash
sudo curl -L "https://get.daocloud.io/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

chmod +x /usr/local/bin/docker-compose

docker-compose -version
docker-compose
```

goland打开tools打开file watch中的 gofmt和goimports`go get golang.org/x/tools/cmd/goimports`，作用是做自动格式化。

项目前端基于vue所以需要搭建nodejs环境。安装完成后`node -v`  `npm -v`并配置cnpm镜像， 使用定制的cnpm (gzip 压缩支持) 命令行工具代替默认的npm，`npm install -g cnpm --registry=https://registry.npmmirror.com`   `cnpm -v`



**go的package包管理以及go的编码规范**

go传统模式下，项目必须新建在go path下的src目录下，且设置`GO111MODULE=off`，此时import的东西会先在gopath的src目录下找，后在goroot下的src目录下找。

go modules模式下设置`GO111MODULE=on`，可以在任意位置新建项目，需要`go mod init`，能用go modules就用go modules。

**Go语言编码规范**

> 代码规范不是强制性的，不遵循规范写出来的代码运行也是没有问题的。目的是为了方便团队形成一个统一的代码风格。提高代码的可读性、规范性和统一性。规范并不是唯一的，理论上每个公司都可以制定自己的规范。
>
> 必须使用Gofmt做代码格式化和自动优化。如果使用Goland IDE开发可以选择goimports, goimports包含了Gofmt的功能同时还支持自动添加和删除package导入功能Goland -> Preferences -> File Watchers -> 添加goimports
>
> 在引包的时候，需要注意**不要使用相对路径**，而应该使用绝对路径。但是如果引入本项目的其他包，可以使用相对路径。如果引入了三种类型的包，标准库包，程序内部包，第三方包，建议采用如下方式进行组织包。
>
>         package main
>         import (
>             "encoding/json"
>             "strings"
>             
>             "myproject/models"
>             "myproject/controller"
>             "myproject/utils"
>        
>             "github.com/astaxie/beego"
>             "github.com/go-sql-driver/mysql"
>          )
>  **命名规范**
>
> 包名、文件名、结构体名、接口命名、变量命名、常量命名
>
> 包的名字应该和目录保持一致，采取有意义的包名，并且不能和标准库冲突，包名应该为小写字母开头，不要使用下划线或或者大小写。
>
> 文件名应该为小写字母开头，使用下划线分割各个单词(蛇形命名)。
>
> 结构体名采用驼峰命名法，首字母根据访问控制大写或小写，声明和初始化格式采用多行。
>
> 接口命名单个变量的结构名以“er“作为后缀。
>
> 变量命名遵循驼峰命名法，首字母根据访问控制大写或小写，专有名词全部大写或小写APIClient UserID或apiClient userID表示包外可或不可访问。若变量类型为bool类型，名称应该以Has is Can Allow开头。
>
> 常量命名均需使用全部大写字母组成，并使用下划线分词。若是枚举的常量，需要先创建相应类型。
>
> ```go
> type Scheme string
> const(
> 	HTTP Scheme = "http"
>        HTTPS Scheme = "https"
> )
> ```
>
> **注释规范**
>
> `/**/` 一般用于包的文档注释或注释成块的代码片段。
>
> 每个包都需要有一个包注释，在一个文件中即可，在package语句之前需要有一个块注释。包含包的基本简介、创建人: xxx、创建时间: yyymmdd。
>
> 函数注释，函数名, 简要说明、参数列表, 说明、返回值, 说明。
>
> 中文和英文之间英文和中文标点之间都需要使用空格。
>
> `//` 在任何地方都可以声明，单行注释不能太长，禁止超过120字符。
>
> **代码风格**
>
> 错误处理的原则就是不能丢弃任何有返回err的调用，不要采用`_`丢弃，必须全部处理。接收到错误，要么返回err，要么实在不行就panic，或者使用log记录下来 ， error的信息不要采用大写字母，尽量保持你的错误简短，但是要足够表达你的错误的意思。 尽早return，一旦有错误，马上返回。尽量不要使用panic，只有当实在不可运行的情况采用panic，例如文件无法打开，数据库无法连接导致程序无法正常运行。强烈建议在main包中使用log.Fatal来记录错误，这样就可以由log来结束程序。

**rpc**  processon画图工具

> - RPC（Remote Procedure Call）远程过程调用，简单的理解是一个节点请求另一个节点提供的服务
> - 本地过程调用：如果需要将本地student对象的age+1，可以实现一个addAge()方法，将student对象传入，对年龄进行更新之后返回即可，本地方法调用的函数体通过函数指针来指定。
> - 远程过程调用：上述操作的过程中，如果addAge()这个方法在服务端，执行函数的函数体在远程机器上，如何告诉机器需要调用这个方法呢？
>
> > 1. 首先客户端需要告诉服务器，需要调用的函数ID。传指针是不行的，因为两个地址空间是完全不一样的。在RPC中，函数和进程ID存在一一映射关系。客户端和服务端需要分别维护一个{函数 **Call-ID**}的对应表，两者不需要完全相同，但是对应关系需要一样。客户端做远程调用时，需要查一下函数对应的ID，然后附上这个ID，执行函数的代码。服务器端也通过查表，来确定客户端需要调用的函数，执行相应函数的代码。
> > 2. 客户端需要把本地参数传给远程函数，本地调用的过程中，直接压栈即可，但是在远程调用过程中不再同一个内存里，无法直接传递函数的参数，甚至有时候客户端服务器使用的都不是同一种语言。因此需要客户端把参数转换成字节流，传给服务端，然后服务端将字节流转换成自身能读取的格式，是一个序列化和反序列化的过程。同理，从服务器端返回的值也需要**序列化和反序列化**的过程。
> > 3. **网络传输**。数据准备好了之后，如何进行传输？远程调用往往用在网络上。客户端服务器通过网络连接，所有数据需要网络传输。因此需要一个网络传输层，网络传输层需要把调用的ID和序列化后的参数传给服务端，然后把计算好的结果序列化传给客户端，因此使用的协议不限，只要能完成传输就行，TCP 以及基于其的http协议即可完成上述过程，gRPC中采用的是HTTP2.0协议。因为http协议是一次性的，一旦对方返回结果，连接断开，性能要求高时比较麻烦。
>
> **eg**
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-11_10-56-49.png)
>
> rpc中第一个点是选择序列化和反序列化的**数据编码**协议，若是成功实现，客户端服务器使用是否是同一种语言不再重要，只要能实现对等的序列化反序列化即可。
>
> 第二点是选择**网络传输**协议，基于tcp封装或是直接使用http
>
> **rpc开发要素分析**
>
> 一个基本RPC框架由4部分组成，分别是：客户端、客户端存根、服务端、服务端存根。
>
> **客户端**（Client）：服务调用的发起方，也称为消费者。
>
> **客户端存根**（ClientStub）：
>
> 该程序运行在客户端所在的计算机上，主要用来存储要调用服务器的地址，对客户端发送的数据进行序列化、建立网络连接之后发送数据包给Server端的存根程序。
>
> 接收Server端存根程序响应的消息，对消息进行反序列化。
>
> **服务端**（Server）:提供客户端想要调用的函数
>
> **服务端存根**（ServerStub）:
>
> 接收客户端的消息并反序列化，对server端响应的消息进行序列化并响应给Client端
>
> 总体来讲客户端和服务端的Stub在底层帮助我们实现了Call ID的映射、数据的序列化和反序列化、网络传输，这样RPC客户端和RPC服务端 只需要专注于服务端和客户端的业务逻辑层即可。
>
> **动态代理技术** ServerStub和ClientStub程序，在具体编码和开发实践中，都是使用动态代理技术自动生成的一段程序。
>
> go语言的rpc的序列化和反序列化协议是gob协议，可以替换为json

**grpc**

> gRPC是一种现代化开源的高性能RPC框架，能够运行于任意环境之中。最初由谷歌进行开发。它使用HTTP/2作为传输协议。
>
> **protobuf**
>
> grpc的数据编解码使用protobuf， Protobuf是Protocol Buffer的简称，它是Google公司于2008年开源的一种高效的平台无关、语言无关、可扩展的数据格式，目前Protobuf作为接口规范的描述语言，可以作为Go语言RPC接口的基础工具。其压缩效率高，压缩比大，传输速度快。 
>
> protobuf协议编译器是用c++编写的，根据自己的操作系统下载对应版本的protoc编译器：https://github.com/protocolbuffers/protobuf/releases，解压后拷贝路径到系统路径下。`C:\Users\Administrator\Downloads\protoc-3.19.4-win64\bin`
>
> protoc-gen-go，安装生成Go语言代码的工具
>
> ```bash
> go get -u github.com/golang/protobuf/protoc-gen-go
> ```
>
> protobuf是一个与语言无关的一个数据协议，所以我们需要先编写IDL文件然后借助专用工具生成指定语言的代码，从而实现数据的序列化与反序列化过程 
>
> 新建文件rpckj.proto
>
> ```protobuf
> // 指定使用protobuf版本
> // 此处使用v3版本
> syntax = "proto3";
> package pb; // 生成go文件的包名为pb
> option go_package ="./pb";    // 生成代码文件rpckj.pb.go在pb中
> 
> // grpc利用protobuf协议生成源码 增加service语法
> // 自动生成对应其他语言的服务器端和客户端的存根
> service Hello{
>  rpc Hello(HelloRequest) returns (Response);
> }
> 
> message HelloRequest {
>  string name = 1; // 1是编号不是值
>  int32 age = 2;
>  repeated string Courses = 3;
> }
> 
> message Response{
>  string reply = 1;
> }
> ```
>
> 打开该目录，执行 `protoc -I . rpckj.proto --go_out=plugins=grpc:.`
>
> . 当前目录下，goland插件机制解析service，`=plugins=grpc:.` 
>
> 此时在当前目录的pb下会生成一个rpckj.pb.go文件，我们的Go语言代码里就是使用这个文件。 
>
> main中测试序列化效果
>
> ```go
> package main
> 
> import (
> 	"encoding/json"
> 	"fmt"
> 	"github.com/golang/protobuf/proto"
> 	"rpckj/proto/pb"
> )
> type Hello struct {
> 	Name string `json:"name"`
> 	Age int32 `json:"age"`
> 	Courses []string `json:"course"`
> }
> 
> func main()  {
> 	req := pb.HelloRequest{
> 		Name: "zxy",
> 		Age: 24,
> 		Courses: []string{"go","gin","微服务"},
> 	}
> 	// json 可以直观的看到压缩比
> 	jsonStruct := Hello{
> 		Name: "zxy",
> 		Age: 24,
> 		Courses: []string{"go","gin","微服务"},
> 	}
> 	jsonrsp , _ := json.Marshal(jsonStruct)
> 	fmt.Println(string(jsonrsp),len(jsonrsp))
> 	// {"name":"zxy","age":24,"course":["go","gin","微服务"]} 57
> 	// protbuf
> 	rsp ,_ := proto.Marshal(&req) // 具体如何编码可以自己百度原理
> 	fmt.Println(string(rsp),len(rsp))
> 	// zxygogin	微服务 27
> 	newReq := pb.HelloRequest{}
> 	proto.Unmarshal(rsp,&newReq)
> 	fmt.Println(newReq.Name,newReq.Age,newReq.Courses)
> }
> ```
>
> **rpc的四种模式**
>
> > 1简单模式：客户端发起一次请求，服务器响应一个数据。
> >
> > 2客户端流模式：即从客户端往服务器端发送数据使用的是流，即服务器端的参数为流类型，然而在发送结束后，服务器返还数据给客户端一个响应。例如物联网终端项服务器报送数据。
> >
> > 3服务器端流模式：客户端发起一次请求，服务端返回一段连续的数据流，比如客户端发送一个股票代码，服务器端将其实时数据不断的返回给客户端。
> >
> > 4双向模式：客户端和服务器端都可以向对方发送数据流，这个时候双方的数据可以同时互相发送，也可以实时交互。典型的例子是聊天机器人。
>
> **proto的默认值：**
>
> > strings：空string
> >
> > bytes：空[]byte
> >
> > bools ：false
> >
> > 数值类型：0值
> >
> > 枚举类型：默认是第一个定义的枚举值，且必须为0
>
> **option go_package ="./pb"; 的作用** 表示在当前文件夹下生成一个新的文件夹pb并将生成的go文件package名表示为pb。../表示父目录。
>
> proto中的编号1 2表示字段名 编号时会利用这种方式13zxy2224....表示1编号的值有3个字符zxy，2编号的值有2个字符24，...不传递字段名节省编码效率。所以客户端服务器的字段名编号是不可以搞反的。
>
> 在一个proto文件中如何import另一个proto文件中定义的message。
>
> **grpc的metadata**
>
> 每次rpc调用中，都可能有一些有用的数据，这些数据就可以通过metadata传递，metadata以key-value形式传递数据。key是string，value是[]string类型。metadata使client和server能够为对方提供关于本次调用的一些信息(类似token等)，相当于http协议里的header信息。http header的生命周期是一次http请求，metadata的声明周期是一次RPC调用。
>
> **grpc拦截器**
>
> 对请求拦截做统一处理，例如验证是否合法
>
> 通过拦截器和metadata实现auth功能。
>
> **GRPC 的验证器**
>
> https://github.com/envoyproxy/protoc-gen-validate
>
> windows下安装
>
> `go install github.com/envoyproxy/protoc-gen-validate@latest`
>
> 编写代码后
>
> `protoc --validate_out="lang=go:." rpckj.proto`
>
> **GRPC中异常处理**
>
> 错误码详解
>
> https://github.com/grpc/grpc/blob/master/doc/statuscodes.md
>
> 在实际开发中，很多时候我们会自己定义状态码
>
> **GRPC超时重传机制**
>
> `context`
>
> **proto文件生成go文件源码中message变为结构体**

**微服务开发电商** 服务注册和发现 分布式配置中心 链路追踪 熔断系统

> 启动服务，进入目录，运行` cnpm install` `cnpm run dev` 端口号找config目录修改
>
> **需求分析：**
>
> **后台管理系统：**
>
> 商品列表、商品分类、品牌管理、品牌分类、订单列表、用户信息管理、用户列表、用户地址、用户留言、首页轮播图管理。对其进行修改删除添加查看等。
>
> **电商系统：**
>
> 首页展示、商品搜索、商品排序、详细信息、加入购物车、结算价格展示、增删改个人信息、订单信息、购买信息、支付页面、对系统留言信息、投诉信息、登录注册等。
>
> **系统架构设计**
>
> 单体应用部署：
>
> 将本地项目上传在云服务器中，生产环境中不会使用django等web框架直接部署，而是使用wsgi 等web服务器部署。浏览器请求云服务器项目需要使用nginx进行转发。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_17-53-27.png)
>
> 单体应用逐步扩大时面临的问题：
>
> 主仓库代码是随时可以用于生产服务器部署的代码，任何修改都需要进行分支。完成后先拉取最新分支，并发布到测试服务器中。最后再拉取最新分支，合并分支到主分支。若最后又发现了新分支，所以需要继续进行测试-回归测试，继续拉取合并。系统越大，这个问题越突出。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-15-07.png)
>
> 换语言 换版本 在小系统中随便就换了，但是大系统中会面临很大问题，你不知道会在哪里出现问题。
>
> 单体应用架构演变-微服务：
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-20-41.png)
>
> 功能增多 并发增加  例如增加一个小程序
>
> 代码复用问题、系统间相互调用(秒杀下单需要查询商品)问题、接口不仅需要对外提供服务，也需要对内提供服务，但是对内对外服务的参数可能不一样、数据分析导致数据库性能问题，影响业务、数据库被多个服务依赖，无法升级和拆分、开发测试部署困难。
>
> 对某个部件的升级需要对所有功能测试后实施。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-33-22.png)
>
> 单体应用代码重复问题：
>
> 前后端分离，此时三个系统就是前端客户端，后端系统访问共有的服务，独立部署 但是数据库性能还是会影响，表结构变化需要谨慎。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-37-11.png)
>
> 对数据库服务进行改进，使得每个服务都有自己独立的数据库mysql redis。会添加多余的接口。但是会有很好的隔离性
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-42-08.png)
>
> 内部系统间通过http请求，效率较低。因为是一个纯文本协议。希望内部通过rpc像调用本地函数一样调用。最下面是service服务，上面是整合出来的web服务，服务之间语言不限。组件不限。可以分别部署。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-49-01.png)
>
> 微服务中需要解决的问题：
>
> 服务过多，微服务间调用问题 必须知道ip+端口，并且需要知道服务健康问题
>
> 注册中心：服务开发完注册到中心，中心定时检测是否健康
>
> 服务发现：web向服务发现查询某个微服务的ip和端口
>
> 配置中心：超时时间、改token，服务每次都直接在配置中心获取，不需要重新启动
>
> 链路追踪：解决整个服务出现性能问题，A调用B B调用C ... 将调用的时间记录下来，分析每部分的性能
>
> 

**系统可靠性保障** 熔断限流 api网关的部署

> 最后利用nginx作为服务网关：提供路由服务、服务发现、鉴权、熔断(多次访问无结果，再次来请求直接熔断)、ip黑白名单、负载均衡
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_20-11-34.png)
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_20-14-26.png)

**前后端分离开发中接口管理的痛点**

> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_20-57-29.png)
>
> 对数据的解释通过文档说明，所以文档变得更加重要。
>
> yapi写好接口可以实现自动mock数据给前端使用，也可以生成http请求并验证返回数据是否合法。yapi可以根据接口自动生成一个测试集。
>
> YApi 是高效、易用、功能强大的 api 管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务。可以帮助开发者轻松创建、发布、维护  API，YApi 还为用户提供了优秀的交互体验，开发人员只需利用平台提供的接口数据写入工具以及简单的点击操作就可以实现接口的管理。
>
> 安装
>
> ```
> 拉镜像
> docker pull registry.cn-hangzhou.aliyuncs.com/anoy/yapi
> 
> 创建挂载目录
> mkdir -p /data/yapi/mongodata
> 
> 运行专用mongo
> docker run --restart always -v /data/yapi/mongodata:/data/db -d --name yapimongo mongo
> 
> 运行容器初始化
> docker run -it --rm --link yapimongo:mongo --entrypoint npm --workdir /api/vendors registry.cn-hangzhou.aliyuncs.com/anoy/yapi run install-server
> 
> 初始化管理员账号成功,账号名："admin@admin.com"，密码："ymfe.org"
> 
> 运行服务
> docker run -d  --restart=always --name yapi  --link yapimongo:mongo --workdir /api/vendors  -p 3001:3000  registry.cn-hangzhou.aliyuncs.com/anoy/yapi  server/app.js
> 
> chrom访问
> http://192.168.220.128:3001 登录
> 
> 可以创建项目、分类和分类下的接口，接口创建完成后的mock地址是给前端用的，运行时需要先安装插件。编辑中可以设置请求参数，mock部分如果没有写死，可以自动生成。因为前后端分离系统，所以数据为json类型，但是json无法具有表述性，例如数据字段类型。所以可以在项目中开启JSON-SCHEMA，mock严格模式、开启json5。可以在运行里的body里查看数据内容。也可以使用高级设置进一步设置。可以在url中设置运行环境、header、cookie等参数。全部完成后会在预览中自动向前端生成mock地址。用于前端测试。
> 
> 最后可以使用测试集合，导入接口。开始测试后，会生成测试报告。多个接口一键测试完成。数据管理中的数据导入导出，可以导入导出接口数据文档。
> 
> 点击下面的链接下载最新版插件，并且解压：https://cdn.jsdelivr.net/npm/yapi-x-chrome-extension/archive.zip
> 复制下面的链接在地址栏打开 Chrome 的扩展程序：chrome://extensions，然后，打开开发者模式：最后，点击加载已解压的扩展程序，导入插件即可
> ```
>

**微服务之用户：**

用户的登录注册以及后台管理系统中查看所有用户。

`create database shop_user_srv;`

用户密码需要哈希MD5后保存在数据库中，因为密文需要不可反解的特性，所以用户找回密码需要直接进行修改。

> **MD5算法：**
>
> 压缩性：任意长度数据计算出的MD5值长度固定
>
> 容易计算：从原始数据计算出MD5值很容易
>
> 抗修改性：对原始数据修改一点，MD5值差异很大
>
> 抗强碰撞：很难找到两个不同数据，使他们具有相同MD5值
>
> 不可逆：不可反解

> **MD5加盐值**
>
> 随机数和字符串进行组合生成MD5，数据库同时存储MD5值和随机数值，验证正确性直接使用salt和MD5值即可。
>
> "123456" Md5后的值为 e10adc3949ba59abbe56e057f20f883e，但是这个是可以被暴力破解的，因为有些网站会提前计算一些常见字符串的哈希值存入表中，查看哈希后的数值有无匹配。若是用户确实设置了简单的常用的密码，就很容易被破解，所以我们可以通过加盐来避免这种攻击。也可以对两个相同密码产生不同的哈希值。

**日志**

日志分级别：debug、info、warn、err、fetal从低到高。生产配置的日志级别高，开发环境配置的日志级别低。

**go的配置文件管理-viper**

> viper是一个配置管理的解决方案，它能够从 json，toml，ini，yaml，hcl，env 等多种格式文件中，读取配置内容，还能从一些远程配置中心读取配置文件，如consul，etcd等；还能够监听文件的内容变化。 

**Session机制在微服务下的问题**

> 用户通过浏览器登录，服务器向数据库查询用户，数据库返回后，服务器生成一条sessionid存入数据库，并将sessionid设置到cookie中返回给浏览器。此后浏览器每次请求带上sessionid，一般将token放在headers中。服务器组件通过sessionid查询数据库查询用户。
>
> 但是如果引用到微服务，因为微服务的数据库是相互隔离的，所以服务器无法验证。
>
> 有一种方式，使用公共的数据库存储session，需要部署集群保证高并发。
>
> 第二种方式，jwt。使用加密的方式实现认证。
>
> **JWT本质上是一种协议**
>
> 一个典型的jwt由三部分组成：
>
> header：tocken类型 和 加密或哈希算法名称
>
> Payload：自己想放的内容，不要放敏感信息
>
> Signature：对上述两部分用服务器自己密钥的加密 或带密钥哈希

**CORB(Cross-Origin Read Blocking)**

> 前后端分离的项目-拨号连接grpc服务器，容易出现跨域的问题
>
> 浏览器在加载可以跨域资源时，在将资源载入页面时对其进行识别与拦截等一系列处理。
>
> X-Content-Type-Options(:nosniff)
> 相当于一个提示标志，被服务器用来提示客户端须遵循在Content-Type首部中对MIME类型的设定，不能对其进行修改。从而禁用了客户端（浏览器）的MIME类型嗅探行为（即把不可执行的MIME类型转变为可执行的MIME类型）。
> 指定值为nosniff时，会拒绝以下两种请求：
> 请求类型：style，MIME类型不是“text/css”
> 请求类型：script，MIME类型不是“Javascript类型”。Javascript类型有text/javascript、application/javascript、application/x-javascript等
>
> 所以当服务端出现response.addHeader("X-Content-Type-Options", "nosniff")安全响应头，且未指定Content-Type为Javascript类型时
> jsonp请求跨域资源时会出现如上CORB或拒绝解析的问题。



**服务注册和发现**

**服务注册**，就是将提供某个服务的模块信息(通常是这个服务的ip和端口)注册到一个公共的组件上去（比如: zookeeper\consul）。

**服务发现**，就是新注册的这个服务模块能够及时的被其他调用者发现。不管是服务新增和服务删减都能实现自动发现。

微服务时代，我们所有的服务都被尽量拆分成最小的粒度，原先所有的服务都在混在一个server里，现在就被按照功能或者对象拆分成N个服务模块，这样做的好处是深度解耦，一个模块只负责自己的事情就好，能够实现快速的迭代更新。坏处就是服务的管理和控制变得异常的复杂和繁琐，人工维护难度变大。还有排查问题和性能变差（服务调用时的网络开销）。 各个微服务相互独立，每个微服务，由多台机器或者单机器不同的实例组成，各个微服务之间错综复杂的相互关联调用。 

在不用服务注册之前，我们可以想象一下，怎么去维护这种复制的关系网络呢？答案就是：**写死！**。将其他模块的ip和端口写死在自己的配置文件里，甚至写死在代码里，每次要去新增或者移除1个服务的实例的时候，就得去通知其他所有相关联的服务去修改。随之而来的就是各个项目的配置文件的反复更新、每隔一段时间大规模的ip修改和机器裁撤，非常的痛苦。在微服务时代，我们会上云，会用k8s，会有docker，这样一个服务从创建到上线会变得异常的频繁，每一个接口依赖的服务，可能会随时的动态改变，靠人手的去写配置和变更配置，对于运维和开发同学来说简直就是灾难。

每一个服务对应的机器或者实例在启动运行的时候，都去向名字服务集群注册自己。每个服务的机器实例在启动后，就完成了注册的操作。注册的方式有很多的形式，不同的名字服务软件方式不一样，有HTTP接口形式，有RPC的方式，也有使用JSON格式的配置表的形式的。方式虽然不同，但是结果都是一样。实例注册到名字服务上之后，接下来就是服务发现了。 想要获取某个服务相关的信息，首先向注册集群中心发送请求获取，然后就能收到服务相关的信息。有些注册服务软件也提供了DNS解析功能或者负载均衡功能，它会直接返回给你一个可用的ip，你直接调用就可以了，不用自己去做选择。  服务注册和服务发现，不仅仅解决了服务调用这种写死IP以及杂乱无章的管理的状态，更重要的一点是它还管理了服务器的存活状态，也就是**健康检查**。  当这个服务组的某台机器，如果出现宕机或者服务死掉的时候，就会标记这个实例的状态为故障，或者干脆剔除掉这台机器。这样一来，就实现了自动监控和管理。  健康检查有多重实现方式，比如有几秒就发一次健康检查心跳，如果返回的HTTP状态不是200，那么就判断这台服务不可用，对它进行标记。也可以执行一个shell脚本，看执行的返回结果，来标记状态等等。 

zk、consul和etcd都可以作为注册中心。

**consul安装**

`docker run -d -p 8500:8500 -p 8300:8300 -p 8301:8301 -p 8302:8302 -p 8600:8600/udp consul consul agent -dev -client=0.0.0.0`

http://192.168.220.128:8500简单的管理界面

访问DNS查看服务 `dig @192.168.220.128 -p 8600 consul.service.consul SRV`

**服务注册**

PUT http://192.168.220.128:8500/v1/agent/service/register

header 中 Content-Type application/json

body中row json

```json
{
    "Name":"shop-web",
    "ID":"shop-web",
    "Tags":["shop","zxy","web"],
    "Address":"127.0.0.1",
    "Port":50051
}
```

发现服务未启动，健康检查依然能够通过，是因为body中未配置check

所以先注销服务+ID

PUT http://192.168.220.128:8500/v1/agent/service/deregister/shop-web



**负载均衡**

> Load balancing，即负载均衡，是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源之间分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间的目的。同时避免过载。
>
> **1.为什么需要负载均衡** 
>
> 我们在日常生活中经常免不了要去一些比较拥挤的地方，比如地铁站、火车站、电影院、银行等。无论是买票，还是排队入场，这些场所一般都会设置多个服务点或者入口。如果没有人引导的话，大多数情况下，最近的入口会挤满人。而距离较远的服务点或者入口就宽松很多。这种情况下，就会大大浪费资源，因为如果可以把这些排队的人很好的分散到各个入口的话会大大缩短排队时间。其实，网站的建设也是一样的。为了提升网站的服务能力，很多网站采用集群部署，就像话剧院有多个入口一样。这时候，就需要一个协调者，来均衡的分配这些用户的请求，可以让用户的可以均匀的分派到不同的服务器上。
>
> 考虑微服务之间的负载均衡
>
> **2.负载均衡的策略**
>
> > **集中式load balance**
> >
> > LB上有所有服务的地址映射表，消费方调用某个目标服务，向LB发起请求，LB以某种策略做负载均衡后将请求转发到目标服务。但是这样LB流量过大，容易造成性能瓶颈。
> >
> > **进程内load balance-主流**
> >
> > 微服务向consul中注册ip和端口，web层的服务启动协程定时通过name拉取ip和端口，保存服务列表在本地进程内，浏览器发送请求后web服务通过负载均衡算法拿到连接调用。这样的话每个语言都要实现一套算法。
> >
> > **独立进程load balance**
> >
> > LB是单独的进程，不需要为不同的语言开发客户库。LB的升级不需要调用方改代码。
>
> **3.负载均衡的算法**
>
> > 1、**轮询（Round Robin）法**
> > 轮询很容易实现，将请求按顺序轮流分配到后台服务器上，均衡的对待每一台服务器，而不关心服务器实际的连接数和当前的系统负载。使用轮询策略的目的是，希望做到请求转移的绝对均衡，但付出的代价性能也是相当大的。为了保证pos变量的并发互斥，引入了重量级悲观锁synchronized，将会导致该轮询代码的并发吞吐量明显下降。
> > 轮询法适用于机器性能相同的服务，一旦某台机器性能不好，极有可能产生木桶效应，性能差的机器扛不住更多的流量。
> >
> > **2、随机法**
> > 通过系统随机函数，根据后台服务器列表的大小值来随机选取其中一台进行访问。由概率概率统计理论可以得知，随着调用量的增大，其实际效果越来越接近于平均分配流量到后台的每一台服务器，也就是轮询法的效果。
> > 同样地，它也不适用于机器性能有差异的分布式系统。
> >
> > **3、随机轮询法**
> > 所谓随机轮询，就是将随机法和轮询法结合起来，在轮询节点时，随机选择一个节点作为开始位置index，此后每次选择下一个节点来处理请求，即（index+1）%size。
> > 这种方式只是在选择第一个节点用了随机方法，其他与轮询法无异，缺点跟轮询一样。
> >
> > **4、源地址哈希法**
> > 源地址哈希法的思想是根据服务消费者请求客户端的IP地址，通过哈希函数计算得到一个哈希值，将此哈希值和服务器列表的大小进行取模运算，得到的结果便是要访问的服务器地址的序号。采用源地址哈希法进行负载均衡，相同的IP客户端，如果服务器列表不变，将映射到同一个后台服务器进行访问。
> >
> > 该方法适合访问缓存系统，如果为了增强缓存的命中率和单调性，可以用一致性哈希算法。 在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。 https://baike.baidu.com/item/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/2460889?fr=aladdin
> >
> > **5、加权轮询（Weight Round Robin）法**
> > 不同的后台服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不一样。跟配置高、负载低的机器分配更高的权重，使其能处理更多的请求，而配置低、负载高的机器，则给其分配较低的权重，降低其系统负载，加权轮询很好的处理了这一问题，并将请求按照顺序且根据权重分配给后端。Nginx的负载均衡默认算法是加权轮询算法。
> >
> > **6、最小连接法**
> >
> > 连接已有的连接数最少的服务器。



**为什么需要分布式配置中心**

> 对于单机版，我们称之为配置文件；对于分布式集群系统，我们称之为配置中心;我们现在有一个项目，使用GIN进行开发的，配置文件的话我们知道是一个叫做config.yaml的文件。配置文件在项目启动时会被加载到内存中使用。
>
> **需求一**
>
> 由于业务的变动，添加配置项和修改配置项都需要在多个微服务中进行，并且完成后需要进行重启！即使go的viper能完成修改配置文件自动生效，但是其他语言未知。
>
> **需求二**
>
> 我们在进行业务开发的时候，一般会有多个环境，至少应该有三个：开发、测试、线上。那这三个环境之间的配置文件肯定是有不同的，比如说他们之间的数据库是肯定不同的！多服务之间如何隔离。
>
> **什么是分布式配置中心**
>
> 从上边的两个小需求，我们已经可以看出来，传统配置的方式已经暴露出了很多问题，其他的诸如：历史版本管理，权限控制，安全性等等问题，是传统的配置文件无法解决的！
>
> 随着业务的发展、微服务架构的升级，服务的数量、程序的配置日益增多（各种微服务、各种服务器地址、各种参数），传统的配置文件方式和数据库的方式已无法满足开发人员对配置管理的要求：
>
> - 安全性：配置跟随源代码保存在代码库中，容易造成配置泄漏；
> - 时效性：修改配置，需要重启服务才能生效；
> - 局限性：无法支持动态调整：例如日志开关、功能开关；
>
> 因此，我们需要配置中心来统一管理配置！把业务开发者从复杂以及繁琐的配置中解脱出来，只需专注于业务代码本身，从而能够显著提升开发以及运维效率。同时将配置和发布包解藕也进一步提升发布的成功率，并为运维的细力度管控、应急处理等提供强有力的支持。

**配置中心选型**

apollo携程(大而全) VS nacos阿里(简单) 可以理解为django和flask的区别。nacos不止支持配置中心，而且支持服务注册和发现。nacos官方支持各种语言。选择第三方支持的丰富程度高的nacos。

文档：https://nacos.io/zh-cn/docs/quick-start.html

安装

`docker run --name nacos-standalone -e MODE=standalone -e JVM_XMS=512m -e JVM_XMX=512m -e JVM_XMN=256m -p 8848:8848 -d nacos/nacos-server:latest`

访问 http://192.168.220.128:8848/nacos 用户名密码都是nacos

里面的命名空间是为了解决冲突，隔离配置集。需要记住ID。命名空间一般用来区分微服务。

但是开发、测试、线上环境可以用组区别。dev、pro、test等

对nacos SDK的要求：1.获取已经注册好的配置 2.对变化的配置自动监听并拉取。

`go get -u "github.com/nacos-group/nacos-sdk-go"`

在线网站中https://oktools.net/json2yaml，将yaml转为json配置到nacos中

后面好改为struct。

