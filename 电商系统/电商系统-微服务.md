**开发环境**

![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-10_09-54-00.png)

**git bash配置**

```bash
Administrator@PC-202003301339 MINGW64 ~
$ git config --global user.name "zxy1013"

Administrator@PC-202003301339 MINGW64 ~
$ git config --global user.email "1253141170@qq.com"

Administrator@PC-202003301339 MINGW64 ~
$ git config --global --list
```

**安装docker-compose**

```bash
sudo curl -L "https://get.daocloud.io/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

chmod +x /usr/local/bin/docker-compose

docker-compose -version
docker-compose
```

goland打开tools打开file watch中的 gofmt和goimports`go get golang.org/x/tools/cmd/goimports`，作用是做自动格式化。

项目前端基于vue所以需要搭建nodejs环境。安装完成后`node -v`  `npm -v`并配置cnpm镜像， 使用定制的cnpm (gzip 压缩支持) 命令行工具代替默认的npm，`npm install -g cnpm --registry=https://registry.npmmirror.com`   `cnpm -v`



**go的package包管理以及go的编码规范**

go传统模式下，项目必须新建在go path下的src目录下，且设置`GO111MODULE=off`，此时import的东西会先在gopath的src目录下找，后在goroot下的src目录下找。

go modules模式下设置`GO111MODULE=on`，可以在任意位置新建项目，需要`go mod init`，能用go modules就用go modules。

**Go语言编码规范**

> 代码规范不是强制性的，不遵循规范写出来的代码运行也是没有问题的。目的是为了方便团队形成一个统一的代码风格。提高代码的可读性、规范性和统一性。规范并不是唯一的，理论上每个公司都可以制定自己的规范。
>
> 必须使用Gofmt做代码格式化和自动优化。如果使用Goland IDE开发可以选择goimports, goimports包含了Gofmt的功能同时还支持自动添加和删除package导入功能Goland -> Preferences -> File Watchers -> 添加goimports
>
> 在引包的时候，需要注意**不要使用相对路径**，而应该使用绝对路径。但是如果引入本项目的其他包，可以使用相对路径。如果引入了三种类型的包，标准库包，程序内部包，第三方包，建议采用如下方式进行组织包。
>
>         package main
>         import (
>             "encoding/json"
>             "strings"
>             
>             "myproject/models"
>             "myproject/controller"
>             "myproject/utils"
>        
>             "github.com/astaxie/beego"
>             "github.com/go-sql-driver/mysql"
>          )
>  **命名规范**
>
> 包名、文件名、结构体名、接口命名、变量命名、常量命名
>
> 包的名字应该和目录保持一致，采取有意义的包名，并且不能和标准库冲突，包名应该为小写字母开头，不要使用下划线或或者大小写。
>
> 文件名应该为小写字母开头，使用下划线分割各个单词(蛇形命名)。
>
> 结构体名采用驼峰命名法，首字母根据访问控制大写或小写，声明和初始化格式采用多行。
>
> 接口命名单个变量的结构名以“er“作为后缀。
>
> 变量命名遵循驼峰命名法，首字母根据访问控制大写或小写，专有名词全部大写或小写APIClient UserID或apiClient userID表示包外可或不可访问。若变量类型为bool类型，名称应该以Has is Can Allow开头。
>
> 常量命名均需使用全部大写字母组成，并使用下划线分词。若是枚举的常量，需要先创建相应类型。
>
> ```go
> type Scheme string
> const(
> 	HTTP Scheme = "http"
>        HTTPS Scheme = "https"
> )
> ```
>
> **注释规范**
>
> `/**/` 一般用于包的文档注释或注释成块的代码片段。
>
> 每个包都需要有一个包注释，在一个文件中即可，在package语句之前需要有一个块注释。包含包的基本简介、创建人: xxx、创建时间: yyymmdd。
>
> 函数注释，函数名, 简要说明、参数列表, 说明、返回值, 说明。
>
> 中文和英文之间英文和中文标点之间都需要使用空格。
>
> `//` 在任何地方都可以声明，单行注释不能太长，禁止超过120字符。
>
> **代码风格**
>
> 错误处理的原则就是不能丢弃任何有返回err的调用，不要采用`_`丢弃，必须全部处理。接收到错误，要么返回err，要么实在不行就panic，或者使用log记录下来 ， error的信息不要采用大写字母，尽量保持你的错误简短，但是要足够表达你的错误的意思。 尽早return，一旦有错误，马上返回。尽量不要使用panic，只有当实在不可运行的情况采用panic，例如文件无法打开，数据库无法连接导致程序无法正常运行。强烈建议在main包中使用log.Fatal来记录错误，这样就可以由log来结束程序。

**rpc**  processon画图工具

> - RPC（Remote Procedure Call）远程过程调用，简单的理解是一个节点请求另一个节点提供的服务
> - 本地过程调用：如果需要将本地student对象的age+1，可以实现一个addAge()方法，将student对象传入，对年龄进行更新之后返回即可，本地方法调用的函数体通过函数指针来指定。
> - 远程过程调用：上述操作的过程中，如果addAge()这个方法在服务端，执行函数的函数体在远程机器上，如何告诉机器需要调用这个方法呢？
>
> > 1. 首先客户端需要告诉服务器，需要调用的函数ID。传指针是不行的，因为两个地址空间是完全不一样的。在RPC中，函数和进程ID存在一一映射关系。客户端和服务端需要分别维护一个{函数 **Call-ID**}的对应表，两者不需要完全相同，但是对应关系需要一样。客户端做远程调用时，需要查一下函数对应的ID，然后附上这个ID，执行函数的代码。服务器端也通过查表，来确定客户端需要调用的函数，执行相应函数的代码。
> > 2. 客户端需要把本地参数传给远程函数，本地调用的过程中，直接压栈即可，但是在远程调用过程中不再同一个内存里，无法直接传递函数的参数，甚至有时候客户端服务器使用的都不是同一种语言。因此需要客户端把参数转换成字节流，传给服务端，然后服务端将字节流转换成自身能读取的格式，是一个序列化和反序列化的过程。同理，从服务器端返回的值也需要**序列化和反序列化**的过程。
> > 3. **网络传输**。数据准备好了之后，如何进行传输？远程调用往往用在网络上。客户端服务器通过网络连接，所有数据需要网络传输。因此需要一个网络传输层，网络传输层需要把调用的ID和序列化后的参数传给服务端，然后把计算好的结果序列化传给客户端，因此使用的协议不限，只要能完成传输就行，TCP 以及基于其的http协议即可完成上述过程，gRPC中采用的是HTTP2.0协议。因为http协议是一次性的，一旦对方返回结果，连接断开，性能要求高时比较麻烦。
>
> **eg**
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-11_10-56-49.png)
>
> rpc中第一个点是选择序列化和反序列化的**数据编码**协议，若是成功实现，客户端服务器使用是否是同一种语言不再重要，只要能实现对等的序列化反序列化即可。
>
> 第二点是选择**网络传输**协议，基于tcp封装或是直接使用http
>
> **rpc开发要素分析**
>
> 一个基本RPC框架由4部分组成，分别是：客户端、客户端存根、服务端、服务端存根。
>
> **客户端**（Client）：服务调用的发起方，也称为消费者。
>
> **客户端存根**（ClientStub）：
>
> 该程序运行在客户端所在的计算机上，主要用来存储要调用服务器的地址，对客户端发送的数据进行序列化、建立网络连接之后发送数据包给Server端的存根程序。
>
> 接收Server端存根程序响应的消息，对消息进行反序列化。
>
> **服务端**（Server）:提供客户端想要调用的函数
>
> **服务端存根**（ServerStub）:
>
> 接收客户端的消息并反序列化，对server端响应的消息进行序列化并响应给Client端
>
> 总体来讲客户端和服务端的Stub在底层帮助我们实现了Call ID的映射、数据的序列化和反序列化、网络传输，这样RPC客户端和RPC服务端 只需要专注于服务端和客户端的业务逻辑层即可。
>
> **动态代理技术** ServerStub和ClientStub程序，在具体编码和开发实践中，都是使用动态代理技术自动生成的一段程序。
>
> go语言的rpc的序列化和反序列化协议是gob协议，可以替换为json

**grpc**

> gRPC是一种现代化开源的高性能RPC框架，能够运行于任意环境之中。最初由谷歌进行开发。它使用HTTP/2作为传输协议。
>
> **protobuf**
>
> grpc的数据编解码使用protobuf， Protobuf是Protocol Buffer的简称，它是Google公司于2008年开源的一种高效的平台无关、语言无关、可扩展的数据格式，目前Protobuf作为接口规范的描述语言，可以作为Go语言RPC接口的基础工具。其压缩效率高，压缩比大，传输速度快。 
>
> protobuf协议编译器是用c++编写的，根据自己的操作系统下载对应版本的protoc编译器：https://github.com/protocolbuffers/protobuf/releases，解压后拷贝路径到系统路径下。`C:\Users\Administrator\Downloads\protoc-3.19.4-win64\bin`
>
> protoc-gen-go，安装生成Go语言代码的工具
>
> ```bash
> go get -u github.com/golang/protobuf/protoc-gen-go
> ```
>
> protobuf是一个与语言无关的一个数据协议，所以我们需要先编写IDL文件然后借助专用工具生成指定语言的代码，从而实现数据的序列化与反序列化过程 
>
> 新建文件rpckj.proto
>
> ```protobuf
> // 指定使用protobuf版本
> // 此处使用v3版本
> syntax = "proto3";
> package pb; // 生成go文件的包名为pb
> option go_package ="./pb";    // 生成代码文件rpckj.pb.go在pb中
> 
> // grpc利用protobuf协议生成源码 增加service语法
> // 自动生成对应其他语言的服务器端和客户端的存根
> service Hello{
>  rpc Hello(HelloRequest) returns (Response);
> }
> 
> message HelloRequest {
>  string name = 1; // 1是编号不是值
>  int32 age = 2;
>  repeated string Courses = 3;
> }
> 
> message Response{
>  string reply = 1;
> }
> ```
>
> 打开该目录，执行 `protoc -I . rpckj.proto --go_out=plugins=grpc:.`
>
> . 当前目录下，goland插件机制解析service，`=plugins=grpc:.` 
>
> 此时在当前目录的pb下会生成一个rpckj.pb.go文件，我们的Go语言代码里就是使用这个文件。 
>
> main中测试序列化效果
>
> ```go
> package main
> 
> import (
> 	"encoding/json"
> 	"fmt"
> 	"github.com/golang/protobuf/proto"
> 	"rpckj/proto/pb"
> )
> type Hello struct {
> 	Name string `json:"name"`
> 	Age int32 `json:"age"`
> 	Courses []string `json:"course"`
> }
> 
> func main()  {
> 	req := pb.HelloRequest{
> 		Name: "zxy",
> 		Age: 24,
> 		Courses: []string{"go","gin","微服务"},
> 	}
> 	// json 可以直观的看到压缩比
> 	jsonStruct := Hello{
> 		Name: "zxy",
> 		Age: 24,
> 		Courses: []string{"go","gin","微服务"},
> 	}
> 	jsonrsp , _ := json.Marshal(jsonStruct)
> 	fmt.Println(string(jsonrsp),len(jsonrsp))
> 	// {"name":"zxy","age":24,"course":["go","gin","微服务"]} 57
> 	// protbuf
> 	rsp ,_ := proto.Marshal(&req) // 具体如何编码可以自己百度原理
> 	fmt.Println(string(rsp),len(rsp))
> 	// zxygogin	微服务 27
> 	newReq := pb.HelloRequest{}
> 	proto.Unmarshal(rsp,&newReq)
> 	fmt.Println(newReq.Name,newReq.Age,newReq.Courses)
> }
> ```
>
> **rpc的四种模式**
>
> > 1简单模式：客户端发起一次请求，服务器响应一个数据。
> >
> > 2客户端流模式：即从客户端往服务器端发送数据使用的是流，即服务器端的参数为流类型，然而在发送结束后，服务器返还数据给客户端一个响应。例如物联网终端项服务器报送数据。
> >
> > 3服务器端流模式：客户端发起一次请求，服务端返回一段连续的数据流，比如客户端发送一个股票代码，服务器端将其实时数据不断的返回给客户端。
> >
> > 4双向模式：客户端和服务器端都可以向对方发送数据流，这个时候双方的数据可以同时互相发送，也可以实时交互。典型的例子是聊天机器人。
>
> **proto的默认值：**
>
> > strings：空string
> >
> > bytes：空[]byte
> >
> > bools ：false
> >
> > 数值类型：0值
> >
> > 枚举类型：默认是第一个定义的枚举值，且必须为0
>
> **option go_package ="./pb"; 的作用** 表示在当前文件夹下生成一个新的文件夹pb并将生成的go文件package名表示为pb。../表示父目录。
>
> proto中的编号1 2表示字段名 编号时会利用这种方式13zxy2224....表示1编号的值有3个字符zxy，2编号的值有2个字符24，...不传递字段名节省编码效率。所以客户端服务器的字段名编号是不可以搞反的。
>
> 在一个proto文件中如何import另一个proto文件中定义的message。
>
> **grpc的metadata**
>
> 每次rpc调用中，都可能有一些有用的数据，这些数据就可以通过metadata传递，metadata以key-value形式传递数据。key是string，value是[]string类型。metadata使client和server能够为对方提供关于本次调用的一些信息(类似token等)，相当于http协议里的header信息。http header的生命周期是一次http请求，metadata的声明周期是一次RPC调用。
>
> **grpc拦截器**
>
> 对请求拦截做统一处理，例如验证是否合法
>
> 通过拦截器和metadata实现auth功能。
>
> **GRPC 的验证器**
>
> https://github.com/envoyproxy/protoc-gen-validate
>
> windows下安装
>
> `go install github.com/envoyproxy/protoc-gen-validate@latest`
>
> 编写代码后
>
> `protoc --validate_out="lang=go:." rpckj.proto`
>
> **GRPC中异常处理**
>
> 错误码详解
>
> https://github.com/grpc/grpc/blob/master/doc/statuscodes.md
>
> 在实际开发中，很多时候我们会自己定义状态码
>
> **GRPC超时重传机制**
>
> `context`
>
> **proto文件生成go文件源码中message变为结构体**

**微服务开发电商** 服务注册和发现 分布式配置中心 链路追踪 熔断系统

> 启动服务，进入目录，运行` cnpm install` `cnpm run dev` 端口号找config目录修改
>
> **需求分析：**
>
> **后台管理系统：**
>
> 商品列表、商品分类、品牌管理、品牌分类、订单列表、用户信息管理、用户列表、用户地址、用户留言、首页轮播图管理。对其进行修改删除添加查看等。
>
> **电商系统：**
>
> 首页展示、商品搜索、商品排序、详细信息、加入购物车、结算价格展示、增删改个人信息、订单信息、购买信息、支付页面、对系统留言信息、投诉信息、登录注册等。
>
> **系统架构设计**
>
> 单体应用部署：
>
> 将本地项目上传在云服务器中，生产环境中不会使用django等web框架直接部署，而是使用wsgi 等web服务器部署。浏览器请求云服务器项目需要使用nginx进行转发。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_17-53-27.png)
>
> 单体应用逐步扩大时面临的问题：
>
> 主仓库代码是随时可以用于生产服务器部署的代码，任何修改都需要进行分支。完成后先拉取最新分支，并发布到测试服务器中。最后再拉取最新分支，合并分支到主分支。若最后又发现了新分支，所以需要继续进行测试-回归测试，继续拉取合并。系统越大，这个问题越突出。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-15-07.png)
>
> 换语言 换版本 在小系统中随便就换了，但是大系统中会面临很大问题，你不知道会在哪里出现问题。
>
> 单体应用架构演变-微服务：
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-20-41.png)
>
> 功能增多 并发增加  例如增加一个小程序
>
> 代码复用问题、系统间相互调用(秒杀下单需要查询商品)问题、接口不仅需要对外提供服务，也需要对内提供服务，但是对内对外服务的参数可能不一样、数据分析导致数据库性能问题，影响业务、数据库被多个服务依赖，无法升级和拆分、开发测试部署困难。
>
> 对某个部件的升级需要对所有功能测试后实施。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-33-22.png)
>
> 单体应用代码重复问题：
>
> 前后端分离，此时三个系统就是前端客户端，后端系统访问共有的服务，独立部署 但是数据库性能还是会影响，表结构变化需要谨慎。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-37-11.png)
>
> 对数据库服务进行改进，使得每个服务都有自己独立的数据库mysql redis。会添加多余的接口。但是会有很好的隔离性
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-42-08.png)
>
> 内部系统间通过http请求，效率较低。因为是一个纯文本协议。希望内部通过rpc像调用本地函数一样调用。最下面是service服务，上面是整合出来的web服务，服务之间语言不限。组件不限。可以分别部署。
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_19-49-01.png)
>
> 微服务中需要解决的问题：
>
> 服务过多，微服务间调用问题 必须知道ip+端口，并且需要知道服务健康问题
>
> 注册中心：服务开发完注册到中心，中心定时检测是否健康
>
> 服务发现：web向服务发现查询某个微服务的ip和端口
>
> 配置中心：超时时间、改token，服务每次都直接在配置中心获取，不需要重新启动
>
> 链路追踪：解决整个服务出现性能问题，A调用B B调用C ... 将调用的时间记录下来，分析每部分的性能
>
> 

**系统可靠性保障** 熔断限流 api网关的部署

> 最后利用nginx作为服务网关：提供路由服务、服务发现、鉴权、熔断(多次访问无结果，再次来请求直接熔断)、ip黑白名单、负载均衡
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_20-11-34.png)
>
> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_20-14-26.png)

**前后端分离开发中接口管理的痛点**

> ![](F:\markdown笔记\电商系统\images\Snipaste_2022-02-14_20-57-29.png)
>
> 对数据的解释通过文档说明，所以文档变得更加重要。
>
> yapi写好接口可以实现自动mock数据给前端使用，也可以生成http请求并验证返回数据是否合法。yapi可以根据接口自动生成一个测试集。
>
> YApi 是高效、易用、功能强大的 api 管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务。可以帮助开发者轻松创建、发布、维护  API，YApi 还为用户提供了优秀的交互体验，开发人员只需利用平台提供的接口数据写入工具以及简单的点击操作就可以实现接口的管理。
>
> 安装
>
> ```
> 拉镜像
> docker pull registry.cn-hangzhou.aliyuncs.com/anoy/yapi
> 
> 创建挂载目录
> mkdir -p /data/yapi/mongodata
> 
> 运行专用mongo
> docker run --restart always -v /data/yapi/mongodata:/data/db -d --name yapimongo mongo
> 
> 运行容器初始化
> docker run -it --rm --link yapimongo:mongo --entrypoint npm --workdir /api/vendors registry.cn-hangzhou.aliyuncs.com/anoy/yapi run install-server
> 
> 初始化管理员账号成功,账号名："admin@admin.com"，密码："ymfe.org"
> 
> 运行服务
> docker run -d  --restart=always --name yapi  --link yapimongo:mongo --workdir /api/vendors  -p 3001:3000  registry.cn-hangzhou.aliyuncs.com/anoy/yapi  server/app.js
> 
> chrom访问
> http://192.168.220.128:3001 登录
> 
> 可以创建项目、分类和分类下的接口，接口创建完成后的mock地址是给前端用的，运行时需要先安装插件。编辑中可以设置请求参数，mock部分如果没有写死，可以自动生成。因为前后端分离系统，所以数据为json类型，但是json无法具有表述性，例如数据字段类型。所以可以在项目中开启JSON-SCHEMA，mock严格模式、开启json5。可以在运行里的body里查看数据内容。也可以使用高级设置进一步设置。可以在url中设置运行环境、header、cookie等参数。全部完成后会在预览中自动向前端生成mock地址。用于前端测试。
> 
> 最后可以使用测试集合，导入接口。开始测试后，会生成测试报告。多个接口一键测试完成。数据管理中的数据导入导出，可以导入导出接口数据文档。
> 
> 点击下面的链接下载最新版插件，并且解压：https://cdn.jsdelivr.net/npm/yapi-x-chrome-extension/archive.zip
> 复制下面的链接在地址栏打开 Chrome 的扩展程序：chrome://extensions，然后，打开开发者模式：最后，点击加载已解压的扩展程序，导入插件即可
> ```
>
>  